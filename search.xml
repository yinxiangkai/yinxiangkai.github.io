<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>远程连接服务器</title>
    <url>/posts/b49c4352.html</url>
    <content><![CDATA[<h2 id="1、连接工具："><a href="#1、连接工具：" class="headerlink" title="1、连接工具："></a>1、连接工具：</h2><h3 id="1-1-vscode"><a href="#1-1-vscode" class="headerlink" title="1.1 vscode"></a>1.1 vscode</h3><p>如果不使用图形化界面个人最推荐vscode。</p>
<h4 id="1-1-1-使用说明"><a href="#1-1-1-使用说明" class="headerlink" title="1.1.1 使用说明"></a>1.1.1 使用说明</h4><p>下载网址：<a href="https://code.visualstudio.com/">Visual Studio Code - Code Editing. Redefined</a></p>
<p>安装扩展Remote-SSH。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121238872.png" alt="image">​</p>
<p>Ctrl+Shift+P ,输入remote-ssh选择ssh配置文件</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121241579.png" alt="image">​</p>
<p>然后选择user目录下配置文件</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121242709.png" alt="image">​</p>
<p>进入配置文件按照如下格式填写：通过ssh进行远程连接，ssh默认端口是22，如果路由器进行端口映射，则填写相应端口。GPU服务器的IP地址与端口号，可以找相应的设备管理员询问。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Host A100-135  //随意</span><br><span class="line">    HostName 10.102.33.135 //主机的IP地址</span><br><span class="line">    User username        //用户名</span><br><span class="line">    Port 22           //端口号</span><br></pre></td></tr></table></figure>
<p>点击远程连接（左下角绿色区域），选择连接到主机。然后选择相应的主机，输入密码即可。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121246477.png" alt="image">​</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121248220.png" alt="image">​</p>
<p>在资管理器里显示对应的目录,导航栏-&gt;文件-&gt;打开文件夹选择相应目录即可。</p>
<h4 id="1-1-2-问题解决"><a href="#1-1-2-问题解决" class="headerlink" title="1.1.2 问题解决"></a>1.1.2 问题解决</h4><p>客户端vscode更新可能会导致远程服务器vsocde-server出现问题，通过cmd 连接到远程服务器，清空自己目录下的.vscode-server，然后重新连接即可。<br>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121253911.png" alt="image">​</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121254583.png" alt="image">​</p>
<h3 id="1-2-mobaXterm"><a href="#1-2-mobaXterm" class="headerlink" title="1.2 mobaXterm"></a>1.2 mobaXterm</h3><p>下载地址：<a href="https://mobaxterm.mobatek.net/download.html">MobaXterm Xserver with SSH, telnet, RDP, VNC and X11 - Download (mobatek.net)</a></p>
<p>该软件提供给了多种远程连接方式。在Session中选择相应的连接方式，按照要求填写就行。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121256752.png" alt="image">​</p>
<h3 id="1-3-Xshell"><a href="#1-3-Xshell" class="headerlink" title="1.3 Xshell"></a>1.3 Xshell</h3><p>下载地址：<a href="https://www.xshell.com/zh/free-for-home-school/">家庭/学校免费 - NetSarang Website (xshell.com)</a></p>
<p>基本与mobaXterm类似，但是文件传输需要使用Xfpt比较麻烦。</p>
<h3 id="1-4-问题解决"><a href="#1-4-问题解决" class="headerlink" title="1.4 问题解决"></a>1.4 问题解决</h3><p>可能会存在有账号但是连接不上的情况，一个可能的原因是创建用户时，用户目录的创建存在问题，例如创建用户时使用的命令错误，导致只有账号没有对应的用户目录。无法使用远程桌面服务则有可能是用户目录下缺失desktop等子目录。可以使用命令  xdg-user-dirs-update 。</p>
<h2 id="2-免密登录"><a href="#2-免密登录" class="headerlink" title="2 免密登录"></a>2 免密登录</h2><h4 id="2-1-配置"><a href="#2-1-配置" class="headerlink" title="2.1 配置"></a>2.1 配置</h4><p>远程连接除了每次输入密码还可以通过密钥进行验证。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">ssh<span class="literal">-keygen</span> <span class="literal">-t</span> rsa <span class="literal">-b</span> <span class="number">4096</span> <span class="literal">-C</span> <span class="string">&quot;你的邮箱&quot;</span> <span class="operator">-f</span> ~/.ssh/指定名称、</span><br></pre></td></tr></table></figure>
<p>将公钥（.pub）中的内容复制到服务器个人目录下的.ssh/authorized_keys中即可，没有的话可以手动创建。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121306792.png" alt="image">​</p>
<h4 id="2-2-问题解决"><a href="#2-2-问题解决" class="headerlink" title="2.2 问题解决"></a>2.2 问题解决</h4><p>由于组内服务器不问题，会不定时重装系统，导致用户目录被删除，这种情况下会导致免密登录会出现如下情况：</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121314900.png" alt="image">​</p>
<p>删除本地 .ssh目录下 know_hosts中对应服务器的信息即可。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121318247.png" alt="image">​</p>
<p>再次进行连接：yes 输入密码即可，然后重新配置一次免密登录。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121322216.png" alt="image">​</p>
<p>‍</p>
<h2 id="3-校内服务器与泉城实验室服务器网段一致"><a href="#3-校内服务器与泉城实验室服务器网段一致" class="headerlink" title="3 校内服务器与泉城实验室服务器网段一致"></a>3 校内服务器与泉城实验室服务器网段一致</h2><p>泉城实验室和校园的网段使用的都是10.0.0.0/8的局域网段。导致一旦开启泉城实验室的VPN会导致无法连接校内服务器。解决方案是修改本地主机的路由表。</p>
<p>校内服务器的IP地址是10.102.0.0/16网段,泉城实验室服务器的网段是 10.0.9.0/24。</p>
<h4 id="3-1-临时方案"><a href="#3-1-临时方案" class="headerlink" title="3.1 临时方案"></a>3.1 临时方案</h4><p>首先查看一下VPN的IP。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121355406.png" alt="image">​</p>
<p>关闭VPN打印路由表：</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121359935.png" alt="image">​</p>
<p>启用VPN，打印一下路由表，不难发现整个10.0.0.0/24网段都被转发了。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121358192.png" alt="image">​</p>
<p>删除10.0.0.0/24的路由，该命令要使用管理员权限，使用管理员权限打开cmd再执行改命令。然后就可以再连接VPN的情况下访问校内服务器。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">route delete <span class="number">10.0</span>.<span class="number">0.0</span></span><br></pre></td></tr></table></figure>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121401720.png" alt="image">​</p>
<p>但是上述方案存在一个问题，每次重新启用VPN，VPN软件都会再次添加10.0.0.0/24网段到路由表中。</p>
<h4 id="3-2-长久方案"><a href="#3-2-长久方案" class="headerlink" title="3.2 长久方案"></a>3.2 长久方案</h4><p>实验室网线接口走的是交换机，交换机不关机网关应该不会变，但是如果连接WIFI则不确定，要想切换网络不受影响，可以写个脚本时刻检测网络情况。<br>连接实验室局域网的如果不关机，下面的方法问题不大：</p>
<p>查看默认网关</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121603727.png" alt="image">​</p>
<p>然后在管理员权限下，添加一条路由，学校网段的ip走默认网关，并提高优先级，这样VPN重启就不影响了。<br><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">route add <span class="number">10.102</span>.<span class="number">0.0</span> mask <span class="number">255.255</span>.<span class="number">0.0</span> <span class="number">101.76</span>.<span class="number">255.254</span> metric <span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202409121620484.png" alt="image">​</p>
<h2 id="4-远程控制"><a href="#4-远程控制" class="headerlink" title="4 远程控制"></a>4 远程控制</h2><p>可以使用todesk：<a href="https://www.todesk.com/">ToDesk远程桌面软件-免费安全流畅的远程连接电脑手机</a></p>
<p>‍</p>
]]></content>
      <categories>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>SSH</tag>
        <tag>工具</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title>NTT（快速数论变换）</title>
    <url>/posts/a0adbc0f.html</url>
    <content><![CDATA[<h2 id="1-算法介绍"><a href="#1-算法介绍" class="headerlink" title="1 算法介绍"></a>1 算法介绍</h2><h3 id="1-1-多项式乘法引入"><a href="#1-1-多项式乘法引入" class="headerlink" title="1.1 多项式乘法引入"></a>1.1 多项式乘法引入</h3><h4 id="1-1-1-多项式的两种表示方法"><a href="#1-1-1-多项式的两种表示方法" class="headerlink" title="1.1.1 多项式的两种表示方法"></a>1.1.1 多项式的两种表示方法</h4><p>一般 $n$ 次多项式如公式（1）所示。多项式具有两种表示方法分别是系数表示法和点值表示法。</p>
<script type="math/tex; mode=display">
\begin{equation}
A(x)=a_0+a_1x^1+a_2x^2+\ldots +a_{n-1}x^{n-1}+a_nx^n=\sum^{n}_{i=0}a_ix^i
\end{equation}</script><h5 id="系数表示法："><a href="#系数表示法：" class="headerlink" title="系数表示法："></a>系数表示法：</h5><p>任意多项式都可以通过一组系数所确定，而这组系数所组成的向量也叫做系数向量,通过系数向量表示一个多项的方式也叫做系数表示法。例如公式（1）中 $A(x)$ 的系数向量为：$\mathbf{a}=[a_0  ,a_1,\ldots,a_{n-1},a_n]$。</p>
<h5 id="点值表示法："><a href="#点值表示法：" class="headerlink" title="点值表示法："></a>点值表示法：</h5><p>对于一个已知的多项式例如公式（1）中的 $A(x)$ ，将 $x_i$ 代进去可以得到一个确定的值 $y_i$ ，如：$y_0=A(x_0)$ 。且可将 $(x_0,y_0)$ 看作是坐标系上的一个点。可将任意多（互不相等）的自变量 $( x_1,x_2,\ldots,x_{n-1}, x_n)$ 代入到 $A(x)$ 中，从而得到更多的点：$(x_1,y_1),(x_2,y_2),\ldots(x_n,y_n)$。通过 n+1 个不同点组成的点集 $P=\{(x_0,y_0),(x_1,y_1),\ldots,(x_n,y_n)\} $ ，唯一确定一个 n 次多项式，该方式也叫做多项式的点值表示法。</p>
<h4 id="1-1-2-多项式乘法"><a href="#1-1-2-多项式乘法" class="headerlink" title="1.1.2 多项式乘法"></a>1.1.2 多项式乘法</h4><p>已知两个多项式 $A(x)$ 和 $B(x)$，分别是 $n$ 次多项式和 m 次多项式。</p>
<script type="math/tex; mode=display">
\begin{align}
A(x)=\sum^{n}_{i=0}a_ix^i\\
B(x)=\sum^{m}_{i=0}b_ix^i
\end{align}</script><p>公式（2）和公式（3）相乘得到一个最高为 $n+m$ 次的多项式 $C(x)$。系数向量：$\mathbf{c}=[c_0  ,c_1,\ldots,c_{m+n}]$。</p>
<script type="math/tex; mode=display">
\begin{align}
C(x)=\sum^{n+m}_{i=0}c_ix^i

\end{align}</script><h5 id="系数乘法："><a href="#系数乘法：" class="headerlink" title="系数乘法："></a>系数乘法：</h5><p>系数乘法，将两个多项式的系数相乘，系数相乘，如公式（5）所示。不难看出时间复杂为 $O(n^2)$。整理可得公式（6）。</p>
<script type="math/tex; mode=display">
\begin{align}
C_{i+j}=  \sum_{i=0}^{n} \sum_{j=0}^{m} a_i b_j 
\end{align}</script><script type="math/tex; mode=display">
\begin{align}
C_i=\sum^{i}_{j=0}a_jb_{i-j}
\end{align}</script><h5 id="点值乘法："><a href="#点值乘法：" class="headerlink" title="点值乘法："></a>点值乘法：</h5><p>点值乘法只需将要将对应的纵坐标相乘即可，但是因为新得到的多项式次数更高，所以每个因子多项式都需要提供 $m+n+1$ 个点参与运算。时间复杂度为 $O(n)$。</p>
<h5 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h5><p>在计算多项式乘法时，点值表示的时间复杂度低。但是在计算系统中系数表示更加的常用。于是很自然的想到，在进行乘法时从系数表示转换到点值表示，使用点值表示法进行乘法运算，然后再转换为系数表示法。</p>
<p>但是很不幸的是，从系数表示转换到点值表示，以及点值表示到系数表示，这两个过程的时间复杂度均为 $O(n^2)$。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202402191953350.svg" alt="图1 多项式乘法总结图" title="图1 多项式乘法总结图"></p>
<h4 id="1-1-3-转换优化"><a href="#1-1-3-转换优化" class="headerlink" title="1.1.3 转换优化"></a>1.1.3 转换优化</h4><p>如果通过减少求值的点数可以较少计算时间。根据函数的奇偶性我们可以只求一半的点值，从而减少一半的计算量。这里为了方便表示设一个 $n-1$ 次的一般多项式，$n=2^a , a\in \mathbb{N}$。</p>
<script type="math/tex; mode=display">
P(x)=p_0+p_1x^1+p_2x^2+\ldots +p_{n-1}x^{n-1}=\sum^{n-1}_{i=0}p_ix^i</script><p>将偶次项和奇数项分别组合：</p>
<script type="math/tex; mode=display">
P(x)=(p_0+p_2x^2\ldots+p_{n-2}x^{n-2})+(p_1x^1+\ldots +p_{n-1}x^{n-1})</script><p>对奇次项提取公因式 $x$:</p>
<script type="math/tex; mode=display">
P(x)=(p_0+p_2x^2\ldots+p_{n-2}x^{n-2})+x(p_1x^0+\ldots +p_{n-1}x^{n-2})</script><p>化简为：</p>
<script type="math/tex; mode=display">
\begin{align}
P(x)=P_e(x^2)+xP_o(x^2)
\end{align}</script><p>则我们可以取 $\frac{n}{2}$ 对相反数点，这样我们只需要计算一半的点值。</p>
<script type="math/tex; mode=display">
P(x_i)=P_e(x_i^2)+xP_o(x_i^2) \\
P(-x_i)=P_e(x_i^2)-x_iP_o(x_i^2)</script><p>  观察公式（7）不难发现，是将是将 $P(x)$ 拆成了两个规模为 $\frac{n}{2}$ 的 $P_e(x)$,$P_o(x）$。自然而然想到了递归执行。但是问题是相反数平方运算后所得结果均为正数，无法构造相反数对，无法实现递归。如果能一直保持相反数点对，那么时间复杂度可以表示为$T(n)=T(2n)+O(n)$ ，即时间复杂度为 $O(n\log n)$。</p>
<h4 id="1-1-4-单位根（复平面）"><a href="#1-1-4-单位根（复平面）" class="headerlink" title="1.1.4 单位根（复平面）"></a>1.1.4 单位根（复平面）</h4><p>既然实数域没有办法解决上面的问题，可以将起扩展到复平面。我们希望取一些点使其平方后的结果依然存在相反数对。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202402191953363.svg" alt="图2 复平面图" title="图2 复平面图"></p>
<p>既然点是我们自己选的，那不如使最后一组相反数点对为 $\{1,-1\}$。我们取 n 等于 8 作为演示。不难看出最后选取的 8 个点均是 $x^8=1$ 的解。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202402191953795.svg" alt="图3 n=8选点示例图" title="图3 n=8选点示例图"></p>
<p>对于任意 $n=2^a , a\in \mathbb{N}$，来说即为 $x^n=1$。</p>
<p>由欧拉公式:</p>
<script type="math/tex; mode=display">
e^{i \theta}=\cos\theta+i\sin\theta</script><p>可以得到公式：</p>
<script type="math/tex; mode=display">
z^n=1=\cos2k\pi+i\sin2k\pi=e^{2k\pi i},k \in[ 0,n)</script><p>所以:</p>
<script type="math/tex; mode=display">
z=\sqrt[n]{e^{2k\pi i}}=e^\frac{2k\pi i}{n} ,k \in[ 0,n)</script><p>上面是 $n$ 次单位复数根的推导。当 $k=1$ 时，值 $\omega_n=e^\frac{2\pi i}{n}$ 被成为主 $n$ 次单位复数根，其他的 $n$ 次单位根都是 $\omega_n$ 的幂次。其中 $\theta$ 表示为复平面单位圆上的弧长。因此 $e^\frac{2\pi i}{n}$ 表示将一个单位圆均分 $n$ 份。$n=8$ 时如下图所示。​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202402192044572.webp" alt="图4  8次单位根示意图" title="图4  8次单位根示意图">​</p>
<h5 id="n-次单位根的性质："><a href="#n-次单位根的性质：" class="headerlink" title="$n$ 次单位根的性质："></a>$n$ 次单位根的性质：</h5><p><strong>消去引理：</strong></p>
<script type="math/tex; mode=display">
\omega_{dn}^{dk}=\omega_n^k\\
\omega_{n}^{\frac{n}{2}}=-\omega_2=-1\\
\omega_{n}^{k+\frac{n}{2}}=-\omega_n^k</script><p><strong>折半引理：</strong></p>
<script type="math/tex; mode=display">
(\omega_n^k)^2=\omega_{\frac{n}{2}}^k</script><p><strong>求和引理：</strong></p>
<script type="math/tex; mode=display">
\sum_{i=0}^{n-1} (\omega_n^k)^i =
\begin{cases}
0, & k \neq mn, \ m \in \mathbb{Z} \\
n, & k = mn, \ m \in \mathbb{Z}
\end{cases}</script><h3 id="1-2-DFT-与-IDFT"><a href="#1-2-DFT-与-IDFT" class="headerlink" title="1.2 $DFT$ 与 $IDFT$"></a>1.2 $DFT$ 与 $IDFT$</h3><p>经过 1.1 节的介绍已经对多项式乘法的相关内容有了相应的了解，下面开始正式介绍 $DFT$ 与 $IDFT$，将在 1.3 节介绍 $FFT$ 与 $IFFT$ 的相关内容。我们是从多项式乘法引入的$DFT$和$IDFT$，但是$DFT$和$IDFT$的应用的场景有很多，多项式求值、大数乘法，拉格朗日插值、矩阵乘法、中国剩余定理以及环同态。</p>
<h4 id="1-2-1-离散傅里叶变换（-DFT-）"><a href="#1-2-1-离散傅里叶变换（-DFT-）" class="headerlink" title="1.2.1 离散傅里叶变换（$DFT$）"></a>1.2.1 离散傅里叶变换（$DFT$）</h4><p>设有一个 $n-1$ 次的多项式 $P(x)$:</p>
<script type="math/tex; mode=display">
P(x) = a_0 + a_1x + a_2x^2 + \ldots + a_{n-1}x^{n-1}</script><p>多项式 $P(x)$ 的 $DFT$ 在单位根 $\omega_n^k = e^{2\pi i k / n}  $ 上的值计算如下：</p>
<script type="math/tex; mode=display">
P_k = P(\omega_n^k) = \sum_{j=0}^{n-1} a_j \omega_n^{kj} \quad  k = 0, 1, \ldots, n-1</script><h4 id="1-2-2-逆离散傅里叶变换（-IDFT-）"><a href="#1-2-2-逆离散傅里叶变换（-IDFT-）" class="headerlink" title="1.2.2 逆离散傅里叶变换（$IDFT$）"></a>1.2.2 逆离散傅里叶变换（$IDFT$）</h4><p>对 $DFT$ 过程我们可以通过矩阵进行描述 $y=Wa$：</p>
<script type="math/tex; mode=display">
\left[ \begin{array}{c}
y_0 \\
y_1 \\
y_2 \\
\vdots \\
y_{n-1} \\
\end{array} \right]
=
\left[ \begin{array}{cccc}
1 & 1 & \ldots & 1 \\
1 & \omega_n & \ldots & \omega_n^{n-1} \\
1 & \omega_n^2 & \ldots & \omega_n^{2(n-1)} \\
\vdots & \vdots & \ddots & \vdots \\
1 & \omega_n^{n-1} & \ldots & \omega_n^{(n-1)^2}
\end{array} \right]
\left[ \begin{array}{c}
a_0 \\
a_1 \\
a_2 \\
\vdots \\
a_{n-1} \\
\end{array} \right]</script><p>其中 $V_n$ 是一个范德蒙矩阵，是一个可逆矩阵，因此 $IDFT$：$a=W^{-1}y$。</p>
<p>下面求取:$W_n^{-1}$。矩阵 $W$ 可以表示为：$W_{jk}=ω_ n^{jk}$。$W_{jk}^{-1}$ 的值应该是 $W_{jk}$ 的共轭除以 $n$。由 $\omega _n$ 的性质，我们知道 $\omega _n^k$ 的共轭是 $\omega _n^{-k}$。因此 $W_{jk}^{-1}=\frac{1}{n}ω_ n^{-jk}$。所以 $DFT$ 和 $IDFT$ 的时间复杂一致，甚至计算流程基本一致。</p>
<script type="math/tex; mode=display">
a_j= \frac{1}{n}\sum_{j=0}^{n-1} y_j ω_ n^{-jk} \quad  k = 0, 1, \ldots, n-1</script><h3 id="1-3-快速傅里叶变化（-FFT-）"><a href="#1-3-快速傅里叶变化（-FFT-）" class="headerlink" title="1.3 快速傅里叶变化（$FFT$）"></a>1.3 快速傅里叶变化（$FFT$）</h3><p>其实 $FFT$ 的思路在 1.1.3 节中进行了介绍只是并不是很完善，下面进行一个较为细致的描述。详细介绍 FFT 的递归实现和迭代实现。</p>
<h4 id="1-3-1-FFT-递归实现"><a href="#1-3-1-FFT-递归实现" class="headerlink" title="1.3.1 $FFT$ 递归实现"></a>1.3.1 $FFT$ 递归实现</h4><p>将单位根带入公式（7）得：</p>
<script type="math/tex; mode=display">
\begin{align}
P(\omega_n^k)=P_e((\omega_n^k)^2)+{\omega_n^k}P_o((\omega_n^k)^2) \quad k \in[ 0,n)
\end{align}</script><p>根据消去引理推导出得对称性以及折半引理对公式（8）进行化简。取 $k \in[0,\frac{n}{2})$ 。</p>
<script type="math/tex; mode=display">
\begin{align*}
P(\omega_{n}^{k})&=P_{e}((\omega_{n}^{k})^2)+{\omega_{n}^{k}}P_{o}((\omega_{n}^{k})^2)\\
 & =P_{e}(\omega_{\frac{n}{2}}^{k})+{\omega_{n}^{k}}P_{o}(\omega_{\frac{n}{2}}^{k})\\ 

 \end{align*}</script><script type="math/tex; mode=display">
\begin{align*}
P(\omega_{n}^{k+m})&=P_{e}((\omega_{n}^{k+m})^2)+\omega_{n}^{k+m}P_{o}((\omega_{n}^{k+m})^2)\\
 & =P_{e}(\omega_{\frac{n}{2}}^{k+m})+\omega_{n}^{k+m}P_{o}(\omega_{\frac{n}{2}}^{k+m})\\ 
& =P_{e}(-\omega_{\frac{n}{2}}^{k})-\omega_{n}^{k}P_{o}(-\omega_{\frac{n}{2}}^{k})\\
& =P_{e}(\omega_{\frac{n}{2}}^{k})-\omega_{n}^{k}P_{o}(\omega_{\frac{n}{2}}^{k})
 \end{align*}</script><p>即公式（9-10），这两个式子也被称为 CT(Cooley-Tukey)蝶形操作，$\omega_{n}^{k}$ 被成为转换因子。</p>
<script type="math/tex; mode=display">
\begin{align}
P(\omega_{n}^{k})=P_{e}(\omega_{\frac{n}{2}}^{k})+{\omega_{n}^{k}}P_{o}(\omega_{\frac{n}{2}}^{k})\\
P(\omega_{n}^{k+m})=P_{e}(\omega_{\frac{n}{2}}^{k})-\omega_{n}^{k}P_{o}(\omega_{\frac{n}{2}}^{k})
\end{align}</script><p>现在给出递归版本得算法：</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\hline
\textbf{Algorithm 1} & \text{ Recursion   FFT}\\ 
\hline
\textbf{Require:} & P=[p_0,p_1,\ldots,p_{n-1}]\quad n=2^{a},a\in\mathbb{N}\\ 
\textbf{function} & \text{FFT\_R}(P)\\ 

&n\leftarrow len(P)\\
&\text{if}\quad n==1 \\
&\quad \text{return}\quad P\\
&\text{endif}\\
&\omega_n \leftarrow e^{\frac{2\pi i}{n}}\\
&P_e\leftarrow [p_0,p_2,\ldots,p_{n-2}]\\
&P_o\leftarrow [p_1,p_3,\ldots,p_{n-1}]\\
&y_e\leftarrow  FFT\_R(P_e)\\
&y_o\leftarrow  FFT\_R(P_o)\\
& \text{for} \quad k \quad \text{to} \quad \frac{n}{2}-1\\
&\quad y[k]=y_e[k]+\omega_n^ky_o[k]\\
&\quad y[k+\frac{n}{2}]=y_e[k]-\omega_n^ky_o[k]\\
&\text{endfor}\\
&\text{return} \quad y \\
\textbf{end function} & \\ 
\hline & 
\end{array}</script><h5 id="蝶形操作："><a href="#蝶形操作：" class="headerlink" title="蝶形操作："></a>蝶形操作：</h5><p>蝶形操作得名于其数据流图的形状，上面的推导过程出现的是 CT 蝶形变换，还有一种 GS 蝶形变换。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202402192017314.svg" alt="图5 CT蝶形操作图" title="图5 CT蝶形操作图">​</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202402191954300.svg" alt="图6 CT蝶形操作简化图" title="图6 CT蝶形操作简化图">​</p>
<p>通过公式（9-10）我们可以推导出 GS 蝶形变换的形式。将公式（9）和（10）分别加减运算得：</p>
<script type="math/tex; mode=display">
P(\omega_{n}^{k}) + P(\omega_{n}^{k+m}) = 2P_{e}(\omega_{\frac{n}{2}}^{k})
\\

P(\omega_{n}^{k}) - P(\omega_{n}^{k+m}) = 2\omega_{n}^{k}P_{o}(\omega_{\frac{n}{2}}^{k})</script><p>整理得公式（11-12）不难看出，GS 操作是 CT 操作的逆过程，可以用于 $IFFT$ 中,当然也可以用在$FFT$中，通常CT方法也叫$DIT$（时域抽取）操作，GS操作也叫$DIF$（频域抽取）操作。</p>
<script type="math/tex; mode=display">
\begin{align}

P_e(\omega_{\frac{n}{2}}^{k}) &= \frac{1}{2}(P(\omega_{n}^{k}) + P(\omega_{n}^{k+m})) \\
P_o(\omega_{\frac{n}{2}}^{k}) &= \frac{1}{2\omega_{n}^{k}}(P(\omega_{n}^{k}) - P(\omega_{n}^{k+m})) 

\end{align}</script><p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202402191954666.svg" alt="资源 11" title="图7 GS蝶形操作">​</p>
<h4 id="1-3-2-FFT-迭代实现"><a href="#1-3-2-FFT-迭代实现" class="headerlink" title="1.3.2 $FFT$ 迭代实现"></a>1.3.2 $FFT$ 迭代实现</h4><p>继续优化。依然拿 n=8 举例。递归数据操作如图 7 所示，在递归操作中是自定向下层层展开，然后逐层向上收缩。每一次递归都会消耗堆栈资源，影响效率。如果可以从底向上计算，那么可以省去堆栈资源的消耗，提高程序运行效率。于是现在的问题就变为了如何确定递归树叶子节点的元素排序。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202402191954478.svg" alt="图8 n=8时递归示意图" title="图8 n=8时递归示意图">​</p>
<h5 id="位逆序"><a href="#位逆序" class="headerlink" title="位逆序"></a><strong>位逆序</strong></h5><p>将叶子节点元素顺序和原始元素顺序均使用二进制表示。发现二进制表示发生了左右对称反转，称之为位逆序变换。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//位逆序</span></span><br><span class="line">Layer <span class="number">4</span>:	<span class="number">0</span>	<span class="number">4</span>	<span class="number">2</span>	<span class="number">6</span>	<span class="number">1</span>	<span class="number">5</span>	<span class="number">3</span>	<span class="number">7</span></span><br><span class="line">Binary:		<span class="number">000</span> <span class="number">100</span> <span class="number">010</span> <span class="number">110</span> <span class="number">001</span> <span class="number">101</span> <span class="number">011</span> <span class="number">111</span></span><br><span class="line">Reverse:	<span class="number">000</span> <span class="number">001</span> <span class="number">010</span> <span class="number">011</span> <span class="number">100</span> <span class="number">101</span> <span class="number">110</span> <span class="number">111</span></span><br><span class="line">Decimal:	<span class="number">0</span>	<span class="number">1</span>	<span class="number">2</span>	<span class="number">3</span>	<span class="number">4</span>	<span class="number">5</span>	<span class="number">6</span>	<span class="number">7</span></span><br></pre></td></tr></table></figure>
<p>下面是 Bit-Reverse-Copy 的实现:</p>
<script type="math/tex; mode=display">
\begin{array}{ll}\hline\textbf{Algorithm 2} & \text{Bit-Reverse-Copy}\\ 
\hline\textbf{Require:} & A\\ \textbf{function} & \text{BitReverseCopy}(A)\\  & n\leftarrow len(A)\\  & b\leftarrow\log_2(n)\\  & \text{for}\quad i=0\quad\text{to}\quad n-1\\  & \quad r\leftarrow\text{ReverseBits}(i,b)\\  & \quad B[r]\leftarrow A[i]\\  & \text{endfor}\\  & \text{return}\quad B\\ \textbf{end function} \\ \hline \end{array}</script><p>函数 ReverseBits 的实现如下,基本过程就是取原值低位赋值给目标值低位，然后原值右移一位，目标值左移一位，直到循环结束。</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\hline
\textbf{Function} & \text{ReverseBits}(i, b) \\
\hline
& result \leftarrow 0 \\
& \text{for}\quad j = 0\quad\text{to}\quad b - 1 \\
& \quad result \leftarrow result \ll 1 \\
& \quad bit \leftarrow (i \gg j) \& 1 \\
& \quad result \leftarrow result \, | \, bit \\
& \text{endfor} \\
& \text{return}\quad result \\
\hline
\end{array}</script><h5 id="迭代算法实现"><a href="#迭代算法实现" class="headerlink" title="迭代算法实现"></a>迭代算法实现</h5><p>算法 3 是$DIT$实现，算法4是$DIF$实现。$s $ 可以看作是合并轮数。$m$ 是当前合并次数下每个单元的规模。其中$\hat{1}$是乘法单位元都是$\omega_n^0$。这里的$\omega_n=﻿e^{\pm2\pi i  / n}$,在进行$FFT$操作时取正，$IFFT$操作时取负。当然IFFT还需要乘上$n^{-1}$。</p>
<script type="math/tex; mode=display">
\begin{array}{ll}\hline\textbf{Algorithm 3} & \text{DIT}\\ 
\hline
\textbf{Require:} & A=[a_0,a_1,\ldots,a_{n-1}]\quad n=2^{x},x\in\mathbb{N}\\ \textbf{function} & \text{DIT}(A)\\  
& n\leftarrow len(A)\\  
& P\leftarrow BitReverseCopy(A)\\
& \text{for}\quad s=1\quad\text{to}\quad \log_2n\\  
& \quad m=2^s\\
& \quad \omega_m=\omega_n^{\frac{n}{m}}\\

& \quad\text{for}\quad k=0\quad \text{to} \quad n-1 \quad \text{by}\quad m\\  
& \quad\quad \varphi=\hat{1}\\

& \quad\quad\text{for}\quad j=0\quad\text{to} \quad \frac{m}{2}-1\\  
& \quad\quad\quad t=\varphi P[k+j+\frac{m}{2}]\\
& \quad\quad\quad u= P[k+j]\\
& \quad\quad\quad P[k+j]= u+t\\
& \quad\quad\quad P[k+j+\frac{m}{2}]= u-t\\
& \quad\quad\quad \varphi=\varphi \omega_m\\
& \quad\quad\text{endfor}\\ 

& \quad\text{endfor}\\ 

& \text{endfor}\\  
& \text{return}\quad P\\
 \textbf{end function}
& \\ 
\hline 
& \end{array}</script><script type="math/tex; mode=display">
\begin{array}{ll}\hline\textbf{Algorithm 4} & \text{DIF}\\ 
\hline
\textbf{Require:} & A=[a_0,a_1,\ldots,a_{n-1}]\quad n=2^{x},x\in\mathbb{N}\\ \textbf{function} & \text{DIF}(P)\\  
& n\leftarrow len(A)\\  
& P\leftarrow A\\
& \text{for}\quad s=\log_2n \quad\text{to}\quad 1\\  
& \quad m=2^s\\
& \quad \omega_m=\omega_n^{\frac{n}{m}}\\

& \quad\text{for}\quad k=0\quad \text{to} \quad n-1 \quad \text{by}\quad m\\  
& \quad\quad \varphi=\hat{1}\\

& \quad\quad\text{for}\quad j=0\quad\text{to} \quad \frac{m}{2}-1\\  
& \quad\quad\quad t= P[k+j+\frac{m}{2}]\\
& \quad\quad\quad u= P[k+j]\\
& \quad\quad\quad P[k+j]= u+t\\
& \quad\quad\quad P[k+j+\frac{m}{2}]= \varphi(u-t)\\
& \quad\quad\quad \varphi=\varphi \omega_m\\
& \quad\quad\text{endfor}\\ 

& \quad\text{endfor}\\ 

& \text{endfor}\\  
& P\leftarrow BitReverseCopy(P)\\
& \text{return}\quad P\\
 \textbf{end function}
& \\ 
\hline 
& \end{array}</script><p>下面是 n=8 时，$DIT$迭代 $FFT$ 的数据流图。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202402291729252.svg" alt="图9 n=8迭代DIT数据流图" title="图9 n=8迭代DIT数据流图">​</p>
<h5 id="迭代的另一种视角"><a href="#迭代的另一种视角" class="headerlink" title="迭代的另一种视角"></a>迭代的另一种视角</h5><p>如果不对输入进行位逆序而是对输出进行位逆序应当怎样计算，下面给出一个示例算法，该算法和算法3的逻辑是类似的。只是出现了些许变动。这里的$\Phi_{rev}$是位逆序后的$\omega$的幂次表，需要注意的是这里不对输入进行位逆序而是对单位根幂次表进行位逆序。由于上述的变换，数据流图也发生了相应的改变。m表示的是当前轮次NTT的大小，n表示当前轮次CT跨度，$j_1$表示分组的起点，数据流图如图10所示，输出结果是位逆序后的。</p>
<script type="math/tex; mode=display">
\begin{array}{ll}\hline\textbf{Algorithm 5} & \text{DIT root}\\ 
\hline
\textbf{Require:} & A=[a_0,a_1,\ldots,a_{n-1}]\quad n=2^{x},x\in\mathbb{N} \quad \Phi_{rev} \\ 
\textbf{function} & \text{DIT}(A)\\  
& t=n\\ 
& \text{for}\quad m=1\quad\text{to}\quad n \quad\text{by}\quad m\\  
& \quad t=\frac{t}{2}\\
& \quad\text{for}\quad i=0\quad \text{to} \quad m-1 \\  
& \quad\quad j =2\cdot i\cdot t\\
& \quad\quad \varphi =\Phi_{rev}[m+i]\\
& \quad\quad\text{for}\quad k=0\quad\text{to} \quad t\\  
& \quad\quad\quad v=\varphi P[k+j+t]\\
& \quad\quad\quad u= P[k+j]\\
& \quad\quad\quad P[k+j]= u+v\\
& \quad\quad\quad P[k+j+t]= u-v\\
& \quad\quad\text{endfor}\\ 

& \quad\text{endfor}\\ 

& \text{endfor}\\  
& \text{return}\quad P\\
 \textbf{end function}
& \\ 
\hline 
& \end{array}</script><p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202407121417909.svg" alt="图10 n=8迭代DIT数据流图2" title="图10 n=8迭代DIT数据流图2">​</p>
<h3 id="1-4-快速数论变换（-NTT-）"><a href="#1-4-快速数论变换（-NTT-）" class="headerlink" title="1.4 快速数论变换（$NTT$）"></a>1.4 快速数论变换（$NTT$）</h3><p>$FFT$ 存一些问题。首先 FFT 是在复数域上的表示，而计算机系统中表示复数，需要比实数花费更多的资源，且复数运算也比实数运算更加复杂。此外 FFT 涉及大量的正余弦运算，对于精度有影响。于是我们期望在实数域内寻找类似单位根性质的数学概念。有限域上的原根满足相应的要求。</p>
<h4 id="1-4-1-数学基础"><a href="#1-4-1-数学基础" class="headerlink" title="1.4.1 数学基础"></a>1.4.1 数学基础</h4><h5 id="欧拉函数"><a href="#欧拉函数" class="headerlink" title="欧拉函数"></a>欧拉函数</h5><p>欧拉函数，即 $\varphi(n)$,表示的是小于等于 $n$ 且和 $n$ 互素的数的个数。当 n 是素数时 $\varphi(n)=n-1$。</p>
<h5 id="欧拉定理"><a href="#欧拉定理" class="headerlink" title="欧拉定理"></a>欧拉定理</h5><p>对于 $a \in \mathbb{Z}$ ,$m\in \mathbb{N}^*$,若 $\gcd(a,m)=1$,则 $a^{\varphi(m)} \equiv 1 \pmod{m}$。</p>
<h5 id="费马小定理"><a href="#费马小定理" class="headerlink" title="费马小定理"></a>费马小定理</h5><p>若 $p $ 为素数，$\gcd(a,p)=1$,则 $a^{p-1} \equiv 1 \pmod{p}$。</p>
<p>也可表达为，对于任意整数 $a $，有 $a^p \equiv a \pmod{p}$。</p>
<p>利用费马小定理求逆元:$a^{-1}=a^{p-2}$</p>
<h5 id="阶"><a href="#阶" class="headerlink" title="阶"></a>阶</h5><p>由欧拉定理可知，若 $\gcd(a,p)=1$，一定存在一个最小的正整数 $n$ 满足同余式 $a^n \equiv 1 \pmod{m}$。这个 $n$ 被称作 $a$ 模 $m$ 的阶记作 $\delta_m(a) $ 或者 $ord_m(a)$。具有以下性质：</p>
<p>性质 1：$a,a^2,\ldots,a^{\delta_m(a)}$ 模 $m $ 两两不同余，之后进入周期。</p>
<p>性质 2：若 $a^n \equiv 1 \pmod{m}$,则 $\delta_m(a)|n$。可以推导出若 $a^p \equiv a^q \pmod{m} $，则有 $p \equiv q \pmod{\delta_m(a)}$。</p>
<h5 id="原根"><a href="#原根" class="headerlink" title="原根"></a>原根</h5><p>给定  $n \in \mathbb{N}^*$ ，$g \in \mathbb{Z}$，满足  $\gcd(g, m) = 1$，且  $\delta_m(g) = \varphi(m)$ ，则称  $g$  为模 $m$ 的原根。</p>
<p>即 $g$ 满足 $\delta_m(g)=| \mathbb{Z}_m^* |=\varphi(m)$ 。当 $m$ 是素数时，我们有 $g^i \mod m$，$0&lt;i&lt;m$ 的结果互不相同</p>
<p>原根个数：若一个数 $m$ 有原根，则它原根的个数为 $\varphi(\varphi(m))$。</p>
<p>原根存在定理：一个数 $m$ 存在原根当且仅当 $m=2,4,p^a,2p^a$ ，其中 $p$ 为奇素数，$a\in \mathbb{N}^*$。</p>
<h5 id="原根的性质"><a href="#原根的性质" class="headerlink" title="原根的性质"></a>原根的性质</h5><p>原根具有以下性质，不难看与单位根具有类似的性质。所以可以用于替代单位根，用于简化 $DFT$ 计算。</p>
<p>不重性：$\forall 0 \leq i &lt; j &lt; \varphi(p),\ g^i \not\equiv g^j \pmod{p} $</p>
<p>折半性：定义 $g_n = g^{\frac{\delta_p(g)}{n}} \equiv g^{\frac{p-1}{n}}$,$g_n^k = (g_n)^k$ 则 $g_{an}^{ak} \equiv g_n^k \pmod{p}$。</p>
<p>对称性：$g_{2n}^{k+n} \equiv - g_{2n}^k \pmod{p}$</p>
<p>求和性：$\sum_{i=0}^{n-1} (g_n)^{ki} \equiv n[k=0] \pmod{p} $，$k=0$ 为真 $[k=0]=1$,否则为 $0$。</p>
<h5 id="原根与模数的选择"><a href="#原根与模数的选择" class="headerlink" title="原根与模数的选择"></a>原根与模数的选择</h5><p>为了实现多次二分，模数 $p$ 应选可以拆分为 $q\times 2^k +1$ 的素数,$q$ 为奇素数，$k$ 为整数,$2^k$ 模数的阶，也就是原根的最大数量。可以看下表的例子。</p>
<script type="math/tex; mode=display">
\text{表 1：原根和模数的相关数据}\\ \begin{array}{cccc} \hline \text{原根 } g & \text{模数 } p & \text{分解 } p & \text{模数的阶} \\ \hline 3 & 469762049 & 7 \times 2^{26} + 1 & 2^{26} \\ 3 & 998244353 & 119 \times 2^{23} + 1 & 2^{23} \\ 3 & 2281701377 & 17 \times 2^{27} + 1 & 2^{27} \\ \hline \end{array}</script><h4 id="1-4-2-NTT-的递归实现"><a href="#1-4-2-NTT-的递归实现" class="headerlink" title="1.4.2 $NTT$ 的递归实现"></a>1.4.2 $NTT$ 的递归实现</h4><p>将原根带入公式（7）得：</p>
<script type="math/tex; mode=display">
\begin{align}
P(g_n^k)=P_e((g_n^k)^2)+{g_n^k}P_o((g_n^k)^2)\mod p \quad k \in[ 0,n)
\end{align}</script><p>根据消去引理推导出得对称性以及折半引理对公式（13）进行化简。取 $k \in[0,\frac{n}{2})$ 。</p>
<script type="math/tex; mode=display">
\begin{align*}
P(g_{n}^{k})&=P_{e}((g_{n}^{k})^2)+{g_{n}^{k}}P_{o}((g_{n}^{k})^2) \mod p\\
 & =P_{e}(g_{\frac{n}{2}}^{k})+{g_{n}^{k}}P_{o}(g_{\frac{n}{2}}^{k}) \mod p\\ 

 \end{align*}</script><script type="math/tex; mode=display">
\begin{align*}
P(g_{n}^{k+m})&=P_{e}((g_{n}^{k+m})^2)+g_{n}^{k+m}P_{o}((g_{n}^{k+m})^2) \mod p\\
 & =P_{e}(g_{\frac{n}{2}}^{k+m})+g_{n}^{k+m}P_{o}(g_{\frac{n}{2}}^{k+m}) \mod p\\ 
& =P_{e}(-g_{\frac{n}{2}}^{k})-g_{n}^{k}P_{o}(-g_{\frac{n}{2}}^{k}) \mod p\\
& =P_{e}(g_{\frac{n}{2}}^{k})-g_{n}^{k}P_{o}(g_{\frac{n}{2}}^{k}) \mod p
 \end{align*}</script><p>简化为：</p>
<script type="math/tex; mode=display">
P(g_{n}^{k})=P_{e}(g_{\frac{n}{2}}^{k})+{g_{n}^{k}}P_{o}(g_{\frac{n}{2}}^{k})\\
P(g_{n}^{k+m})=P_{e}(g_{\frac{n}{2}}^{k})-g_{n}^{k}P_{o}(g_{\frac{n}{2}}^{k})</script><p>现在给出递归版本得算法,不难发现除了将单位根替换为原根，增加模运算，以及增加了参数 ，原根 $g$，模数 $p $ 外与 $FFT$ 并无太大区别。</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\hline
\textbf{Algorithm 6} & \text{ Recursion Number Theoretic Transform (NTT)}\\ 
\hline
\textbf{Require:} & A=[a_0,a_1,\ldots,a_{n-1}],\quad n=2^{k},\quad g ,\quad p \\
\textbf{function} & \text{NTT\_R}(A, g, p)\\ 

&n\leftarrow \text{len}(A)\\
&\text{if}\quad n==1 \\
&\quad \text{return}\quad A\\
&\text{endif}\\
&g_n \leftarrow g^{\frac{p-1}{n}} \pmod p\\
&A_e\leftarrow [a_0,a_2,\ldots,a_{n-2}]\\
&A_o\leftarrow [a_1,a_3,\ldots,a_{n-1}]\\
&Y_e\leftarrow  \text{NTT\_R}(A_e, g_n^2, p)\\
&Y_o\leftarrow  \text{NTT\_R}(A_o, g_n^2, p)\\
& \text{for} \quad k \quad \text{from} \quad 0 \quad \text{to} \quad n/2-1\\
&\quad Y[k]= (Y_e[k] + g_n^k Y_o[k]) \pmod p\\
&\quad Y[k+n/2]= (Y_e[k] - g_n^k Y_o[k]) \pmod p\\
&\text{end for}\\
&\text{return} \quad Y \\
\textbf{end function} & \\ 
\hline & 
\end{array}</script><blockquote>
<p>注意NTT里的$g^{-1}$是取逆元操作，在计算$INTT$时请注意。</p>
</blockquote>
<h4 id="1-4-3-NTT-的迭代实现"><a href="#1-4-3-NTT-的迭代实现" class="headerlink" title="1.4.3 $NTT$ 的迭代实现"></a>1.4.3 $NTT$ 的迭代实现</h4><p>$NTT$ 的迭代实现同理，因此不再赘述，直接给出相应的算法。</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\hline
\textbf{Algorithm 7} & \text{Iteration NTT}\\ 
\hline
\textbf{Require:} & A=[a_0,a_1,\ldots,a_{n-1}],\ n=2^{k},\quad  g_n, \quad p\\ 
\textbf{function} & \text{NTT\_I}(A, g_n, p)\\  
& n \leftarrow \text{len}(A)\\  
& P \leftarrow \text{BitReverseCopy}(A)\\
& \text{for}\ s=1\ \text{to}\ \log{n}\\  
& \quad m=2^s\\
& \quad g_m=g_n^{\frac{n}{m}} \pmod p\\
& \quad \text{for}\ k=0\ \text{to}\ n-1\ \text{by}\ m\\  
& \quad\quad \varphi=\hat{1}\\
& \quad\quad \text{for}\ j=0\ \text{to}\ \frac{m}{2}-1\\  
& \quad\quad\quad t=\varphi P[k+j+\frac{m}{2}] \pmod p\\
& \quad\quad\quad u= P[k+j] \pmod p\\
& \quad\quad\quad P[k+j]= (u+t) \pmod p\\
& \quad\quad\quad P[k+j+\frac{m}{2}]= (u-t) \pmod p\\
& \quad\quad\quad \varphi=(\varphi \cdot g_m) \pmod p\\
& \quad\quad \text{endfor}\\ 
& \quad \text{endfor}\\ 
& \text{endfor}\\  
& \text{return}\ P\\
\textbf{end function} & \\ 
\hline
& 
\end{array}</script><h3 id="1-5-矩阵DFT​算法"><a href="#1-5-矩阵DFT​算法" class="headerlink" title="1.5  矩阵DFT​算法"></a>1.5  矩阵DFT​算法</h3><p>现在介绍另外一种算法，这种算法提高缓存命中率，从而提高执行效率。这种算法是将输入看作是一个行优先的矩阵进行计算，请注意对于NTT来说实际的输入指的是系数$a_i$。</p>
<p>如果 $n=R\cdot C$ 我们可以用 $i_r\in[0,R)$ 和 $i_c \in [0,C)$ 重写$i=i_r\cdot C+i_c$ 。这将创建一个对应 $[0,n) \backsimeq[0,R) \times[0,C)$。另一种对应关系是 $k=k_r+k_c\cdot R$ ,注意这里输出的顺序已经变成了列优先了。将$i$和$k$带入下式。</p>
<script type="math/tex; mode=display">
P_{k}=P(\omega_{n}^{k})=\sum_{i=0}^{n-1}a_{i}\omega_{n}^{ki}\quad k=0,1,\ldots,n-1</script><p>需要提前明确的一点是这里公式中$\omega$既可以是原根又可以是单位根,不过为了统一表示省去了原根的取模操作。替换可得：</p>
<script type="math/tex; mode=display">
\begin{align}P_{k_{r}+k_{c}\cdot R}=\sum_{i_{c}=0}^{C-1}\sum_{i_{r}=0}^{R-1}a_{i_{r}\cdot C+i_{c}}\cdot\omega_{R\cdot C}^{(k_{r}+k_{c}\cdot R)(i_{r}\cdot C+i_{c})}\end{align}</script><p>将$\omega$的幂次展开：</p>
<script type="math/tex; mode=display">
\begin{align*}
\omega_{R\cdot C}^{(k_{r}+k_{c}\cdot R)(i_{r}\cdot C+i_{c})}&=\omega_{R\cdot C}^{i_{c}k_{r}+i_{c}k_{c}\cdot R+i_{r}k_{r}\cdot C+i_{r}k_{c}\cdot RC} \\&=\omega_{R\cdot C}^{i_{c}k_{r}}\cdot \omega_{R\cdot C}^{i_{c}k_{c}\cdot R}\cdot \omega_{R\cdot C}^{i_{r}k_{r}\cdot C}\cdot \omega_{R\cdot C}^{i_{r}k_{c}\cdot RC}
\end{align*}</script><p>根据原根的折半性质或者单位根的消去引理$\omega_{an}^{ak}=\omega_n^k$，可得：</p>
<script type="math/tex; mode=display">
\omega_{R\cdot C}^{i_{c}k_{r}}\cdot \omega_{R\cdot C}^{i_{c}k_{c}\cdot R}\cdot \omega_{R\cdot C}^{i_{r}k_{r}\cdot C}\cdot \omega_{R\cdot C}^{i_{r}k_{c}\cdot RC}=\omega_{n}^{i_{c}k_{r}}\cdot \omega_{C}^{i_{c}k_{c}}\cdot \omega_{R}^{i_{r}k_{r}}\cdot1</script><p>则公式(14)变为如下形式：</p>
<script type="math/tex; mode=display">
P_{k_{r}+k_{c}\cdot R}=\sum_{i_{c}=0}^{C-1}\sum_{i_{r}=0}^{R-1}a_{i_{r}\cdot C+i_{c}}\cdot \omega_{n}^{i_{c}k_{r}}\cdot \omega_{C}^{i_{c}k_{c}}\cdot \omega_{R}^{i_{r}k_{r}}</script><p>添加一些括号来确定运算顺序则变成了：</p>
<script type="math/tex; mode=display">
P_{k_{r}+k_{c}\cdot R}=\sum_{i_{c}=0}^{C-1}\Bigg[\bigg(\sum_{i_{r}=0}^{R-1}a_{i_{r}\cdot C+i_{c}}\cdot \omega_{R}^{i_{r}k_{r}}\bigg)\omega_{n}^{i_{c}k_{r}} \Bigg] \omega_{C}^{i_{c}k_{c}}</script><p>首先对输入a子序列进行长度为$R$的$DFT$操作，然后对结果乘上旋转因子，最后进行长度为$C$的$DFT$操作。这么看可能不直观，我们将输入写成一个$R \times C$大小的矩阵：</p>
<script type="math/tex; mode=display">
a
=
\left[ \begin{array}{ccccc}
a_0 & a_1 & a_2 &\ldots & a_{C-1} \\
a_C & a_{C+1} & a_{C+2} & \ldots & a_{C+(C-1)} \\
a_{2C} & a_{2C+1} & a_{2C+2} & \ldots & a_{2C+(C-1)} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{(R-1)C} & a_{(R-1)C+1} & a_{(R-1)C+2}& \ldots & a_{(R-1)C+(C-1)}
\end{array} \right]</script><p>先对对所有列进行DFT运算，然后所有元素乘上相应的转换因子，最后对所有行进行DFT运算。下面是转换转换因子矩阵$T$，注意转换因子矩阵与对列进行DFT的结果进行的是逐点相乘。因为输出是列优先排序，所以需要对结果进行一个转置，从而使得输入与输出保持同一顺序。</p>
<script type="math/tex; mode=display">
T=\left[\begin{array}{ccccc}
1 & 1 & 1 & \ldots & 1\\
1 & \omega &\omega^2 & \ldots & \omega^{C-1}\\
1 & \omega ^2 & \omega ^4 &\ldots & \omega^{2(C-1)}\\
\vdots & \vdots& \vdots & \ddots & \vdots\\ 
1 & \omega^{R-1}&\omega^{2(R-1)} & \ldots & \omega^{(C-1)(R-1)}
\end{array}\right]</script><h5 id="Four-step-DFT"><a href="#Four-step-DFT" class="headerlink" title="Four-step DFT"></a>Four-step DFT</h5><p>对上面的算法进行一个总结就是所谓的四步DFT算法,$[R \times C]$，表示为大小为$R\times C$的行优先矩阵。</p>
<blockquote>
<p>$IDFT*$是省略乘上$n^{-1}$的$IDFT$，所以最后需要补上$n^{-1}$。</p>
</blockquote>
<p><strong>DFT:</strong></p>
<ol>
<li>$[R \times C]$,对每一列进行长度为$R$的$DFT$运算。</li>
<li>$[R \times C]$,所有元素乘上对应的转换因子$\omega^{ik}$。</li>
<li>$[R \times C]$,对每一行进行长度为$C$的$DFT$运算。</li>
<li>$[R \times C]$,将矩阵进行转置。</li>
</ol>
<p><strong>IDFT*：</strong></p>
<ol>
<li>$[C \times R]$,将矩阵进行转置。</li>
<li>$[R \times C]$,对每一行进行长度为$C$的$IDFT*$运算。</li>
<li>$[R \times C]$,所有元素乘上对应的转换因子$\omega^{-ik}$。</li>
<li>$[R \times C]$,对每一列进行长度为$R$的$IDFT*$运算。</li>
</ol>
<h5 id="Six-step-DFT"><a href="#Six-step-DFT" class="headerlink" title="Six-step DFT"></a>Six-step DFT</h5><p>对列进行操作，无法读取连续的内存会影响计算效率，可以增加转置操作，于是获得六步DFT算法：</p>
<p><strong>DFT:</strong></p>
<ol>
<li>$[R \times C]$,将矩阵进行转置。</li>
<li>$[C \times R]$,对每一行进行长度为$R$的$DFT$运算。</li>
<li>$[C \times R]$,将矩阵进行转置。</li>
<li>$[R \times C]$,所有元素乘上对应的转换因子$\omega^{ik}$。</li>
<li>$[R \times C]$,对每一行进行长度为$C$的$DFT$运算。</li>
<li>$[R \times C]$,将矩阵进行转置。</li>
</ol>
<p><strong>IDFT*:</strong></p>
<ol>
<li>$[C \times R]$,将矩阵进行转置。</li>
<li>$[R \times C]$,对每一行进行长度为$C$的$IDFT*$运算。</li>
<li>$[R \times C]$,所有元素乘上对应的转换因子$\omega^{-ik}$。</li>
<li>$[R \times C]$,将矩阵进行转置。</li>
<li>$[C \times R]$,对每一行进行长度为$R$的$IDFT*$运算。</li>
<li>$[C \times R]$,将矩阵进行转置。</li>
</ol>
<h2 id="2-NTT-设计"><a href="#2-NTT-设计" class="headerlink" title="2 NTT 设计"></a>2 NTT 设计</h2><p>本节主要是介绍对NTT的设计，例如模约简方案、转置优化以及预计算。最后探讨有哪些可以进行的优化。</p>
<h3 id="2-1-模约简"><a href="#2-1-模约简" class="headerlink" title="2.1 模约简"></a>2.1 模约简</h3><h4 id="2-1-1-朴素方案"><a href="#2-1-1-朴素方案" class="headerlink" title="2.1.1 朴素方案"></a>2.1.1 朴素方案</h4><p>在模数约简的朴素方法中，如果硬件支持的话，会使用一个硬件指令将两个字（word）长度的被除数除以一个字长度的除数，得到一个字长度的商和一个字长度的余数。如果硬件不支持这种指令，那么就需要在软件中模拟这种指令。</p>
<p>这样的指令在x86和x86-64架构中是存在的。对于软件模拟，GNU GCC和Clang编译器在32位平台上提供了uint64_t类型，在64位平台上提供了unsigned __int128类型，并且这些类型都支持除法操作。</p>
<h4 id="2-1-2-Barrett-约简"><a href="#2-1-2-Barrett-约简" class="headerlink" title="2.1.2 Barrett 约简"></a>2.1.2 Barrett 约简</h4><p>巴雷特约简的思路很简单，将计算$z =a \mod p$，转换为$z=a- tp,t=\lfloor ap^{-1}\rfloor$ 。于是问题就从模运算转换为了求取$p^{-1}$的近似值,也就是$t$的近似值。</p>
<p>对$t$进行进行变换：</p>
<script type="math/tex; mode=display">
t=\lfloor \frac{a}{p} \rfloor=\lfloor \frac{\frac{a}{b^{k-1}}\frac{b^{2k}}{p}}{b^{k+1}} \rfloor</script><p>其中$b$是基底，计算机系统中通常使用二进制表示，即$b=2$，$k$是模数相对于基底的位宽$k=\log_{b}p+1$，之所以是$b^{2k}$是因为通常运用模约简的场景是模乘，因此$a\in[0,p^2)$。经过变换，我们发现分离出来一个一个仅和模数有关的量:$\alpha = \frac{b^{2k}}{p}$，这意味着对同一模数的约简可以提前计算$\alpha$，其他部分可以通过右移和乘法完成，乘法运算效率显著高于除法运算，位移效率更快，计算速度提升了很多。</p>
<p>为了避免浮点数计算，令$\beta=\lfloor \frac{b^{2k}}{p} \rfloor$,替换掉$\alpha$,得到$t$的近似$\hat{t}$：</p>
<script type="math/tex; mode=display">
\hat{t}=\lfloor \frac{\lfloor\frac{a}{b^{k-1}}\rfloor \beta}{b^{k+1}} \rfloor=\lfloor \frac{\lfloor\frac{a}{b^{k-1}}\rfloor \lfloor \frac{b^{2k}}{p} \rfloor}{b^{k+1}} \rfloor</script><p>现在考虑$t$与$\hat{t}$的误差：</p>
<script type="math/tex; mode=display">
\lambda = \frac{a}{b^{k-1}} - \lfloor \frac{a}{b^{k-1}} \rfloor</script><script type="math/tex; mode=display">
\mu = \frac{b^{2k}}{p} - \lfloor \frac{b^{2k}}{p} \rfloor</script><p>且$0 \le \lambda \lt 1$,$0 \le \mu \lt 1$，此外还有：</p>
<script type="math/tex; mode=display">
t=\lfloor\frac{a}{b^{k-1}}\cdot\frac{b^{2k}}{p}\cdot\frac{1}{b^{k+1}}\rfloor=\lfloor\frac{(\lfloor\frac{a}{b^{k-1}}\rfloor+\lambda)(\lfloor\frac{b^{2k}}{p}\rfloor+\mu)}{b^{k+1}}\rfloor\leq\lfloor\hat{t}+\frac{\lfloor\frac{a}{b^{k-1}}\rfloor+\lfloor\frac{b^{2k}}{p}\rfloor+1}{b^{k+1}}\rfloor</script><p>因为$a\lt b^{2k}$,所以$\lfloor \frac{a}{b^{k-1}} \rfloor \leq b^{k+1}-1$；又因为$p \ge b^{k-1}$,所以$\lfloor \frac{b^{2k}}{p}\rfloor \leq b^{k+1}$。对上面不等式放缩：</p>
<script type="math/tex; mode=display">
t\leq\lfloor\hat{t}+\frac{b^{k+1}-1+b^{k+1}+1}{b^{k+1}}\rfloor=\lfloor\hat{t}+2\rfloor</script><p>又因为$\hat{t} \le t$,所以可得：</p>
<script type="math/tex; mode=display">
t-2 \le \hat{t} \le t</script><p>近似性不错，进一步可得：</p>
<script type="math/tex; mode=display">
0 \lt a - \hat{t}p \le a - (t-2)p=a-tp+2p</script><p>又因为$a-tp=z\lt p$，所以：</p>
<script type="math/tex; mode=display">
0 \lt a - \hat{t}p \lt 3p</script><p>不难看出使用近似方法得出得值有可能比p大，但是通过最多两次减法就可以修正误差，下面给出完整的算法：</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\hline
\textbf{Algorithm 8} & \text{Barrett 约简}\\ 
\hline
\textbf{Require:} & a\quad \beta=\lfloor \frac{b^{2k}}{p} \rfloor\quad p\\ 
\textbf{function} & Barrett(a,\beta,p)\\  
& \hat{t} \leftarrow \lfloor \frac{\lfloor\frac{a}{b^{k-1}}\rfloor \beta}{b^{k+1}} \rfloor\\  
& z_1 \leftarrow a \mod b^{k+1}\\
& z_2 \leftarrow \hat{t}\cdot p \mod b^{k+1}\\
& z=z_1-z_2\\
& \text{if} \ z \lt 0\\  
& \quad z=z+b^{k+1}\\
& \text{endif}\\  
& \text{while} \ z \ge p\\  
& \quad z=z-p\\
& \text{endwhile}\\  
& \text{return}\ z\\
\textbf{end function} & \\ 
\hline
& 
\end{array}</script><p>$z_1$和$z_2$的运算可以通过位与操作直接去掉k位的高位即可，简化了计算。下面给出$\beta$的算法：</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\hline
\textbf{Algorithm 9} & \text{计算} \beta\\ 
\hline
\textbf{Require:} & p\quad k \quad b\\ 
\textbf{function} & get\beta(p,k,b)\\  
& \beta \leftarrow b^k\\  
& \text{repeat} \\  
& \quad s \leftarrow \beta \\
& \quad \beta \leftarrow 2\beta -\lfloor\frac{ p\lfloor \frac{\beta^2}{b^k} \rfloor }{b^k}   \rfloor\\
& \text{until} \ \beta \le s  \\  
& t \leftarrow b^{2k}-p\beta\\
& \text{while} \ t \lt 0\\  
& \quad \beta \leftarrow \beta -1\\ 
& \quad t \leftarrow t+p\\ 
& \text{endwhile}\\  
& \text{return}\ \beta\\
\textbf{end function}  \\
\hline
&\end{array}</script><h4 id="2-1-3-Montgomery-约简"><a href="#2-1-3-Montgomery-约简" class="headerlink" title="2.1.3  Montgomery 约简"></a>2.1.3  Montgomery 约简</h4><p>蒙哥马利模乘约减的思路是通过变换，将需要取模的数控制到很小的范围（$[0,(p-1)^2] \rightarrow [0,2p-1]$ ）然后通过少量减法获取最后结果。并通过位运算简化计算，例如：右移除法、位与取模。</p>
<h5 id="蒙哥马利约简"><a href="#蒙哥马利约简" class="headerlink" title="蒙哥马利约简"></a>蒙哥马利约简</h5><p>对于$\forall t \in \mathbb{Z}$且满足$a &lt; r p$，$r\gt p$，$\gcd(r,p)=1$ 。$p$是以$b$为基底,长度为$k$的整数，则r的取值为$b^k$，计算机中$b$为$2$，显然$r\gt p$。但是只有当$\gcd(b,p)=1$时才满足$\gcd(r,p)=1$，之前提到的格式是满足条件的。</p>
<p>由于$r$和$p$互素，所以存在$r’,p’  \in[0,p)$使得下式成立，$r’$是$r$在$p$下的逆元 ，$p’$是$p$在$r$下的负逆元。</p>
<script type="math/tex; mode=display">
rr'-pp'=1</script><p>于是：</p>
<script type="math/tex; mode=display">
\begin{align*}
ar' &=ar'\frac{r}{r} \\
&=\frac{arr'}{r} \\
&=\frac{a(1+pp')}{r}  \\
&=\frac{a+app'}{r}  \\
&=\frac{a+(\lfloor \frac{ap'}{r} \rfloor r+(ap' \bmod r))p}{r}   \\
&=\frac{a+(ap' \bmod r)p}{r}+\lfloor \frac{ap'}{r} \rfloor p   \\
&\equiv \frac{a+(ap' \bmod r)p}{r} &\pmod{p} \\
&\equiv \frac{a+((a\bmod r)p' \mod r)p}{r} &\pmod{p} \\
\end{align*}</script><p>其中$\lfloor \frac{ap’}{r} \rfloor r+(ap’ \bmod r)$是将$ap’$表达为成商乘上除数加余数的形式。上面的推导过程将对$ar’$模$p$转换为了对$\frac{a+((a\bmod r)p’ \bmod r)p}{r}$模$p$操作。显然$((a\mod r)p’ \mod r)p \lt rp$又因为$a &lt; r p$所以可得下面的关系，不难发现最多只需一次减法就可以完成取模操作，其中模$r$可以通过位与运算，除$r$可以通过位右移运算完成，之所以做两次模$r$运算是为了降低乘法位宽。</p>
<script type="math/tex; mode=display">
\frac{t+((t\mod r)p' \mod r)p}{r} \lt 2p</script><p>下面给出相应的算法：</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\hline
\textbf{Algorithm 10} & \text{蒙哥马利约简} \\ 
\hline
\textbf{Require:} & p\quad r \quad p' \quad (pp' \equiv-1\mod r )\quad \\ 
\textbf{function} & REDC(a)\\  
& m \leftarrow (a\bmod r)p' \bmod r \\
& t \leftarrow (a+mp) \text{div }r \\
& \text{if} \ t \gt p\\  
& \quad  \quad \text{return}\ t-p\\
& \text{else} \\  
& \quad  \quad \text{return}\ t\\
& \text{endif}\\  
\textbf{end function}  \\
\hline
&\end{array}</script><h5 id="蒙哥马利域"><a href="#蒙哥马利域" class="headerlink" title="蒙哥马利域"></a>蒙哥马利域</h5><p>由上面蒙哥马利约简的过程不难发现实际是对$xR^{-1}$(这里的$R^{-1}$就是上面提到的$r’$,只是为了方便区分)进行约简，所以在使用蒙哥马利约简时，首先需要转换到蒙哥马利域中，蒙哥马利域中的形式表示为$\bar{x}$，转换入蒙哥马利域的方式：</p>
<script type="math/tex; mode=display">
\bar{x} =x \cdot R \pmod p</script><p>显然，转入蒙哥马利域的成本是高昂的，只有在蒙哥马利域内计算值得时才会使用蒙哥马利约简，在蒙哥马利域中加法和减法（结合律）不受影响。</p>
<script type="math/tex; mode=display">
\bar{x}+\bar{y} = xR+yR=(x+y)R = \overline{x+y} \pmod p</script><p>但是蒙哥马利域上的乘法是不正确的，这里蒙哥马利域中的乘法用 $\times$表示，正常的乘法用$\cdot$表示。我们期望的结果是：</p>
<script type="math/tex; mode=display">
\bar{x}\times\bar{y}=\overline{x\cdot y}=(x\cdot y) R  \pmod{p}</script><p>但是实际上如果直接相乘获得结果如下：</p>
<script type="math/tex; mode=display">
\bar{x}\cdot\bar{y}=xR\cdot yR=(x\cdot y) RR  \pmod{p}</script><p>蒙哥马利域上的乘法定义如下：</p>
<script type="math/tex; mode=display">
\bar{x}\times\bar{y}=(\bar{x}\cdot \bar{y}) R^{-1}\mod{p} =(x\cdot y) R \mod{p}=RECD(\bar{x}\cdot \bar{y})</script><p>最后就是蒙哥马利域的转出，转出如下所示。</p>
<script type="math/tex; mode=display">
x = \bar{x}\cdot R^{-1} \mod{p}=RECD(\bar{x})</script><h5 id="蒙哥马利模乘"><a href="#蒙哥马利模乘" class="headerlink" title="蒙哥马利模乘"></a>蒙哥马利模乘</h5><p>在执行蒙哥马利乘法本身开销并不高，但是需要完成一些提前计算，这些计算的开销较高。</p>
<ul>
<li>蒙哥马利域的转入</li>
<li>$p’$的计算</li>
<li>蒙哥马利域的转出</li>
</ul>
<p>在约简过程中已经完成了蒙哥马利域的转出。p’的计算可以通过扩展欧几里得算法获得。对于转入还存在另一种策略：</p>
<script type="math/tex; mode=display">
\bar{x} =x \cdot R \mod{p} =x \times R^2  =REDC(x\cdot (R^2 \mod p))</script><p>第二种策略策略是省去模p的运算，但是失去了乘R位运算优势，取而代之的是乘上$R^2 \mod p$，可以提前计算，并需要执行约简操作，因为取模开销很大，大概率第二种策略效率更高一点。于是蒙哥马利模乘可以表示如下：</p>
<script type="math/tex; mode=display">
\begin{align*}
z&=x\cdot y \mod p=REDC(REDC(\bar{x}\cdot \bar{y}))\\
\bar{x}&=REDC(x\cdot (RR \bmod p))\\
\bar{y}&=REDC(y\cdot (RR \bmod p))\\
\end{align*}</script><h4 id="2-1-4-小结"><a href="#2-1-4-小结" class="headerlink" title="2.1.4  小结"></a>2.1.4  小结</h4><p>上面介绍了三种模约简方法，模约简主要用于模乘中，这里主要对比分析一下巴雷特和蒙哥马利，至于朴素方案效率太低就不分析了。在FPGA上当一次处理位宽大于$16$-bit时蒙哥马利更具有优势，反之巴列特算法有优势。对CPU或者GPU版本没有看到相应的资料，不过从两种算法从时间复杂度上是类似的。连续模乘可能蒙哥马利的优势更大。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202402282053440.png" alt="图 11 FPGA蒙哥马利与巴雷特对比" title="图 11 FPGA蒙哥马利与巴雷特对比">​</p>
<h3 id="2-2-root-power-预计算"><a href="#2-2-root-power-预计算" class="headerlink" title="2.2  root power 预计算"></a>2.2  root power 预计算</h3><p>算法3中需要反复执行$\varphi=\varphi \omega_m$，这里的m是当前合并轮次下每个单元的数据规模或者是蝶形运算的步长，$s $ 可以看作是当前合并轮数，$n$是输入规模，$l$是总的轮数。$\omega_m=\omega^{2^{n-s}}$,$s=\log_2m$。一共具有两种预计算方案</p>
<p><strong>方案一：</strong> 预计算$\omega$的幂到一个root power表$t$中，即$t[i]=\omega^i ,i\in[0,\frac{n}{2})$。对于给定的$j$和$m=2^s$，我们可以表示旋转因子$\varphi =t[j\cdot 2^{\alpha }], \alpha =n-s,j\in [0,2^{s-1})$。</p>
<p><strong>方案二：</strong> 计算每个粒度$s\in[1,n]$,单独的root power表：</p>
<script type="math/tex; mode=display">
T_s[i]=t[i\cdot 2^{n-s}]=(\omega^{2^{n-s}})^i, i\in [0,2^{s-1})</script><p>记$T_n=t$，$\sum_{s=1}^n|T_s|=\sum_{s=1}^n 2^{s-1}=2^n-1$。对于给定的$j$和$m=2^s$，我们可以表示旋转因子$\varphi =T[j]$。然后我们将将所有的$T_s$组成一个大的表$T$。</p>
<script type="math/tex; mode=display">
T_s[i]=T[(2^0+2^1+2^2+ \cdots +2^{s-2})+i]=T[2^{s-1}-1+i]</script><p>对于给定的$j$和$m=2^s$，我们可以表示旋转因子$\varphi =T[\beta + j],\beta=2^{s-1}-1=\frac{m}{2}-1$。</p>
<p>两种方式$T[\beta+j]$ 和$t[j \cdot 2^\alpha ]$，内层索引都是相同的，$\alpha$ 和 $\beta$表示循环中不变的表达式，在循环开始前计算一次。但是$T$，可以使用指针指向$T[\beta]$,</p>
<p>一步解引用。而$t$需要先位移后解引用。</p>
<p><strong>Four-step算法：</strong> 因为要用到所有的幂次，所以直接预计算所有的幂次，构建幂次表$T_<em>$即可。需要设计合适的索引。我的想法是利用折半引理，在对行或是对列的NTT中索引格式只需要在方案二的基础上进行细微改动即可，只需要乘上总规模$N$除当前NTT规模$n$的商即可，$T_</em>[(\beta+j)\frac{N}{n}]=T_*[\beta \mu+j\mu]$,只是这种方法会使得方案本一步完成的解引用，需要两步而且增加的是开销较高的乘法。至于列运算结束后的旋转因子矩阵直接按照输入索引去查询即可，因为输入矩阵和旋转因子因子矩阵是一一对应的。</p>
<h3 id="2-3-转置优化"><a href="#2-3-转置优化" class="headerlink" title="2.3 转置优化"></a>2.3 转置优化</h3><p>矩阵的转置有两种方式一种是out-place,一种是in-place。前者需要申请一块同等大小的空间，从而完成转置，即空间复杂度$O(R\times C)$。后一种，空间复杂度远小于$O(R\times C)$。这里主要讨论in-place转置方案，对于方阵很简单只需要交换$<i,j>$与$<j,i>$处的元素即可。</p>
<p>下面讨论$n\times cn$形式的矩阵转置，为了方便表示不妨取$c=2$。将一个$n\times 2n$的矩阵$M$拆分成两个$n\times n$的方阵$A$和$B$:</p>
<script type="math/tex; mode=display">
M=[A \quad B]</script><p>则转置表达为：</p>
<script type="math/tex; mode=display">
M^T=[A \quad B]^T=
\begin{bmatrix}
A^T\\\
B^T
\end{bmatrix}</script><p>定义$\phi(M)$: </p>
<script type="math/tex; mode=display">
\phi(M)=[A^T\quad B^T]</script><p>现在将两个子矩阵$A^T$，$B^T$的行用向量表示：</p>
<script type="math/tex; mode=display">
\phi(M)=[A^T\quad B^T]=
\begin{bmatrix}
\alpha_1 & \beta_1\\\
\cdots &\cdots \\\
\alpha_n & \beta_n
\end{bmatrix}
\longleftrightarrow<\alpha_1,\beta_1,\alpha_2,\beta_2,\cdots,\alpha_n,\beta_n ></script><script type="math/tex; mode=display">
M^T=
\begin{bmatrix}
A^T\\\
B^T
\end{bmatrix}
=
\begin{bmatrix}
\alpha_1 \\\
\cdots \\\
\alpha_n \\\  
\beta_1 \\\
\cdots\\\  
\beta_n
\end{bmatrix}
\longleftrightarrow <\alpha_1,\alpha_2,\cdots,\alpha_n,\beta_1,\beta_2,\cdots,\beta_n></script><p>所以我们可以通过某种方法$\rho$重新排列$\phi(M)$的索引，使其等于$M^T=\rho \phi(M)$，对于索引$i$的目标位置$j$满足：</p>
<script type="math/tex; mode=display">
j=\rho (i)=n \cdot  (i \bmod 2) + (i / 2) \quad i\in[0,2n)</script><p>下面探究对于列排布能否实现同样的作用， 首先我们定义对方阵的行进行索引重排为$\rho_r$,对其列进行索引成排为$\rho_c$。很明显对于一个矩阵A,满足一下关系：</p>
<script type="math/tex; mode=display">
(\rho_cX)^T=\rho_rX^T</script><p>我们已经证明:</p>
<script type="math/tex; mode=display">
M^T=\rho_r \phi(M)</script><p>现在令$M=\rho_c N$,即可获得：</p>
<script type="math/tex; mode=display">
\rho_r \phi(\rho_cN)=(\rho_cN)^T</script><script type="math/tex; mode=display">
\rho_r \phi(\rho_cN)=\rho_r(N)^T</script><script type="math/tex; mode=display">
\phi(\rho_cN)=N^T</script><p>现在证明对列进行排布同样可以完成相应的操作，只不过要现在哎方阵转置前进行列排布。对列进行排布对那内存更友好，需要$O(2n)$的额外空间。</p>
<p>对于$cn\times n$形式的矩阵，只需要对列执行$\rho^{-1}$然后对方阵转置就行。</p>
<h3 id="2-4-可能的优化"><a href="#2-4-可能的优化" class="headerlink" title="2.4  可能的优化"></a>2.4  可能的优化</h3><h4 id="2-4-1-位逆序省略"><a href="#2-4-1-位逆序省略" class="headerlink" title="2.4.1 位逆序省略"></a>2.4.1 位逆序省略</h4><p>我们回到最开始，我们引入DFT是为了进行多项式乘法：</p>
<script type="math/tex; mode=display">
A(x)\cdot B(x)=IDFT(DFT(A)\cdot DFT(B))</script><p>如果使用$DIF$完成$DFT$，使用$DIT$完成$IDFT$，我们就可以省略$DIF$最后的位逆序，以及$DIT$最开始的位逆序，紧挨着的两个位逆序可以省略。</p>
<h4 id="2-4-2-省略转置"><a href="#2-4-2-省略转置" class="headerlink" title="2.4.2 省略转置"></a>2.4.2 省略转置</h4><p>矩阵算法省略转置的原理与位逆序省略的原理相同，如果连续做$DFT$和$IDFT$，我们可以省略$DFT$最后的转置以及$IDFT$最开始的转置。</p>
<h4 id="2-4-3-合并"><a href="#2-4-3-合并" class="headerlink" title="2.4.3 合并"></a>2.4.3 合并</h4><ol>
<li>可以将对列之后乘旋转因子的操作合并到对列操作或者对行操作中，这样可以减少内存读写的次数。</li>
<li>对于$IDFT$可以将乘以$n^{-1}$,合并到四步$IDFT*$中，例如乘旋转因子的过程中。</li>
</ol>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1]七海. 基础知识：FFT - 简单入门[EB/OL]//七海の参考書. (2021-03-29)[2024-01-21]. <a href="https://shiraha.cn/2021/The-concept-of-fft-introducing-edition/">https://shiraha.cn/2021/The-concept-of-fft-introducing-edition/</a>.</p>
<p>[2]快速数论变换（NTT）及蝴蝶操作构造详解[EB/OL]//知乎专栏. [2024-01-21]. <a href="https://zhuanlan.zhihu.com/p/80297169">https://zhuanlan.zhihu.com/p/80297169</a>.</p>
<p>[3]Frigo M, Leiserson C E, Prokop H, et al. Cache-oblivious algorithms[J]. ACM Transactions on Algorithms (TALG), 2012, 8(1): 1-22. <a href="https://doi.org/10.1145/2071379.2071383">https://doi.org/10.1145/2071379.2071383</a>.</p>
<p>[4]LESAVOUREY A, NEGRE C, PLANTARD T. Efficient Randomized Regular Modular Exponentiation using Combined Montgomery and Barrett Multiplications[C/OL]//ICETE: International Joint Conference on e-Business and Telecommunications: 4 [SECRYPT]. Lisbon, Portugal, 2016: 368-375[2024-02-28]. <a href="https://hal.science/hal-01330898">https://hal.science/hal-01330898</a>. DOI:<a href="https://doi.org/10.5220/0005998503680375">10.5220/0005998503680375</a>.</p>
<p>[5]Finite Field Implementations[Z/OL]. [2024-01-26]. <a href="https://docs.google.com/presentation/d/1I5QS58LtA3iiiPiVHHcN7oufCoo8sIDh9UvnJHWjA2Q">https://docs.google.com/presentation/d/1I5QS58LtA3iiiPiVHHcN7oufCoo8sIDh9UvnJHWjA2Q</a>.</p>
<p>[6]RISC ZERO. Finite Field Implementations: Barrett &amp; Montgomery[Z/OL]. (2023-02-17)[2024-01-26]. <a href="https://www.youtube.com/watch?v=hUl8ZB6hpUM">https://www.youtube.com/watch?v=hUl8ZB6hpUM</a>.</p>
<p>[7]AGARWAL R C, COOLEY J W. Fourier transform and convolution subroutines for the IBM 3090 Vector Facility[J/OL]. IBM Journal of Research and Development, 1986, 30(2): 145-161. DOI:<a href="https://doi.org/10.1147/rd.302.0145">10.1147/rd.302.0145</a>.</p>
<p>[8]董晓算法. G41 快速傅里叶变换 FFT算法 多项式乘法_哔哩哔哩_bilibili[EB/OL]. [2024-01-21]. <a href="https://www.bilibili.com/video/BV1Le4y1V78D/">https://www.bilibili.com/video/BV1Le4y1V78D/</a>.</p>
<p>[9]董晓算法. G43 快速数论变换 NTT算法_哔哩哔哩_bilibili[EB/OL]. [2024-01-21]. <a href="https://www.bilibili.com/video/BV1a3411Z7vL/">https://www.bilibili.com/video/BV1a3411Z7vL/</a>.</p>
<p>[10]HEIDEAN M, JOHNSON D, BURRUS C. Gauss and the history of the fast fourier transform[J/OL]. IEEE ASSP Magazine, 1984, 1(4): 14-21. DOI:<a href="https://doi.org/10.1109/MASSP.1984.1162257">10.1109/MASSP.1984.1162257</a>.</p>
<p>[11]COHEN H, FREY G, AVANZI R, 等. Handbook of Elliptic and Hyperelliptic Curve Cryptography[M/OL]. 0 版. Chapman and Hall/CRC, 2005[2024-02-26]. <a href="https://www.taylorfrancis.com/books/9781420034981">https://www.taylorfrancis.com/books/9781420034981</a>. DOI:<a href="https://doi.org/10.1201/9781420034981">10.1201/9781420034981</a>.</p>
<p>[12]Hardcaml Zprize[EB/OL]. [2024-01-30]. <a href="https://zprize.hardcaml.com/ntt-top-level.html">https://zprize.hardcaml.com/ntt-top-level.html</a>.</p>
<p>[13]IEEE Xplore Full-Text PDF:[EB/OL]. [2024-02-28]. <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=4176858">https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=4176858</a>.</p>
<p>[14]Math &amp; Engineering[EB/OL]. [2024-02-22]. <a href="https://xn--2-umb.com/">https://xn—2-umb.com/</a>.</p>
<p>[15]LIANG Z, ZHAO Y. Number Theoretic Transform and Its Applications in Lattice-based Cryptosystems: A Survey[M/OL]. arXiv, 2022[2024-01-30]. <a href="http://arxiv.org/abs/2211.13546">http://arxiv.org/abs/2211.13546</a>.</p>
<p>[16]KNAUTH C, ADAS B, WHITFIELD D, 等. Practically efficient methods for performing bit-reversed permutation in C++11 on the x86-64 architecture[M/OL]. arXiv, 2017[2024-01-29]. <a href="http://arxiv.org/abs/1708.01873">http://arxiv.org/abs/1708.01873</a>.</p>
<p>[17]DUPAQUIS V, VENELLI A. Redundant Modular Reduction Algorithms[C/OL]//PROUFF E. Smart Card Research and Advanced Applications. Berlin, Heidelberg: Springer, 2011: 102-114. DOI:<a href="https://doi.org/10.1007/978-3-642-27257-8_7">10.1007/978-3-642-27257-8_7</a>.</p>
<p>[18]Knezevic M, Vercauteren F, Verbauwhede I. Speeding up Barrett and Montgomery modular multiplications[J]. IEEE Transactions on Comput, 2009, 2.<a href="assets/network-asset-bar_mont-20240412140014-xo4uyzq.pdf">bar_mont.pdf (kuleuven.be)</a></p>
<p>[19]KRAPIVENSKY V. Speeding up decimal multiplication[M/OL]. arXiv, 2020[2024-01-21]. <a href="http://arxiv.org/abs/2011.11524">http://arxiv.org/abs/2011.11524</a>. DOI:<a href="https://doi.org/10.48550/arXiv.2011.11524">10.48550/arXiv.2011.11524</a>.</p>
<p>[20]LONGA P, NAEHRIG M. Speeding up the Number Theoretic Transform for Faster Ideal Lattice-Based Cryptography[A/OL]. (2016)[2024-01-30]. <a href="https://eprint.iacr.org/2016/504">https://eprint.iacr.org/2016/504</a>.</p>
<p>[21]REDUCIBLE. The Fast Fourier Transform (FFT): Most Ingenious Algorithm Ever?[Z/OL]. (2020-11-15)[2024-01-21]. <a href="https://www.youtube.com/watch?v=h7apO7q16V0">https://www.youtube.com/watch?v=h7apO7q16V0</a>.</p>
<p>[22]LONGA P, NAEHRIG M. Speeding up the Number Theoretic Transform for Faster Ideal Lattice-Based Cryptography[A/OL]. (2016)[2024-07-11]. <a href="https://eprint.iacr.org/2016/504">https://eprint.iacr.org/2016/504</a>.</p>
<p>‍</p>
<p>‍</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>NTT</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>赛博土木A-深度学习01：机器学习概述</title>
    <url>/posts/a098a643.html</url>
    <content><![CDATA[<h2 id="1-机器学习组件"><a href="#1-机器学习组件" class="headerlink" title="1 机器学习组件"></a>1 机器学习组件</h2><p>机器学习是人工智能的一个分支，机器学习主要由图所示的组件构成，即：数据、模型、目标函数、算法。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501031713265.svg" alt="图1 机器学习组件" title="图1 机器学习组件">​</p>
<p><strong>数据：</strong> 数据集由一个个独立的样本组成，样本（数据点/数据实例）由一组称为特征的属性构成，监督学习还会包含标签。</p>
<p><strong>模型：</strong> 对数据的处理，根据输入的数据给出相应的结果。模型存在一些列参数，参数可以影响模型的效果。</p>
<p><strong>目标函数：</strong> 用来量化模型的有效性。</p>
<p><strong>算法：</strong> 调整模型参数以优化模型的效果。</p>
<p>‍</p>
<h2 id="2-机器学习分类"><a href="#2-机器学习分类" class="headerlink" title="2 机器学习分类"></a>2 机器学习分类</h2><h3 id="2-1-监督学习"><a href="#2-1-监督学习" class="headerlink" title="2.1 监督学习"></a>2.1 监督学习</h3><p>监督学习(supervised learning)擅长在“给定输入特征”的情况下预测标签。训练时需要提供一个聚到的训练样本集，每个样本包含特征和相应标签值。</p>
<p>监督学习包含如下几类问题：</p>
<ul>
<li>回归：根据特征评估标签值（e.g. 价格）。</li>
<li>分类：预测样本属于属于哪个分类。</li>
<li>标记：预测样本包含多个不互相排斥的分类。</li>
<li>搜索：对搜索结果进行排序。</li>
<li>推荐：个性化推荐。</li>
<li>序列学习：样本之间存在前后联系（翻译）。</li>
</ul>
<h3 id="2-2-无监督学习"><a href="#2-2-无监督学习" class="headerlink" title="2.2 无监督学习"></a>2.2 无监督学习</h3><p>无监督学习的训练样本集不提供标签。主要处理如下的问题：</p>
<ul>
<li>聚类：对数据进行分类。</li>
<li>主成分分析：用少量参数来描述数据的线性属性（运动轨迹：速度、方向、加速度）。</li>
<li>因果关系：影响数据的根本原因。</li>
<li>生成对抗性网络：合成数据。</li>
</ul>
<h3 id="2-3-强化学习"><a href="#2-3-强化学习" class="headerlink" title="2.3 强化学习"></a>2.3 强化学习</h3><p>监督学习与非监督学习都是一种离线学习，首先从环境中收集足够的样本进行训练，然后在环境中使用，训练好的模型不再受环境影响。</p>
<p>强化学习则是与环境进行交互，其过程可以描述如下：在每个特定时间点,智能体从环境 接收一些观察,并且必须选择一个动作,然后通过某种机制将 其传输回环境,最后智能体从环境中获得奖励。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412131553172.png" alt="图2 强化学习与环境的交互" title="图2 强化学习与环境的交互">​</p>
<h2 id="3-深度学习"><a href="#3-深度学习" class="headerlink" title="3 深度学习"></a>3 深度学习</h2><p>深度学习是一种解决机器学习问题的一种工具，其依赖于数据与神经网络编程。深度是指其使用了多层模型。</p>
<p>‍</p>
<p>‍</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 《动手学深度学习》 — 动手学深度学习 2.0.0 documentation[EB/OL]. [2024-12-21]. <a href="https://zh.d2l.ai/">https://zh.d2l.ai/</a>.</p>
<p>‍</p>
]]></content>
      <categories>
        <category>赛博土木</category>
        <category>深度学习，基础</category>
      </categories>
      <tags>
        <tag>赛博土木</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>赛博土木A-深度学习03：softmax回归</title>
    <url>/posts/e35c4051.html</url>
    <content><![CDATA[<h2 id="1-分类问题"><a href="#1-分类问题" class="headerlink" title="1 分类问题"></a>1 分类问题</h2><p>一个样本有四个特征$x_1,x_2,x_3,x_4$,存在三个类别$\{1,2,3\}$。</p>
<p>采用独热编码的形式表示标签：$y\in \{(1,0,0),(0,1,0),(0,0,1)\}$.</p>
<p>为了估计所有类别的概率，需要多个输出。</p>
<script type="math/tex; mode=display">
\begin{aligned}
o_1 &= x_1 w_{11} + x_2 w_{12} + x_3 w_{13} + x_4 w_{14} + b_1,\\
o_2 &= x_1 w_{21} + x_2 w_{22} + x_3 w_{23} + x_4 w_{24} + b_2,\\
o_3 &= x_1 w_{31} + x_2 w_{32} + x_3 w_{33} + x_4 w_{34} + b_3.
\end{aligned}</script><p>向量化表示：</p>
<script type="math/tex; mode=display">
\mathbf{o} = \mathbf{W} \mathbf{x} + \mathbf{b}</script><p>神经网络结构如下：</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412171957157.svg" alt="softmaxreg">​</p>
<p>‍</p>
<p>问题在于目前的$\mathbf{o}$未经规范化，其不满足概率基本公理。</p>
<h2 id="2-softmax函数"><a href="#2-softmax函数" class="headerlink" title="2 softmax函数"></a>2 softmax函数</h2><p>softmax函数，通过求幂来保证预测非负，然后归一化处理。</p>
<script type="math/tex; mode=display">
\hat{\mathbf{y}} = \mathrm{softmax}(\mathbf{o}),\quad \hat{y}_j = \frac{\exp(o_j)}{\sum_k \exp(o_k)}</script><p>不难发现softmax并不改变概率的大小顺序，仅是让结果符合正确的概率分布。</p>
<p>‍</p>
<h2 id="3-损失函数"><a href="#3-损失函数" class="headerlink" title="3 损失函数"></a>3 损失函数</h2><p>对模型在训练集上的表现进行评估，可以用下面的公式进行表示，即在训练集的特征前提下，获得训练集标签的概率，$P$越接近$1$说明模型在训练集上的效果越好。</p>
<script type="math/tex; mode=display">
P(\mathbf{Y} \mid \mathbf{X}) = \prod_{i=1}^n P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)})</script><p>根据最大似然估计，最大化$P$，相当于最小化负对数似然：</p>
<script type="math/tex; mode=display">
-\log P(\mathbf{Y} \mid \mathbf{X}) = \sum_{i=1}^n -\log P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)})
= \sum_{i=1}^n l(\mathbf{y}^{(i)}, \hat{\mathbf{y}}^{(i)})</script><p>损失函数：</p>
<script type="math/tex; mode=display">
l(\mathbf{y}, \hat{\mathbf{y}}) = - \sum_{j=1}^q y_j \log \hat{y}_j</script><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 《动手学深度学习》 — 动手学深度学习 2.0.0 documentation[EB/OL]. [2024-12-21]. <a href="https://zh.d2l.ai/">https://zh.d2l.ai/</a>.</p>
]]></content>
      <categories>
        <category>赛博土木</category>
        <category>深度学习，基础</category>
      </categories>
      <tags>
        <tag>赛博土木</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>赛博土木A-深度学习02：线性回归</title>
    <url>/posts/2e34cdb8.html</url>
    <content><![CDATA[<p>回归：能为一个或多个自变量与因变量之间关系建模的一类方法。</p>
<h2 id="1-线性回归模型"><a href="#1-线性回归模型" class="headerlink" title="1 线性回归模型"></a>1 线性回归模型</h2><p>线性回归基于如下假设：</p>
<ol>
<li>自变量与因变量的关系是线性的。</li>
<li>包含噪声值，且噪声值是正常的。</li>
</ol>
<p>将线性回归与机器学习模型进行结合，现有数据即训练数据集，每组自变量与因变量视为一个样本（数据点）（$(\mathbf{x}^i,y^i)$）。自变量称为特征($\mathbf{x}^{i}=[x^i_1,x^i_2,\ldots,x^i_m]^T$)，因变量即标签($y^i$)。</p>
<h2 id="2-线性模型"><a href="#2-线性模型" class="headerlink" title="2 线性模型"></a>2 线性模型</h2><p>线性模型基本形式是对自变量的加权和：</p>
<script type="math/tex; mode=display">
\hat{y^i} =\omega_1x^i_1 +\ldots\omega_mx^i_m+b</script><p>其中，$\hat{y^i}$ 是样本的预测值,$\omega_j$是权重，b是偏置，以向量形式表示, $\mathbf{x},\mathbf{w} \in \mathbb{R}^m$：</p>
<script type="math/tex; mode=display">
\hat{y}^i =\mathbf{w}^T\mathbf{x}^i+b</script><p>可以通过矩阵表示整个数据集(规模为$n$)，$\mathbf{X} \in \mathbb{R}^{n \times m}$：</p>
<script type="math/tex; mode=display">
\hat{\mathbf{y}}= \mathbf{Xw}+b</script><p>无论采样什么样的手段来观察特征$\mathbf{X}$和标签$\mathbf{y}$也会存在观测误差，因此需要添加噪声项用以表示观测误差。</p>
<p>与机器学习组件进行对应，可以发现$\mathbf{w},b$是模型参数，形成完整的机器学习结构还需要如下两个组件：</p>
<ol>
<li>一种模型质量的度量方式。</li>
<li>一种能够更新模型以提高模型预测质量的方法。</li>
</ol>
<h2 id="3-损失函数"><a href="#3-损失函数" class="headerlink" title="3 损失函数"></a>3 损失函数</h2><p>损失函数用于量化目标实际值与预测值之间的差距（损失），一般使用正整数表示。</p>
<p>平方误差公式：</p>
<script type="math/tex; mode=display">
l^i(\mathbf{w},b)=\frac{1}{2}(\hat{y^i}-y^i)^2</script><p>这里的$\frac{1}{2}$仅仅是为了求导后形式简单而选择的。</p>
<p>理想的参数$(\mathbf{w}^<em>,b^</em>)$使得在样本上损失最小：</p>
<script type="math/tex; mode=display">
\mathbf{w}^*,b^* =\underset{\mathbf{w},b}{argmin}  \ L(\mathbf{w},b)</script><p>‍</p>
<h2 id="4-解析解"><a href="#4-解析解" class="headerlink" title="4 解析解"></a>4 解析解</h2><p>对于线性回归模型，理想参数（解）可以用公式进行表示，可以称为解析解。</p>
<p>将偏置融入$\mathbf{w}$结合形成新的向量$\mathbf{w}$,问题转化为最小化$||\mathbf{y}-\mathbf{Xw}||^2$:</p>
<script type="math/tex; mode=display">
\mathbf{w}^* =(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T \mathbf{y}</script><p>‍</p>
<h2 id="5-随机梯度下降"><a href="#5-随机梯度下降" class="headerlink" title="5 随机梯度下降"></a>5 随机梯度下降</h2><p>但是大多数情况下是无法获得解析解的，因此需要寻找一种方式来找到理想参数。</p>
<p>梯度下降是在损失函数递减的方向是更新参数来降低误差。最简单的做法是计算损失函数关于模型参数的导数。</p>
<p>为了加快速度，通常更新时从训练集中抽取小批样本进行计算<br>（1）初始化模型参数的值，如随机初始化；<br>（2）从数据集中随机抽取小批量样本且在负梯度的方向上更新参数，并不断迭代这一步骤。<br>对于平方损失和仿射变换，我们可以明确地写成如下形式:</p>
<script type="math/tex; mode=display">
\begin{aligned} \mathbf{w} &\leftarrow \mathbf{w} -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{\mathbf{w}} l^{(i)}(\mathbf{w}, b) = \mathbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \mathbf{x}^{(i)} \left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right),\\ b &\leftarrow b -  \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_b l^{(i)}(\mathbf{w}, b)  = b - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right). \end{aligned}</script><p>$|\mathcal{B}|$表示每个小批量中的样本数，这也称为批量大小。$\eta$表示学习率。这两个参数是提前设置的，不会在训练中改变，称为超参数。调整超参数的过程称为调参。</p>
<p>‍</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 《动手学深度学习》 — 动手学深度学习 2.0.0 documentation[EB/OL]. [2024-12-21]. <a href="https://zh.d2l.ai/">https://zh.d2l.ai/</a>.</p>
]]></content>
      <categories>
        <category>赛博土木</category>
        <category>深度学习，基础</category>
      </categories>
      <tags>
        <tag>赛博土木</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>赛博土木A-深度学习04：多层感知机</title>
    <url>/posts/90bbb405.html</url>
    <content><![CDATA[<h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h2><p>通过在输入与输出之间增加隐藏层，可以构建多层网络，前$L − 1$层看作表示,把最后一层看作线性预测器。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412171956836.png" alt="image">​</p>
<p>数学表示：</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbf{H} & = \mathbf{X} \mathbf{W}^{(1)} + \mathbf{b}^{(1)}, \\
    \mathbf{O} & = \mathbf{H}\mathbf{W}^{(2)} + \mathbf{b}^{(2)}.
\end{aligned}</script><p>没有额外的处理，多层网络与单层线性网络没有本质的不同：</p>
<script type="math/tex; mode=display">
\mathbf{O} = (\mathbf{X} \mathbf{W}^{(1)} + \mathbf{b}^{(1)})\mathbf{W}^{(2)} + \mathbf{b}^{(2)} = \mathbf{X} \mathbf{W}^{(1)}\mathbf{W}^{(2)} + \mathbf{b}^{(1)} \mathbf{W}^{(2)} + \mathbf{b}^{(2)} = \mathbf{X} \mathbf{W} + \mathbf{b}</script><p>于是引入了非线性的激活函数$\sigma$，对于激活函数$\sigma()$的结果称为活性值。</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \mathbf{H} & = \sigma(\mathbf{X} \mathbf{W}^{(1)} + \mathbf{b}^{(1)}), \\
    \mathbf{O} & = \mathbf{H}\mathbf{W}^{(2)} + \mathbf{b}^{(2)}.\\
\end{aligned}</script><h2 id="2-激活函数"><a href="#2-激活函数" class="headerlink" title="2 激活函数"></a>2 激活函数</h2><h5 id="ReLU-函数"><a href="#ReLU-函数" class="headerlink" title="ReLU 函数"></a>ReLU 函数</h5><script type="math/tex; mode=display">
\operatorname{ReLU}(x) = \max(x, 0)</script><h5 id="sigmod-函数"><a href="#sigmod-函数" class="headerlink" title="sigmod 函数"></a>sigmod 函数</h5><script type="math/tex; mode=display">
\operatorname{sigmoid}(x) = \frac{1}{1 + \exp(-x)}</script><h5 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a>tanh</h5><script type="math/tex; mode=display">
\operatorname{tanh}(x) = \frac{1 - \exp(-2x)}{1 + \exp(-2x)}</script><h2 id="3-模型选择"><a href="#3-模型选择" class="headerlink" title="3 模型选择"></a>3 模型选择</h2><h3 id="3-1-训练误差与泛化误差"><a href="#3-1-训练误差与泛化误差" class="headerlink" title="3.1 训练误差与泛化误差"></a>3.1 训练误差与泛化误差</h3><p>对于模型在训练集和理想状态的正确性可以用训练误差和泛化误差及进行表示：</p>
<p><strong>训练误差：</strong></p>
<p>模型在训练集上计算得到的误差。</p>
<p><strong>泛化误差：</strong></p>
<p>模型从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。</p>
<p>显然泛化误差是一种抽象概念无法实际计算获得。</p>
<h3 id="3-2-拟合与欠拟合"><a href="#3-2-拟合与欠拟合" class="headerlink" title="3.2 拟合与欠拟合"></a>3.2 拟合与欠拟合</h3><p>根据模型在训练集和测试集上的效果可以形成两种对模型的评价：</p>
<p><strong>过拟合：</strong></p>
<p>过拟合是指在训练集上准确性显著高于测试集。</p>
<p><strong>欠拟合：</strong></p>
<p>欠拟合情况下，模型在训练集和测试集上的准确性没有明显差距，但是整体正确性较低。</p>
<h3 id="3-3-模型复杂性"><a href="#3-3-模型复杂性" class="headerlink" title="3.3 模型复杂性"></a>3.3 模型复杂性</h3><p>采用不同策略的模型之间很难进行比较，只能泛泛的归纳为：参数数量，参数取值范围，训练迭代轮数。</p>
<p>在理论上模型复杂度越高，其能处理的任务更多。但是计算机是一个实践的学科，在理论只具有指导意义。复杂的模型需要足够大的训练集（成本高昂），过小的样本集容易导致欠拟合。</p>
<p>‍</p>
<h3 id="3-4-验证集"><a href="#3-4-验证集" class="headerlink" title="3.4 验证集"></a>3.4 验证集</h3><p>模型中存在人为设置的超参数。通常会根据在测试集上的表现来调整超参数。</p>
<p>如果我们将训练和测试过程都视为训练的过程，会出现超参数面对测试集过拟合的问题。</p>
<p>为此我们需要在增加一个样本集合用来充当前文测试集所扮演的角色，从何避免对测试集的过拟合。这个集合就是验证集。</p>
<h4 id="k折交叉验证"><a href="#k折交叉验证" class="headerlink" title="k折交叉验证"></a>k折交叉验证</h4><p>将训练集分为K份，其中一份用作验证集，其余用于新的训练集。进行K次实验，取平均估计训练和验证误差。</p>
<p>‍</p>
<h2 id="4-正则化"><a href="#4-正则化" class="headerlink" title="4 正则化"></a>4 正则化</h2><p>正则化包含一系列用于纠正机器学习模型过拟合问题的技术。因此，正则化是一种用于提高模型泛化能力的方法。正则化可在增大训练误差的前提下提高泛化能力。换言之，正则化方法通常会导致对训练数据的预测不太准确，但对测试数据的预测更为准确。</p>
<h3 id="4-1-范数"><a href="#4-1-范数" class="headerlink" title="4.1 范数"></a>4.1 范数</h3><p>在机器学习中范数指的是从向量到标量的映射。</p>
<p>满足如下性质：</p>
<ol>
<li><p>缩放：</p>
<script type="math/tex; mode=display">
 f(\alpha \mathbf{x})=|\alpha|f(\mathbf{x})</script></li>
<li><p>三角不等式：</p>
<script type="math/tex; mode=display">
 f(\mathbf{x}+\mathbf{y})\lt f(\mathbf{x})+f(\mathbf{y})</script></li>
<li><p>非负：</p>
<script type="math/tex; mode=display">
 f(\mathbf{x}) \ge 0</script></li>
</ol>
<p>将欧几里得空间内的向量长度(相对坐标原点)，推广到一般向量空间中：</p>
<script type="math/tex; mode=display">
\|\mathbf{x}\|_2 = \sqrt{\sum_{i=1}^n x_i^2}</script><p>上述表示称为$L_2$范式，为了减少受异常值的影响通常采用$L_1$范式：</p>
<script type="math/tex; mode=display">
\|\mathbf{x}\|_1 = \sum_{i=1}^n \left|x_i \right|</script><p>给出范式的一般化表示$L_p$：</p>
<script type="math/tex; mode=display">
\|\mathbf{x}\|_p = \left(\sum_{i=1}^n \left|x_i \right|^p \right)^{1/p}</script><p>矩阵的Frobenius范数：</p>
<script type="math/tex; mode=display">
\|\mathbf{X}\|_F = \sqrt{\sum_{i=1}^m \sum_{j=1}^n x_{ij}^2}</script><h3 id="4-2-权重衰减"><a href="#4-2-权重衰减" class="headerlink" title="4.2 权重衰减"></a>4.2 权重衰减</h3><p>权重衰减用参数向量的范数（$L_2$范数）来衡量模型的复杂度，然后将其作为惩罚项添加到损失函数中。</p>
<h3 id="4-3-暂退法"><a href="#4-3-暂退法" class="headerlink" title="4.3 暂退法"></a>4.3 暂退法</h3><p>暂退法在计算每层神经网络时引入噪声。在标准暂退法正则化中，每个中间活性值以暂退概率$p$进行替换：</p>
<script type="math/tex; mode=display">
\begin{aligned}
h' =
\begin{cases}
    0 & \text{ 概率为 } p \\
    \frac{h}{1-p} & \text{ 其他情况}
\end{cases}
\end{aligned}</script><p>‍</p>
<p>‍</p>
<p>‍</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 《动手学深度学习》 — 动手学深度学习 2.0.0 documentation[EB/OL]. [2024-12-21]. <a href="https://zh.d2l.ai/">https://zh.d2l.ai/</a>.<br>[2] 什么是正则化？| IBM[EB/OL]. (2023-11-10)[2024-12-21]. <a href="https://www.ibm.com/cn-zh/topics/regularization">https://www.ibm.com/cn-zh/topics/regularization</a>.</p>
]]></content>
      <categories>
        <category>赛博土木</category>
        <category>深度学习，基础</category>
      </categories>
      <tags>
        <tag>赛博土木</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>赛博土木A-深度学习05：块组件</title>
    <url>/posts/5afd145b.html</url>
    <content><![CDATA[<p>‍</p>
<p>复杂的神经网络模型通常由多层结构构成，将其基本构成部分称为<strong>块</strong>，描单层、多层组件或者整个模型。</p>
<p>从单纯的编程视角出发，块是同过类实现的，考虑到神经网络的性质，这些类需要具备如下的基本功能：</p>
<ol>
<li>输入数据作为前向传播的函数的参数。</li>
<li>通过前向传播函数生成输出。</li>
<li>计算输出的梯度。</li>
<li>存储和访问前向传播计算所需的参数。</li>
<li>根据需求初始化模型参数。</li>
</ol>
<p>‍</p>
]]></content>
      <categories>
        <category>赛博土木</category>
        <category>深度学习，基础</category>
      </categories>
      <tags>
        <tag>赛博土木</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>赛博土木A-深度学习06：卷积神经网络</title>
    <url>/posts/af6b5fbd.html</url>
    <content><![CDATA[<h2 id="1-全连接层到卷积"><a href="#1-全连接层到卷积" class="headerlink" title="1 全连接层到卷积"></a>1 全连接层到卷积</h2><p>多层感知机更适合处理表格样本数据，但是对于具有一定结构的数据集就不再适用，例如图片。</p>
<h3 id="1-1-不变性"><a href="#1-1-不变性" class="headerlink" title="1.1 不变性"></a>1.1 不变性</h3><p>不变性是指检测对象出现在图片不同的位置，不影响检测对象的形状。</p>
<p>适合于计算机视觉的神经网络架构：</p>
<ol>
<li><strong>平移不变性：</strong> 不管检测对象出现在图像中的哪个位置,神经网络的前面几层  应该对相同的图像区域具有相似的反应,即为“平移不变性”。</li>
<li><strong>局部性：</strong> 神经网络的前面几层应该只探索输入图像中的局部区域,而不过度在意图像中相隔  较远区域的关系,这就是“局部性”原则。最终,可以聚合这些局部特征,以在整个图像级别进行预测。</li>
</ol>
<h3 id="1-2-多层感知机的限制"><a href="#1-2-多层感知机的限制" class="headerlink" title="1.2 多层感知机的限制"></a>1.2 多层感知机的限制</h3><p>输入是二维图像$\mathbf{X}$，隐藏表示$\mathbf{H}$也是矩阵，两者都是二维张量。</p>
<p>使用$[\mathbf{X}]_{i, j}$和$[\mathbf{H}]_{i, j}$分别表示输入图像和隐藏表示中位置$(i,j)$处的像素。为了使每个隐藏神经元都能接收到每个输入像素的信息，参数从权重矩阵转变为为四阶权重张量$\mathsf{W}$。假设<strong>$\mathbf{U}$</strong>包含偏置参数，我们可以将全连接层形式化地表示为：</p>
<script type="math/tex; mode=display">
\begin{aligned} \left[\mathbf{H}\right]_{i, j} &= [\mathbf{U}]_{i, j} + \sum_k \sum_l[\mathsf{W}]_{i, j, k, l}  [\mathbf{X}]_{k, l}\\ &=  [\mathbf{U}]_{i, j} +
\sum_a \sum_b [\mathsf{V}]_{i, j, a, b}  [\mathbf{X}]_{i+a, j+b}.\end{aligned}</script><p>其中，$[\mathsf{V}]_{i, j, a, b} = [\mathsf{W}]_{i, j, i+a, j+b}$。</p>
<h4 id="1-2-1-平移不变性"><a href="#1-2-1-平移不变性" class="headerlink" title="1.2.1 平移不变性"></a>1.2.1 平移不变性</h4><p>为了满足平移不变性，参数和偏置应当与检测位置无关。因此$\mathbf{U}$和$\mathsf{V}$应当与$(i,j)$无关。即$[\mathsf{V}]_{i, j, a, b} = [\mathbf{V}]_{a, b}$，$\mathbf{U}=u$。因此$\mathbf{H}$简化为：</p>
<script type="math/tex; mode=display">
[\mathbf{H}]_{i, j} = u + \sum_a\sum_b [\mathbf{V}]_{a, b} [\mathbf{X}]_{i+a, j+b}</script><h4 id="1-2-2-局部性"><a href="#1-2-2-局部性" class="headerlink" title="1.2.2 局部性"></a>1.2.2 局部性</h4><p>为了满足局部性需要控制范围：</p>
<script type="math/tex; mode=display">
[\mathbf{H}]_{i, j} = u + \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} [\mathbf{V}]_{a, b}  [\mathbf{X}]_{i+a, j+b}</script><p>上式就是一个卷积层，$\mathbf{V}$被称为卷积核，或者滤波器。</p>
<h4 id="1-2-3-卷积"><a href="#1-2-3-卷积" class="headerlink" title="1.2.3 卷积"></a>1.2.3 卷积</h4><p>两个函数，比如$f, g: \mathbb{R}^d \to \mathbb{R}$之间的“卷积”被定义为：</p>
<script type="math/tex; mode=display">
(f * g)(\mathbf{x}) = \int f(\mathbf{z}) g(\mathbf{x}-\mathbf{z}) d\mathbf{z}</script><p>对于二维张量，则为$f$的索引$(a, b)$和$g$的索引$(i-a, j-b)$上的对应加和：</p>
<script type="math/tex; mode=display">
(f * g)(i, j) = \sum_a\sum_b f(a, b) g(i-a, j-b).</script><h4 id="1-2-4-通道"><a href="#1-2-4-通道" class="headerlink" title="1.2.4 通道"></a>1.2.4 通道</h4><p>图像本质上是三维的（宽、高、颜色）。以RGB图像为例其颜色由三个参数构成，并称这个大小为3的轴为通道维度。此外输出可能存在多个输出通道用以表示特殊空间特征（纹理等）所以实际上卷积核是四维的。</p>
<script type="math/tex; mode=display">
[\mathsf{H}]_{i,j,d} = \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} \sum_c [\mathsf{V}]_{a, b, c, d} [\mathsf{X}]_{i+a, j+b, c}</script><h2 id="2-图像卷积"><a href="#2-图像卷积" class="headerlink" title="2 图像卷积"></a>2 图像卷积</h2><h3 id="2-1-互相关运算"><a href="#2-1-互相关运算" class="headerlink" title="2.1 互相关运算"></a>2.1 互相关运算</h3><p>卷积层做的并不是卷积操作，而是互相关操作，输入张量与核张量通过互相关运算产生输出张量。</p>
<p>对于二维张量而言，卷积窗口从左到右，从上到下依次滑动并与核张量进行互相关运算（逐元素相乘并求和）。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412231510115.svg" alt="correlation">​</p>
<script type="math/tex; mode=display">
0\times0+1\times1+3\times2+4\times3=19,\\
1\times0+2\times1+4\times2+5\times3=25,\\
3\times0+4\times1+6\times2+7\times3=37,\\
4\times0+5\times1+7\times2+8\times3=43.</script><p>卷积层在计算完每个元素后还要加上偏置值。</p>
<p>输出大小与输入大小$n_k\times n_w$，以及卷积核大小$h_k\times h_w$相关：</p>
<script type="math/tex; mode=display">
(n_h-k_h+1) \times (n_w-k_w+1)</script><h3 id="2-2-填充与步幅"><a href="#2-2-填充与步幅" class="headerlink" title="2.2 填充与步幅"></a>2.2 填充与步幅</h3><h4 id="2-2-1-填充"><a href="#2-2-1-填充" class="headerlink" title="2.2.1 填充"></a>2.2.1 填充</h4><p>图像卷积有个问题，随着卷积层数的增加会逐步丢失图像边缘信息。为此需要对图像边缘进行填充。</p>
<p>填充后的输出大小：</p>
<script type="math/tex; mode=display">
(n_h-k_h+p_h+1) \times (n_w-k_w+p_w+1)</script><p>其中$p_h=k_h-1,p_w=k_w-1$。注意是左右各填充$\frac{p_w}{2}$，上下同理。</p>
<h4 id="2-2-2-步幅"><a href="#2-2-2-步幅" class="headerlink" title="2.2.2 步幅"></a>2.2.2 步幅</h4><p>面对高像素图象时，信息是冗余的，因此可以提高卷积核每次滑动的元素个数，即步幅。</p>
<p>输出大小：</p>
<script type="math/tex; mode=display">
[(n_h-k_h+p_h+s_h) /s_h]\times[ (n_w-k_w+p_w+s_w)/s_w]</script><h3 id="2-3-通道"><a href="#2-3-通道" class="headerlink" title="2.3 通道"></a>2.3 通道</h3><h4 id="2-3-1-多输入通道"><a href="#2-3-1-多输入通道" class="headerlink" title="2.3.1 多输入通道"></a>2.3.1 多输入通道</h4><p>卷积核应当与输入的通道数$c_i$保持一致，然后分别计算对应通道的互相管运算，最后进行求和。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412231510334.svg" alt="conv-multi-in">​</p>
<h4 id="2-3-2-多输出通道"><a href="#2-3-2-多输出通道" class="headerlink" title="2.3.2 多输出通道"></a>2.3.2 多输出通道</h4><p>对于$c_o$个输出通道，需要为每一个通道构建一个多输入通道卷积核，最后四维卷积核表示为：$c_o\times c_i \times k_h \times k_w$。</p>
<h2 id="3-汇聚层-池化层"><a href="#3-汇聚层-池化层" class="headerlink" title="3 汇聚层/池化层"></a>3 汇聚层/池化层</h2><p>汇聚层是CNN中用于减小特征图尺寸的关键层级结构。其基本思想是通过对输入特征图的子区域进行聚合操作，以提取出更加鲁棒的特征并减小计算量。汇聚操作通常包括最大汇聚（Max Pooling）和平均汇聚（Average Pooling）两种方式。</p>
<h3 id="3-1-感受野"><a href="#3-1-感受野" class="headerlink" title="3.1 感受野"></a>3.1 感受野</h3><p>通常我们希望获得是对整个图像的处理结果，需要插入汇聚层，使得每层的输出特征图变小，这就会导致，每个神经元对其敏感的感受野变大。</p>
<p>感受野，指的是神经网络中神经元“看到的”输入区域，在卷积神经网络中，特征图上某个元素的计算受输入图像上某个区域的影响，这个区域即该元素的感受野。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412231510918.png" alt="image">​</p>
<h3 id="3-2-最大汇聚层与平均汇聚层"><a href="#3-2-最大汇聚层与平均汇聚层" class="headerlink" title="3.2  最大汇聚层与平均汇聚层"></a>3.2  最大汇聚层与平均汇聚层</h3><p>汇聚层也是存在一个窗口，但是不同与卷积层，汇聚层的窗口不含参数，只是对窗口覆盖的元素执行特定运算。最大汇聚层是计算计算最大值，平均汇聚层测试计算平均值。</p>
<p>汇聚层的填充与步幅和卷积层没有什么区别。不同在于汇聚层在每个通道上进行单独运算，所以输入与输出的通道数一致。</p>
<h2 id="4-CNN"><a href="#4-CNN" class="headerlink" title="4 CNN"></a>4 CNN</h2><h3 id="4-1-基本组成"><a href="#4-1-基本组成" class="headerlink" title="4.1 基本组成"></a>4.1 基本组成</h3><p>卷积神经网络由两个部分组成，分别是多层感知机(MLP)和特征提取器，特征提取器由卷积层、激活函数、汇聚层构成。</p>
<p>特征提取器用于提取图片特征，MLP部分根据提取出来的特征进行分类。特征提取器的输出是特征图，通过展开转换为MLP的输入。</p>
<h3 id="4-2-示例-LeNet"><a href="#4-2-示例-LeNet" class="headerlink" title="4.2  示例 LeNet"></a>4.2  示例 LeNet</h3><p>LeNet组成：</p>
<p>特征提取器：两个卷积块</p>
<p>多层感知机：三个全连接层</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501031711929.svg" alt="lenet">​</p>
<p>卷积块：一个卷积层+sigmod激活函数+平均汇聚层。</p>
<p>卷积的输出维度：批量大小、通道数、高度、宽度。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501031711858.svg" alt="lenet-vert">​</p>
<p>为了将卷积块的输出转换为稠密块的输入，我们需要将其展平第一个维度是批次，第二个维度则是平面向量。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Conv2d output shape: 	 torch.Size([<span class="number">1</span>, <span class="number">6</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line">Sigmoid output shape: 	 torch.Size([<span class="number">1</span>, <span class="number">6</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line">AvgPool2d output shape:  torch.Size([<span class="number">1</span>, <span class="number">6</span>, <span class="number">14</span>, <span class="number">14</span>])</span><br><span class="line">Conv2d output shape: 	 torch.Size([<span class="number">1</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">10</span>])</span><br><span class="line">Sigmoid output shape: 	 torch.Size([<span class="number">1</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">10</span>])</span><br><span class="line">AvgPool2d output shape:  torch.Size([<span class="number">1</span>, <span class="number">16</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br><span class="line">Flatten output shape: 	 torch.Size([<span class="number">1</span>, <span class="number">400</span>])</span><br><span class="line">Linear output shape: 	 torch.Size([<span class="number">1</span>, <span class="number">120</span>])</span><br><span class="line">Sigmoid output shape: 	 torch.Size([<span class="number">1</span>, <span class="number">120</span>])</span><br><span class="line">Linear output shape: 	 torch.Size([<span class="number">1</span>, <span class="number">84</span>])</span><br><span class="line">Sigmoid output shape: 	 torch.Size([<span class="number">1</span>, <span class="number">84</span>])</span><br><span class="line">Linear output shape: 	 torch.Size([<span class="number">1</span>, <span class="number">10</span>])</span><br></pre></td></tr></table></figure>
<p>‍</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 彻底搞懂感受野的含义与计算-腾讯云开发者社区-腾讯云[EB/OL]. [2024-12-23]. <a href="https://cloud.tencent.com/developer/article/1557374">https://cloud.tencent.com/developer/article/1557374</a>.<br>[2] 深度神经网络中的感受野(Receptive Field)[EB/OL]. [2024-12-23]. <a href="https://zhuanlan.zhihu.com/p/28492837">https://zhuanlan.zhihu.com/p/28492837</a>.<br>[3] 《动手学深度学习》 — 动手学深度学习 2.0.0 documentation[EB/OL]. [2024-12-21]. <a href="https://zh.d2l.ai/">https://zh.d2l.ai/</a>.</p>
<p>‍</p>
]]></content>
      <categories>
        <category>赛博土木</category>
        <category>深度学习，基础</category>
      </categories>
      <tags>
        <tag>赛博土木</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>赛博土木A-深度学习07：现代卷积神经网络</title>
    <url>/posts/f9ed3af.html</url>
    <content><![CDATA[<h2 id="1-AlexNet"><a href="#1-AlexNet" class="headerlink" title="1 AlexNet"></a>1 AlexNet</h2><p>AlexNet 与letNet没有什么本质上的区别，只是增加了层数修改了一些细节。</p>
<p>‍</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412241543240.svg" alt="alexnet">​</p>
<p>激活函数：采用了ReLU激活函数，取代sigmod。</p>
<p>复杂度控制：通过暂退法控制模型的复杂度，而不是采用权重衰减。</p>
<h2 id="2-块搭建网络，VGGNeT"><a href="#2-块搭建网络，VGGNeT" class="headerlink" title="2 块搭建网络，VGGNeT"></a>2 块搭建网络，VGGNeT</h2><p>利用卷积层、激活函数、汇聚层构成卷积块，然后重复使用该卷积块构成卷积部分。</p>
<p> VGG 首先构建VGG块主要由多层卷积(每层有激活函数）以及一个汇聚层构成。然后重复使用VGG块，搭建VGG网络。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412241544944.svg" alt="vgg">​</p>
<h2 id="3-微网络构建网络，NiN"><a href="#3-微网络构建网络，NiN" class="headerlink" title="3 微网络构建网络，NiN"></a>3 微网络构建网络，NiN</h2><p>NIN提出一种新的方案，利用微神经网络替代卷积块，使用汇聚层进行最后的分类。传统的神经网络中MLP会破坏特征的空间结构。为此使用$1 \times 1$的卷积层对每个像素位置采用全连接，保证空间结构。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412241914570.svg" alt="nin-compare">​</p>
<h2 id="4-并行网络，GoogleNet"><a href="#4-并行网络，GoogleNet" class="headerlink" title="4 并行网络，GoogleNet"></a>4 并行网络，GoogleNet</h2><p>GoogleNet中的基本卷积块被称为Inception块，其将输入的特征图复制四份，并行处理，最后将结果进行连结。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412251415891.svg" alt="inception">​</p>
<p>GoogleNet：</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412251415904.svg" alt="inception-full">​</p>
<h2 id="5-批量规范化"><a href="#5-批量规范化" class="headerlink" title="5 批量规范化"></a>5 批量规范化</h2><p>批量规范化的引入是为了结局神经网络收敛速度。</p>
<h3 id="5-1-问题"><a href="#5-1-问题" class="headerlink" title="5.1 问题"></a>5.1 问题</h3><ul>
<li>数据预处理对最终结果会产生重要的影响，为此需要对数据进行标准化处理使其平均值为0，方差为1。</li>
<li>对于深层网络，模型参数众多，且变换莫测，其会影响网络的收敛。</li>
<li>深层网络容易过拟合。</li>
</ul>
<h2 id="5-2-基本原理"><a href="#5-2-基本原理" class="headerlink" title="5.2 基本原理"></a>5.2 基本原理</h2><p>批量规范化主要对小批量进行：规范化输入；比例拉伸和比例偏移；</p>
<p>$\mathbf{x}\in \mathcal{B}$ 表示来自小批量 $ \mathcal{B}$ 的输入，规范化$BN$：</p>
<script type="math/tex; mode=display">
\mathrm{BN}(\mathbf{x}) = \boldsymbol{\gamma} \odot \frac{\mathbf{x} - \hat{\boldsymbol{\mu}}_\mathcal{B}}{\hat{\boldsymbol{\sigma}}_\mathcal{B}} + \boldsymbol{\beta}</script><p>$\hat{\boldsymbol{\mu}}_\mathcal{B}$是小批量$\mathcal{B}$的样本均值，$\hat{\boldsymbol{\sigma}}_\mathcal{B}$是小批量$\mathcal{B}$的样本标准差。应用标准化后，生成的小批量的平均值为0和单位方差为1。由于单位方差是一个主观的选择，因此通常包含拉伸参数$\boldsymbol{\gamma}$和偏移参数$\boldsymbol{\beta}$，形状与$\mathbf{x}$相同。$\boldsymbol{\gamma}$和$\boldsymbol{\beta}$是需要与其他模型参数一起学习的参数。引入噪声确保除数不为0。</p>
<script type="math/tex; mode=display">
\begin{aligned} \hat{\boldsymbol{\mu}}_\mathcal{B} &= \frac{1}{|\mathcal{B}|} \sum_{\mathbf{x} \in \mathcal{B}} \mathbf{x},\\
\hat{\boldsymbol{\sigma}}_\mathcal{B}^2 &= \frac{1}{|\mathcal{B}|} \sum_{\mathbf{x} \in \mathcal{B}} (\mathbf{x} - \hat{\boldsymbol{\mu}}_{\mathcal{B}})^2 + \epsilon.\end{aligned}</script><h3 id="5-3-批量规范化层"><a href="#5-3-批量规范化层" class="headerlink" title="5.3 批量规范化层"></a>5.3 批量规范化层</h3><h4 id="5-3-1-全连接层"><a href="#5-3-1-全连接层" class="headerlink" title="5.3.1 全连接层"></a>5.3.1 全连接层</h4><p>全连接层的输入为$\mathbf{x}$，权重参数和偏置参数分别为$\mathbf{W}$和$\mathbf{b}$，激活函数为$\phi$，批量规范化的运算符为$\mathrm{BN}$。<br>那么，使用批量规范化的全连接层的输出的计算详情如下：</p>
<script type="math/tex; mode=display">
\mathbf{h} = \phi(\mathrm{BN}(\mathbf{W}\mathbf{x} + \mathbf{b}) ).</script><h4 id="5-3-2-卷积层"><a href="#5-3-2-卷积层" class="headerlink" title="5.3.2 卷积层"></a>5.3.2 卷积层</h4><p>卷积层上的规范化是在每个通道上分别进行批量规范化。</p>
<p>‍</p>
<h2 id="6-残差网络"><a href="#6-残差网络" class="headerlink" title="6 残差网络"></a>6 残差网络</h2><h3 id="6-1-函数类"><a href="#6-1-函数类" class="headerlink" title="6.1 函数类"></a>6.1 函数类</h3><p>设神经网络框架$\mathcal{F}$，包含学习速率以及其它超参数设置。$\forall f \in \mathcal{F}$，存在的参数集（权重和偏重）都可以通过在合适的集合上训练获得。$f^<em>$是理想函数，如果$f^</em> \in \mathcal{F}$我们可以轻易找到，但是通常我们只能找到近似$f^*$的$f_\mathcal{F}$。</p>
<script type="math/tex; mode=display">
f_\mathcal{F} := \mathop{\mathrm{argmin}}_f L(\mathbf{X}, \mathbf{y}, f) \text{ subject to } f \in \mathcal{F}</script><p>为了寻找更接近$f^*$,唯一的办法是扩展$ \mathcal{F} \rarr \mathcal{F}’$。如果$ \mathcal{F} \not\subseteq \mathcal{F}’$结果存在变差的风险。所以$ \mathcal{F} \subseteq \mathcal{F}’$。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412251415579.svg" alt="functionclasses">​</p>
<p>换言之，如果通过增加的网络层可以训练成恒等映射，就可以认为其可能比原网络更有效。</p>
<script type="math/tex; mode=display">
f(x)=x</script><h3 id="6-2-残差块"><a href="#6-2-残差块" class="headerlink" title="6.2 残差块"></a>6.2 残差块</h3><p>每个附加层都应该更容易地包含原始函数作为其元素之一。如下图所示，左面是直接拟合出映射$f(x)$,而右面则是拟合出$f(x)-x$。其中$f(x)$是理想映射。但是理想网络结构不能保证拟合结果一定是理想情况，右侧至少保证可以不会比$x$更差。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412251415321.svg" alt="residual-block">​</p>
<p>因为需要进行相加，所以输出要与输入规模一致，如果想要改变通道数可以引入$1\times1$卷积层。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412251415784.svg" alt="resnet-block">​</p>
<p>ResNet‐18：</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412251415544.svg" alt="resnet18">​</p>
<h2 id="7-稠密连接网络"><a href="#7-稠密连接网络" class="headerlink" title="7 稠密连接网络"></a>7 稠密连接网络</h2><p>稠密神经网络是残差神经网络结合泰勒展开的产物。</p>
<p>泰勒展开形式如下：</p>
<script type="math/tex; mode=display">
f(x) = f(0) + f'(0) x + \frac{f''(0)}{2!}  x^2 + \frac{f'''(0)}{3!}  x^3 + \ldots</script><p>而稠密连接网络DenseNet相比ResNet的区别在于将相加给位连接。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412251445742.svg" alt="densenet-block">​</p>
<p>这样每经过一次稠密块，都可以保留之前的结果。</p>
<script type="math/tex; mode=display">
\mathbf{x} \to \left[
\mathbf{x},
f_1(\mathbf{x}),
f_2([\mathbf{x}, f_1(\mathbf{x})]), f_3([\mathbf{x}, f_1(\mathbf{x}), f_2([\mathbf{x}, f_1(\mathbf{x})])]), \ldots\right]</script><p>​​</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412251445100.svg" alt="densenet">​</p>
<p>但是稠密层也带来了一个问题随着使用次数的增加，其通道数快速增加。为此需要插入过渡层来控制模型的复杂度，一方面通过 $1 \times 1$ 卷积层来控制通道数，另一方面通过平均汇聚层减小特征图大小。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 《动手学深度学习》 — 动手学深度学习 2.0.0 documentation[EB/OL]. [2024-12-21]. <a href="https://zh.d2l.ai/">https://zh.d2l.ai/</a>.</p>
]]></content>
      <categories>
        <category>赛博土木</category>
        <category>深度学习，基础</category>
      </categories>
      <tags>
        <tag>赛博土木</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>赛博土木A-深度学习08：序列模型基础</title>
    <url>/posts/168e861e.html</url>
    <content><![CDATA[<p>多层感知机和卷积神经网络分别用于处理表格和图像，这两种情况可以认为样本是独立同分布的。但是很多情况样本是有顺序关系的，例如文本、音频和视频。此外还需要根据过去的信息来预测未来的走势，例如股票。为此引入了新的结构—循环神经网络。</p>
<h2 id="1-序列模型"><a href="#1-序列模型" class="headerlink" title="1 序列模型"></a>1 序列模型</h2><p>首先预测分为两种，一种是在观测范围内进行预测,内插法；一种是在观测范围外进行预测，外推法；</p>
<p>基于时间步$t$以及其对应的值进行预测，预测$x_t$:</p>
<script type="math/tex; mode=display">
x_t \sim P(x_t \mid x_{t-1}, \ldots, x_1)</script><h3 id="1-1-自回归模型"><a href="#1-1-自回归模型" class="headerlink" title="1.1 自回归模型"></a>1.1 自回归模型</h3><p>参照线性回归模型，可以建立$x_t$与$x$的映射模型，但是不同于线性回归，样本数量不会变换，对于序列模型而言需要考虑的样本数量会随着$t$的增大而同步增加，意味着模型参数会根据观测对象变化而变化。</p>
<h4 id="1-1-1-自回归模型"><a href="#1-1-1-自回归模型" class="headerlink" title="1.1.1 自回归模型"></a>1.1.1 自回归模型</h4><p>我们可以假定$x_t$只受前面$\tau$跨度（$x_{t-1}, \ldots, x_{t-\tau}$）的影响，这样就可以固定参数的数量，从而训练模型，这种模型被称为自回归模型。</p>
<h4 id="1-1-2-隐变量自回归模型"><a href="#1-1-2-隐变量自回归模型" class="headerlink" title="1.1.2 隐变量自回归模型"></a>1.1.2 隐变量自回归模型</h4><p>自回归模型抛弃了大量的序列，我们也可以之前的序列进行一个总结$h_t$，根据总结去推测，$\hat{x}_t = P(x_t \mid h_{t})$，这样参数数量就不会受序列影响了。总结通过$h_t = g(h_{t-1}, x_{t-1})$更新。因为$h_t$是模型内部的参数既不是输入也不是输出，因此称其为隐变量，故而模型称为隐变量自回归模型。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501031715020.svg" alt="sequence-model">​</p>
<h3 id="1-1-3-问题"><a href="#1-1-3-问题" class="headerlink" title="1.1.3 问题"></a>1.1.3 问题</h3><p>自回归模型存在一个问题，可以利用历史观测来预测下一个数据，是基于序列本身的动力学，但是如果是预测多个数据显然存在问题。因为受新的数据影响其动力学应当是变化的。但是我们只能根据现有数据进行预测，因此事实上假定了序列动力学是不变的。</p>
<script type="math/tex; mode=display">
P(x_1, \ldots, x_T) = \prod_{t=1}^T P(x_t \mid x_{t-1}, \ldots, x_1)</script><h3 id="1-2-马尔可夫模型"><a href="#1-2-马尔可夫模型" class="headerlink" title="1.2 马尔可夫模型"></a>1.2 马尔可夫模型</h3><p>如果状态转换只依赖于前$\tau$个状态（例如自回归模型），那么我们就可该转换过程为一个马尔可夫状态。如果之和前一个状态有关即$\tau =1$,则是最简单的一阶马尔可夫模型：</p>
<script type="math/tex; mode=display">
P(x_1, \ldots, x_T) = \prod_{t=1}^T P(x_t \mid x_{t-1}) ， P(x_1 \mid x_0) = P(x_1)</script><p>当假设$x_t$仅是离散值时，，使用动态规划可以沿着马尔可夫链精确地计算结果。<br>例如，高效地计算$P(x_{t+1} \mid x_{t-1})$：</p>
<script type="math/tex; mode=display">
\begin{aligned}
P(x_{t+1} \mid x_{t-1})
&= \frac{\sum_{x_t} P(x_{t+1}, x_t, x_{t-1})}{P(x_{t-1})}\\
&= \frac{\sum_{x_t} P(x_{t+1} \mid x_t, x_{t-1}) P(x_t, x_{t-1})}{P(x_{t-1})}\\
&= \sum_{x_t} P(x_{t+1} \mid x_t) P(x_t \mid x_{t-1})
\end{aligned}</script><h3 id="1-3-因果关系"><a href="#1-3-因果关系" class="headerlink" title="1.3 因果关系"></a>1.3 因果关系</h3><p>因果关系强强调的是序列有一个自然的方向，通常是时间。解释$P(x_{t+1} \mid x_{t})$ 比观察$P(x_{t} \mid x_{t+1})$更容易。且更具有实际价值。</p>
<p>‍</p>
<h2 id="2-文本数据预处理"><a href="#2-文本数据预处理" class="headerlink" title="2 文本数据预处理"></a>2 文本数据预处理</h2><p>文本数据的预处理主要包括如下的步骤：</p>
<ul>
<li>文本转换为字符串加载到内存中。</li>
<li>字符串拆分为词元（单词和字符）</li>
<li>建立一个词表将拆分的词元映射到数字索引</li>
<li>将文本转换为数字索引序列。</li>
</ul>
<h2 id="3-语言模型"><a href="#3-语言模型" class="headerlink" title="3 语言模型"></a>3 语言模型</h2><p>将文本数据映射为词元数字索引，将这些词元数字索引视为离散的观测序列。对于长度为$T$的文本观测序列 $x_1,x_2,\ldots,x_T$。语言模型的目标是估计序列的联合：</p>
<script type="math/tex; mode=display">
P(x_1, x_2, \ldots, x_T)</script><h3 id="3-1-学习语言模型"><a href="#3-1-学习语言模型" class="headerlink" title="3.1 学习语言模型"></a>3.1 学习语言模型</h3><p>一段文本出现的概率计算方式：</p>
<script type="math/tex; mode=display">
P(x_1, x_2, \ldots, x_T) 
 = \prod_{t=1}^T P(x_t  \mid  x_1, \ldots, x_{t-1})</script><p>计算上式，需要单词的概率，以及给定几个单词后出现某个单词的概率，显然这些概率应该在进行推测之前获得，对应到机器学习中就是模型的参数。</p>
<p>需要构建以足够规模的文本语料库用作训练集。，然后计算单词的频率，以及各种组合的频率。</p>
<script type="math/tex; mode=display">
\hat{P}(\text{learning} \mid \text{deep}) = \frac{n(\text{deep, learning})}{n(\text{deep})}</script><p>随着组合规模的上升，很容易出现组合本身是合理的，但是在训练语料库中很少出现或者没有出现。这样计算概率值为0.</p>
<p>为了解决0概率问题引入了拉普拉斯平滑，拉普拉斯平滑的思想是在一个规模巨大的语料库中对每个词元出现次数$+1$，不会造成什么影响但是可以解决零概率事件。具体方法是在所有计数中添加一个小常量。用$n$表示训练集中的单词总数（重复计数），用$m$表示词元的数量（非重复计数）。其中，$\epsilon_1,\epsilon_2$和$\epsilon_3$是超参数。</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \hat{P}(x) & = \frac{n(x) + \epsilon_1/m}{n + \epsilon_1}, \\
    \hat{P}(x' \mid x) & = \frac{n(x, x') + \epsilon_2 \hat{P}(x')}{n(x) + \epsilon_2}, \\
    \hat{P}(x'' \mid x,x') & = \frac{n(x, x',x'') + \epsilon_3 \hat{P}(x'')}{n(x, x') + \epsilon_3}.
\end{aligned}</script><p>该模型很容无效，一方面是模型参数过多，另一方面完全忽略词义。</p>
<h3 id="3-2-马尔可夫模型"><a href="#3-2-马尔可夫模型" class="headerlink" title="3.2 马尔可夫模型"></a>3.2 马尔可夫模型</h3><p>马尔可夫模型根据涉及元素的多少分为一元语法、二元语法、三元语法模型。</p>
<script type="math/tex; mode=display">
\begin{aligned}
P(x_1, x_2, x_3, x_4) &=  P(x_1) P(x_2) P(x_3) P(x_4),\\
P(x_1, x_2, x_3, x_4) &=  P(x_1) P(x_2  \mid  x_1) P(x_3  \mid  x_2) P(x_4  \mid  x_3),\\
P(x_1, x_2, x_3, x_4) &=  P(x_1) P(x_2  \mid  x_1) P(x_3  \mid  x_1, x_2) P(x_4  \mid  x_2, x_3).
\end{aligned}</script><h3 id="3-3-自然语言统计"><a href="#3-3-自然语言统计" class="headerlink" title="3.3 自然语言统计"></a>3.3 自然语言统计</h3><p>根据自然语言统计，词频遵循齐普夫定律，即第<em>$i$</em>个最常用单词的频率为$n_i$：</p>
<script type="math/tex; mode=display">
n_i \propto \frac{1}{i^\alpha},</script><p>等价：</p>
<script type="math/tex; mode=display">
\log n_i = -\alpha \log i + c</script><p>对n元语法模型的词元频率进行分析：</p>
<ul>
<li>单词序列也遵循齐普夫定律。</li>
<li>此表中$n$元组的数量并不多</li>
<li>n元组很少出现。</li>
</ul>
<h3 id="3-4-读取序列长度"><a href="#3-4-读取序列长度" class="headerlink" title="3.4 读取序列长度"></a>3.4 读取序列长度</h3><p>神经网络一次处理具有预定长度（$n$ 个时间步）的一个小批量序列。</p>
<h4 id="3-4-1-随机采样"><a href="#3-4-1-随机采样" class="headerlink" title="3.4.1 随机采样"></a>3.4.1 随机采样</h4><p>在随机采样中,每个样本都是在原始的长序列上任意捕获的子序列。对于语言建模,目标是基于到目前为止我们看到的词元来预测下一个词元,因此标签是移位了一个词元的原始序列。</p>
<h4 id="3-4-2-顺序分区"><a href="#3-4-2-顺序分区" class="headerlink" title="3.4.2 顺序分区"></a>3.4.2 顺序分区</h4><p>不同于随机采样相邻，顺序分区方式中相邻小批量中的子序列在原始序列上是相邻的。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 《动手学深度学习》 — 动手学深度学习 2.0.0 documentation[EB/OL]. [2024-12-21]. <a href="https://zh.d2l.ai/">https://zh.d2l.ai/</a>.</p>
]]></content>
      <categories>
        <category>赛博土木</category>
        <category>深度学习，基础</category>
      </categories>
      <tags>
        <tag>赛博土木</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>赛博土木A-深度学习09：循环神经网络</title>
    <url>/posts/95c64ca1.html</url>
    <content><![CDATA[<h2 id="1-无隐状态的神经网络"><a href="#1-无隐状态的神经网络" class="headerlink" title="1 无隐状态的神经网络"></a>1 无隐状态的神经网络</h2><p>单隐藏层的MLP 结构如下：</p>
<script type="math/tex; mode=display">
\mathbf{H} = \phi(\mathbf{X} \mathbf{W}_{xh} + \mathbf{b}_h)</script><script type="math/tex; mode=display">
\mathbf{O} = \mathbf{H} \mathbf{W}_{hq} + \mathbf{b}_q</script><p>其中$\mathbf{H}$是隐藏层。</p>
<h2 id="2-有隐状态的循环神经网络"><a href="#2-有隐状态的循环神经网络" class="headerlink" title="2 有隐状态的循环神经网络"></a>2 有隐状态的循环神经网络</h2><p>隐藏状态的表示如下：</p>
<script type="math/tex; mode=display">
\mathbf{H}_t = \phi(\mathbf{X}_t \mathbf{W}_{xh} + \mathbf{H}_{t-1} \mathbf{W}_{hh}  + \mathbf{b}_h)</script><script type="math/tex; mode=display">
\mathbf{O}_t = \mathbf{H}_t \mathbf{W}_{hq} + \mathbf{b}_q</script><p>不同于MLP，新增了 $\mathbf{H}_{t-1} \mathbf{W}_{hh}$ 结构用保留序列的历史信息。并且隐状态是随着时间步变换而同步变化的，因此会循环计算 $\mathbf{H}_t$ 。因此将这类循环计算隐状态的神经网络称为循环神经网络。计算隐状态的层被称为循环层。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501031715321.svg" alt="rnn">​</p>
<p>‍</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 《动手学深度学习》 — 动手学深度学习 2.0.0 documentation[EB/OL]. [2024-12-21]. <a href="https://zh.d2l.ai/">https://zh.d2l.ai/</a>.</p>
]]></content>
      <categories>
        <category>赛博土木</category>
        <category>深度学习，基础</category>
      </categories>
      <tags>
        <tag>赛博土木</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>赛博土木A-深度学习10：现代循环神经网络</title>
    <url>/posts/8ea7f284.html</url>
    <content><![CDATA[<h2 id="1-门控循环单元（GRU）"><a href="#1-门控循环单元（GRU）" class="headerlink" title="1 门控循环单元（GRU）"></a>1 门控循环单元（GRU）</h2><p>门控循环单元引入了对因状态的门控，意味着有专门的机制来控制新状态更新与重置的时机</p>
<h5 id="重置门和更新门"><a href="#重置门和更新门" class="headerlink" title="重置门和更新门"></a>重置门和更新门</h5><p>重置门（$\mathbf{R}_t$）和更新门（$\mathbf{Z}_t$）的结构如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{R}_t = \sigma(\mathbf{X}_t \mathbf{W}_{xr} + \mathbf{H}_{t-1} \mathbf{W}_{hr} + \mathbf{b}_r),\\
\mathbf{Z}_t = \sigma(\mathbf{X}_t \mathbf{W}_{xz} + \mathbf{H}_{t-1} \mathbf{W}_{hz} + \mathbf{b}_z),
\end{aligned}</script><p>其中$\mathbf{W}_{xr}, \mathbf{W}_{xz} \in \mathbb{R}^{d \times h}$和$\mathbf{W}_{hr}, \mathbf{W}_{hz} \in \mathbb{R}^{h \times h}$是权重参数，$\mathbf{b}_r, \mathbf{b}_z \in \mathbb{R}^{1 \times h}$是偏置参数。</p>
<h5 id="候选隐状态"><a href="#候选隐状态" class="headerlink" title="候选隐状态"></a>候选隐状态</h5><p>时间步$t$的候选隐状态$\tilde{\mathbf{H}}_t \in \mathbb{R}^{n \times h}$：</p>
<script type="math/tex; mode=display">
\tilde{\mathbf{H}}_t = \tanh(\mathbf{X}_t \mathbf{W}_{xh} + \left(\mathbf{R}_t \odot \mathbf{H}_{t-1}\right) \mathbf{W}_{hh} + \mathbf{b}_h),</script><p>其中$\mathbf{W}_{xh} \in \mathbb{R}^{d \times h}$和$\mathbf{W}_{hh} \in \mathbb{R}^{h \times h}$是权重参数，$\mathbf{b}_h \in \mathbb{R}^{1 \times h}$是偏置项，符号$\odot$是Hadamard积（按元素乘积）运算符。在这里，我们使用tanh非线性激活函数来确保候选隐状态中的值保持在区间(-1, 1)中。</p>
<h5 id="隐状态"><a href="#隐状态" class="headerlink" title="隐状态"></a>隐状态</h5><p>隐状态如下</p>
<script type="math/tex; mode=display">
\mathbf{H}_t = \mathbf{Z}_t \odot \mathbf{H}_{t-1}  + (1 - \mathbf{Z}_t) \odot \tilde{\mathbf{H}}_t</script><p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501021032972.svg" alt="gru-3">​</p>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p><strong>更新门：</strong> 决定了多少过去的信息应该被传递到未来。</p>
<p><strong>重置门：</strong> 决定了如何将新的输入信息与先前的记忆结合。</p>
<h2 id="2-长短期记忆网络（LSTM）"><a href="#2-长短期记忆网络（LSTM）" class="headerlink" title="2 长短期记忆网络（LSTM）"></a>2 长短期记忆网络（LSTM）</h2><p>  LSTM 结构如下：</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501021041391.svg" alt="lstm-3">​  </p>
<p>假设有$h$个隐藏单元，批量大小为$n$，输入数为$d$。因此，输入为$\mathbf{X}_t \in \mathbb{R}^{n \times d}$，前一时间步的隐状态为$\mathbf{H}_{t-1} \in \mathbb{R}^{n \times h}$。相应地，时间步t的门被定义如下：输入门是$\mathbf{I}_t \in \mathbb{R}^{n \times h}$，遗忘门是$\mathbf{F}_t \in \mathbb{R}^{n \times h}$，输出门是$\mathbf{O}_t \in \mathbb{R}^{n \times h}$。它们的计算方法如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{I}_t &= \sigma(\mathbf{X}_t \mathbf{W}_{xi} + \mathbf{H}_{t-1} \mathbf{W}_{hi} + \mathbf{b}_i),\\
\mathbf{F}_t &= \sigma(\mathbf{X}_t \mathbf{W}_{xf} + \mathbf{H}_{t-1} \mathbf{W}_{hf} + \mathbf{b}_f),\\
\mathbf{O}_t &= \sigma(\mathbf{X}_t \mathbf{W}_{xo} + \mathbf{H}_{t-1} \mathbf{W}_{ho} + \mathbf{b}_o),
\end{aligned}</script><p>其中$\mathbf{W}_{xi}, \mathbf{W}_{xf}, \mathbf{W}_{xo} \in \mathbb{R}^{d \times h}$和$\mathbf{W}_{hi}$, $\mathbf{W}_{hf}$, $\mathbf{W}_{ho} \in \mathbb{R}^{h \times h}$是权重参数，$\mathbf{b}_i,$ $\mathbf{b}_f, \mathbf{b}_o \in \mathbb{R}^{1 \times h}$是偏置参数。</p>
<p>候选记忆单元$\tilde{\mathbf{C}}_t \in \mathbb{R}^{n \times h}$：</p>
<script type="math/tex; mode=display">
\tilde{\mathbf{C}}_t = \text{tanh}(\mathbf{X}_t \mathbf{W}_{xc} + \mathbf{H}_{t-1} \mathbf{W}_{hc} + \mathbf{b}_c)</script><p>记忆元$\mathbf{C}_t \in \mathbb{R}^{n \times h}$：</p>
<script type="math/tex; mode=display">
\mathbf{C}_t = \mathbf{F}_t \odot \mathbf{C}_{t-1} + \mathbf{I}_t \odot \tilde{\mathbf{C}}_t</script><p>隐状态$\mathbf{H}_t \in \mathbb{R}^{n \times h}$：</p>
<script type="math/tex; mode=display">
\mathbf{H}_t = \mathbf{O}_t \odot \tanh(\mathbf{C}_t)</script><h2 id="3-深度循环网络"><a href="#3-深度循环网络" class="headerlink" title="3 深度循环网络"></a>3 深度循环网络</h2><p>对于$L$个隐藏层的深度循环神经网络每一个隐藏层表示如下：</p>
<script type="math/tex; mode=display">
\mathbf{H}_t^{(l)} = \phi_l(\mathbf{H}_t^{(l-1)} \mathbf{W}_{xh}^{(l)} + \mathbf{H}_{t-1}^{(l)} \mathbf{W}_{hh}^{(l)}  + \mathbf{b}_h^{(l)})</script><p>最后的输出只与最后一层隐藏层有关</p>
<script type="math/tex; mode=display">
\mathbf{O}_t = \mathbf{H}_t^{(L)} \mathbf{W}_{hq} + \mathbf{b}_q</script><p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501021112064.svg" alt="deep-rnn">​</p>
<h2 id="4-双向模型"><a href="#4-双向模型" class="headerlink" title="4 双向模型"></a>4 双向模型</h2><p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501021351483.svg" alt="birnn">​</p>
<p>对于任意时间步$t$，给定一个小批量的输入数据<br>$\mathbf{X}_t \in \mathbb{R}^{n \times d}$（样本数$n$，每个示例中的输入数$d$），并且令隐藏层激活函数为$\phi$。在双向架构中，设该时间步的前向和反向隐状态分别为$\overrightarrow{\mathbf{H}}_t  \in \mathbb{R}^{n \times h}$和$\overleftarrow{\mathbf{H}}_t  \in \mathbb{R}^{n \times h}$，其中$h$是隐藏单元的数目。<br>前向和反向隐状态的更新如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\overrightarrow{\mathbf{H}}_t &= \phi(\mathbf{X}_t \mathbf{W}_{xh}^{(f)} + \overrightarrow{\mathbf{H}}_{t-1} \mathbf{W}_{hh}^{(f)}  + \mathbf{b}_h^{(f)}),\\
\overleftarrow{\mathbf{H}}_t &= \phi(\mathbf{X}_t \mathbf{W}_{xh}^{(b)} + \overleftarrow{\mathbf{H}}_{t+1} \mathbf{W}_{hh}^{(b)}  + \mathbf{b}_h^{(b)}),
\end{aligned}</script><p>其中，权重$\mathbf{W}_{xh}^{(f)} \in \mathbb{R}^{d \times h}, \mathbf{W}_{hh}^{(f)} \in \mathbb{R}^{h \times h}, \mathbf{W}_{xh}^{(b)} \in \mathbb{R}^{d \times h}, \mathbf{W}_{hh}^{(b)} \in \mathbb{R}^{h \times h}$和偏置$\mathbf{b}_h^{(f)} \in \mathbb{R}^{1 \times h}, \mathbf{b}_h^{(b)} \in \mathbb{R}^{1 \times h}$都是模型参数。</p>
<p>‍</p>
<h2 id="5-序列到序列学习"><a href="#5-序列到序列学习" class="headerlink" title="5 序列到序列学习"></a>5 序列到序列学习</h2><p>机器翻译是一种常用的应用场景，即将输入序列转换为输出序列。输入序列与输出序列均是可变序列。</p>
<p>为此引入编码器与解码器架构：</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501021351042.svg" alt="encoder-decoder">​</p>
<p><strong>编码器</strong>（encoder）：接受一个长度可变的序列作为输入，并将其转换为具有固定形状的编码状态。</p>
<p><strong>解码器</strong>（decoder）：它将固定形状的编码状态映射到长度可变的序列。</p>
<p>‍</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501021351648.svg" alt="seq2seq">​</p>
<p>“<eos>”表示序列结束词元。一旦输出序列生成此词元,模型就会停止预测。“<bos>”表示序列开始词元,它是解码器的输入序列的第一个词元。使用循环神经网络编码器最终的隐状态来初始化解码器的隐状态。</p>
<p>嵌入层的权重是一个矩阵,其行数等于输入词表的大小(vocab_size),其列数等于特征向量的维度(embed_size)。对于任意输入词元的索引i,嵌入层获取权重矩阵的第i行(从0开始)以返回其特征向量。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501031710816.svg" alt="seq2seq-details">​</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 《动手学深度学习》 — 动手学深度学习 2.0.0 documentation[EB/OL]. [2024-12-21]. <a href="https://zh.d2l.ai/">https://zh.d2l.ai/</a>.</p>
]]></content>
      <categories>
        <category>赛博土木</category>
        <category>深度学习，基础</category>
      </categories>
      <tags>
        <tag>赛博土木</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>赛博土木A-深度学习11：注意力机制</title>
    <url>/posts/1cbcd929.html</url>
    <content><![CDATA[<h2 id="1-注意力提示"><a href="#1-注意力提示" class="headerlink" title="1 注意力提示"></a>1 注意力提示</h2><p>人类的注意力提示存在两种模式，分别是自主性与非自主性。非自主性是受外界环境影响例如突出的颜色，而自主性则是受人的主观影响。</p>
<p>非自主性注意力提示可以通过全连接层和池化层进行实现。</p>
<p>注意力机制引入了自主性提示（查询）。将感官输入称为值，每一个值都对应一个键。注意力机制通过注意力汇聚的方式，将查询与键进行匹配，进而引导至对应的值上。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501031708167.svg" alt="qkv">​</p>
<h2 id="2-Nadaraya-Watson核回归"><a href="#2-Nadaraya-Watson核回归" class="headerlink" title="2 Nadaraya-Watson核回归"></a>2 Nadaraya-Watson核回归</h2><p>对于回归问题最简单的估计器则是平均汇聚：</p>
<script type="math/tex; mode=display">
f(x)=\frac{1}{n}\sum_{i=1}^ny_i</script><p>平均汇聚忽略了输入$x_i$,Nadaraya-Watson核回归输入的位置对输出$y_i$进行加权，其中$K$是核：</p>
<script type="math/tex; mode=display">
f(x) = \sum_{i=1}^n \frac{K(x - x_i)}{\sum_{j=1}^n K(x - x_j)} y_i</script><p>可以给出更一般的表示：</p>
<script type="math/tex; mode=display">
f(x) = \sum_{i=1}^n \alpha(x, x_i) y_i</script><p>$x$表示查询，$(x_i,y_i)$表示键值对。用$\alpha(x,x_i)$表示键与查询的关系。</p>
<p>采用高斯核$K(u) = \frac{1}{\sqrt{2\pi}} \exp(-\frac{u^2}{2})$：</p>
<script type="math/tex; mode=display">
\begin{aligned} f(x) &=\sum_{i=1}^n \alpha(x, x_i) y_i\\ &= \sum_{i=1}^n \frac{\exp\left(-\frac{1}{2}(x - x_i)^2\right)}{\sum_{j=1}^n \exp\left(-\frac{1}{2}(x - x_j)^2\right)} y_i \\&= \sum_{i=1}^n \mathrm{softmax}\left(-\frac{1}{2}(x - x_i)^2\right) y_i \end{aligned}</script><p>也可以引入参数：</p>
<script type="math/tex; mode=display">
\begin{aligned}f(x) &= \sum_{i=1}^n \alpha(x, x_i) y_i \\&= \sum_{i=1}^n \frac{\exp\left(-\frac{1}{2}((x - x_i)w)^2\right)}{\sum_{j=1}^n \exp\left(-\frac{1}{2}((x - x_j)w)^2\right)} y_i \\&= \sum_{i=1}^n \mathrm{softmax}\left(-\frac{1}{2}((x - x_i)w)^2\right) y_i\end{aligned}</script><h2 id="3-注意力评分函数"><a href="#3-注意力评分函数" class="headerlink" title="3 注意力评分函数"></a>3 注意力评分函数</h2><p>将高斯核的指数部分称为注意力评分函数，简称评分函数。如下图所示，$a$ 表示注意力评分函数，其结果通过softmax函数后得到概率分布，最后和值结合获得一个加权平均值。</p>
<p>‍</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501031708487.svg" alt="attention-output">​</p>
<p>用数学语言描述，假设有一个查询$\mathbf{q}\in\mathbb{R}^q$和$m$个“键－值”对$(\mathbf{k}_1,\mathbf{v}_1),\ldots,(\mathbf{k}_m,\mathbf{v}_m)$，其中$\mathbf{k}_i\in\mathbb{R}^k$，$\mathbf{v}_i\in\mathbb{R}^v$。注意力汇聚函数$f$就被表示成值的加权和：</p>
<script type="math/tex; mode=display">
f(\mathbf{q},(\mathbf{k}_1,\mathbf{v}_1),\ldots,(\mathbf{k}_m,\mathbf{v}_m))=\sum_{i=1}^m\alpha(\mathbf{q},\mathbf{k}_i)\mathbf{v}_i\in\mathbb{R}^v,</script><p>$\mathbf{q}$和键$\mathbf{k}_i$的注意力权重（标量）是通过注意力评分函数将两个向量映射成标量，再经过softmax运算得到的：</p>
<script type="math/tex; mode=display">
\alpha(\mathbf{q},\mathbf{k}_i)=\mathrm{softmax}(a(\mathbf{q},\mathbf{k}_i))=\frac{\exp(a(\mathbf{q},\mathbf{k}_i))}{\sum_{j=1}^m\exp(a(\mathbf{q},\mathbf{k}_j))}\in\mathbb{R}.</script><p> 选择不同的注意力评分函数a会导致不同的注意力汇聚操作。</p>
<h2 id="4-Bahdanau注意力"><a href="#4-Bahdanau注意力" class="headerlink" title="4 Bahdanau注意力"></a>4 Bahdanau注意力</h2><p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501031709489.svg" alt="seq2seq-attention-details">​</p>
<h2 id="5-多头注意力"><a href="#5-多头注意力" class="headerlink" title="5 多头注意力"></a>5 多头注意力</h2><p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501031709770.svg" alt="multi-head-attention">​</p>
<h2 id="6-transformer"><a href="#6-transformer" class="headerlink" title="6 transformer"></a>6 transformer</h2><p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202501031709730.svg" alt="transformer">​</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] 《动手学深度学习》 — 动手学深度学习 2.0.0 documentation[EB/OL]. [2024-12-21]. <a href="https://zh.d2l.ai/">https://zh.d2l.ai/</a>.</p>
]]></content>
      <categories>
        <category>赛博土木</category>
        <category>深度学习，基础</category>
      </categories>
      <tags>
        <tag>赛博土木</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Word 写论文</title>
    <url>/posts/fc1d140d.html</url>
    <content><![CDATA[<h3 id="1-页边距"><a href="#1-页边距" class="headerlink" title="1 页边距"></a>1 页边距</h3><p>举例：设置页边距上下2.5cm 左右3.0cm。根据边距，建议将页眉页脚设置为2cm（个人建议）。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412111634163.png" alt="image">​</p>
<h3 id="2-分节"><a href="#2-分节" class="headerlink" title="2 分节"></a>2 分节</h3><p>论文分为多个部分，为了防止修改一部分而影响全局，可以将各部分进行分节处理。中文摘要（含关键词）-英文摘要（含关键词）-目录-正文（每一章）-参考文献-致谢-附录，每部分各做为一节。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412111635438.png" alt="image">​</p>
<h3 id="3-页眉"><a href="#3-页眉" class="headerlink" title="3 页眉"></a>3 页眉</h3><p>页眉同行包含框线，这里采用的时一磅的边框线。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412111637264.png" alt="image">​</p>
<p>因为进行了分节，所以需要在每一节添加页眉，如果封面出现页眉，删除内容，然后清除格式即可解决。以前的规范没有要求奇偶不同，如果新的规范要求奇偶不同。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412111637641.png" alt="image">​</p>
<h3 id="4-页码"><a href="#4-页码" class="headerlink" title="4 页码"></a>4 页码</h3><p>页脚用于设置页码，正文前的部分（摘要和目录），正文以及之后采用阿拉伯数字。第一节不要选续前节，后续节采用续前节。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412111638823.png" alt="image">​</p>
<h3 id="5-字体"><a href="#5-字体" class="headerlink" title="5 字体"></a>5 字体</h3><p>修改主题字体，中文采用宋体，西文为Times New Roma，后文设置样式时只提及字号默认采用了主题字体。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412111638458.png" alt="image">​</p>
<h3 id="6-样式"><a href="#6-样式" class="headerlink" title="6 样式"></a>6 样式</h3><p>样式对于word极为关键，所以需要先对样式进行设置，有些样式如题注只有在添加时才出现。下面给出一些需要设置的样式</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412111652315.png" alt="image">​</p>
<p>‍</p>
<h3 id="7-目录"><a href="#7-目录" class="headerlink" title="7 目录"></a>7 目录</h3><p>目录主要设置各级标题在目录中的表示形式，以及显示哪些标题。这就是为什么同样是非正文标题要单独设置摘要目录以及正文后标题两种。目录摘要是一级标题但是不出现在目录中。而结论等正文后一级标题需要在目录中显示。写完了记得更新目录。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412111653551.png" alt="image">​</p>
<h3 id="8-题注"><a href="#8-题注" class="headerlink" title="8 题注"></a>8 题注</h3><p>图表数量和位置可能会变动，为了方便建议使用题注进行编号。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412111640188.png" alt="image">​</p>
<h2 id="9-引用"><a href="#9-引用" class="headerlink" title="9 引用"></a>9 引用</h2><p>论文中通常只存在图表和参考文献的引用，建议使用交叉引用。在需要正文引用的位置点交叉引用。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202412111645491.png" alt="image">​</p>
<p>‍</p>
]]></content>
      <categories>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>学术</tag>
      </tags>
  </entry>
  <entry>
    <title>学术工具速览</title>
    <url>/posts/fcebcda5.html</url>
    <content><![CDATA[<h2 id="论文搜索"><a href="#论文搜索" class="headerlink" title="论文搜索"></a>论文搜索</h2><p>论文搜索直接使用谷歌学术。</p>
<p>介绍一个论文标记插件：CCFrank，可以标记论文所在期刊会议在CCF评价体系中的分类。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202411271625983.png" alt="image">​</p>
<h2 id="论文管理"><a href="#论文管理" class="headerlink" title="论文管理"></a>论文管理</h2><p>论文管理工具推荐<a href="https://www.zotero.org/download/">Zotero </a>，顺便安装一下浏览器插件方便添加。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202411271628884.png" alt="image">​</p>
<p>去<a href="https://zotero-chinese.com/plugins/#search=mar">Zotero 插件商店 </a>插件市场下载市场插件(注意版本)。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202411271729136.png" alt="image">​</p>
<p>下载后在zotero中点加导航栏-&gt;工具-&gt;插件 将下载的.xpi文件拖到插件窗口中。</p>
<p>此时导航栏-&gt;工具下出现插件市场，建议安装下述两个插件。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202411271730079.png" alt="image">​</p>
<h4 id="向zotero添加条目"><a href="#向zotero添加条目" class="headerlink" title="向zotero添加条目"></a>向zotero添加条目</h4><p>在“我的文库”中创建目录然后打开目录保持zotero打开状态，去往浏览器，找到需要的资源点击插件添加。如果想要保存论文pdf，需要先获取访问许可。访问许可认证选择机构，填写Shandong university 就行。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202411271714542.png" alt="image">​</p>
<h4 id="生成文献"><a href="#生成文献" class="headerlink" title="生成文献"></a>生成文献</h4><p>可以直接点击条目右键选择用算选条目建立参考文献，选择相应的输出格式即可。</p>
<p>国内需要使用国标格式</p>
<p>在导航栏-&gt;设置-&gt;引用-&gt;获得更多样式，搜索china添加即可</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202411271721679.png" alt="image">​</p>
<h4 id="word使用"><a href="#word使用" class="headerlink" title="word使用"></a>word使用</h4><p>在想要插入文献的位置，选择插入引用，在出现的搜索栏中搜索相应的条目加入即可。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202411271714320.png" alt="image">​</p>
<p>全部加入后，在参考文献部分生成列表</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202411271718780.png" alt="image">​</p>
<h2 id="翻译工具"><a href="#翻译工具" class="headerlink" title="翻译工具"></a>翻译工具</h2><p>翻译工具可以使用<a href="https://www.zhiyunwenxian.cn/">知云文献翻译客户端软件</a>，提供了知云翻译和xtranslator两种工具，后者可以在任意页面使用，前者需要将文件导入知云。</p>
<h2 id="写作工具"><a href="#写作工具" class="headerlink" title="写作工具"></a>写作工具</h2><p>overleaf多人协作组里有会员账号。</p>
<h2 id="笔记工具"><a href="#笔记工具" class="headerlink" title="笔记工具"></a>笔记工具</h2><p>国内推荐思源或者Typora</p>
<h2 id="绘图工具"><a href="#绘图工具" class="headerlink" title="绘图工具"></a>绘图工具</h2><p>word推荐Visio <a href="https://softms.sdu.edu.cn/index.html">山东大学正版软件平台</a>。</p>
<p>Adobe illustrator <a href="https://softms.sdu.edu.cn/index.html">山东大学正版软件平台</a>。</p>
<p>数据处理使用python <a href="https://matplotlib.org/">Matplotlib</a>库。</p>
<h2 id="论文写作标准"><a href="#论文写作标准" class="headerlink" title="论文写作标准"></a>论文写作标准</h2><p>‍</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">代号</th>
<th style="text-align:center">名称</th>
<th style="text-align:center">地址</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">GB/T 7713.2—2022</td>
<td style="text-align:center">学术论文编写规则</td>
<td style="text-align:center"><a href="https://onedrive-blue.vercel.app/api/raw/?path=/%E6%A0%87%E5%87%86%E6%96%87%E4%BB%B6/GBT7713_2-2022-%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%E6%92%B0%E5%86%99%E8%A7%84%E5%88%99.pdf">下载地址</a></td>
</tr>
<tr>
<td style="text-align:center">GB 7714—2015</td>
<td style="text-align:center">信息与文献 参考文献著录规则</td>
<td style="text-align:center"><a href="https://onedrive-blue.vercel.app/api/raw/?path=/%E6%A0%87%E5%87%86%E6%96%87%E4%BB%B6/GBT7714-2015-%E4%BF%A1%E6%81%AF%E4%B8%8E%E6%96%87%E7%8C%AE%20%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E8%91%97%E5%BD%95%E8%A7%84%E5%88%99.pdf">下载地址</a></td>
</tr>
<tr>
<td style="text-align:center">GB/T 3179—2009</td>
<td style="text-align:center">期刊编排格式</td>
<td style="text-align:center"><a href="https://onedrive-blue.vercel.app/api/raw/?path=/%E6%A0%87%E5%87%86%E6%96%87%E4%BB%B6/GBT3179-2009-%E6%9C%9F%E5%88%8A%E7%BC%96%E6%8E%92%E6%A0%BC%E5%BC%8F.pdf">下载地址</a></td>
</tr>
<tr>
<td style="text-align:center">GB/T 15834—2011</td>
<td style="text-align:center">标点符号用法</td>
<td style="text-align:center"><a href="https://onedrive-blue.vercel.app/api/raw/?path=/%E6%A0%87%E5%87%86%E6%96%87%E4%BB%B6/GBT15834-2011-%E6%A0%87%E7%82%B9%E7%AC%A6%E5%8F%B7%E7%94%A8%E6%B3%95.pdf">下载地址</a></td>
</tr>
<tr>
<td style="text-align:center">GB/T 15835—2011</td>
<td style="text-align:center">出版物上数字用法</td>
<td style="text-align:center"><a href="https://onedrive-blue.vercel.app/api/raw/?path=/%E6%A0%87%E5%87%86%E6%96%87%E4%BB%B6/GBT15835-2011-%E5%87%BA%E7%89%88%E7%89%A9%E4%B8%8A%E6%95%B0%E5%AD%97%E7%94%A8%E6%B3%95.pdf">下载地址</a></td>
</tr>
<tr>
<td style="text-align:center">GB 3100—1993</td>
<td style="text-align:center">国际单位制及其应用</td>
<td style="text-align:center"><a href="https://onedrive-blue.vercel.app/api/raw/?path=/%E6%A0%87%E5%87%86%E6%96%87%E4%BB%B6/GB3100-1993-%E5%9B%BD%E9%99%85%E5%8D%95%E4%BD%8D%E5%88%B6%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8.pdf">下载地址</a></td>
</tr>
<tr>
<td style="text-align:center">GB/T 7408—2005</td>
<td style="text-align:center">数据元和交换格式 信息交换 日期和时间表示法</td>
<td style="text-align:center"><a href="https://onedrive-blue.vercel.app/api/raw/?path=/%E6%A0%87%E5%87%86%E6%96%87%E4%BB%B6/GBT7408-2005-%E6%95%B0%E6%8D%AE%E5%85%83%E5%92%8C%E4%BA%A4%E6%8D%A2%E6%A0%BC%E5%BC%8F%20%E4%BF%A1%E6%81%AF%E4%BA%A4%E6%8D%A2%20%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E8%A1%A8%E7%A4%BA%E6%B3%95.pdf">下载地址</a></td>
</tr>
<tr>
<td style="text-align:center">CY/T 35—2001</td>
<td style="text-align:center">文献章节编号方法</td>
<td style="text-align:center"><a href="https://onedrive-blue.vercel.app/api/raw/?path=/%E6%A0%87%E5%87%86%E6%96%87%E4%BB%B6/CYT35-2001-%E6%96%87%E7%8C%AE%E7%AB%A0%E8%8A%82%E7%BC%96%E5%8F%B7%E6%96%B9%E6%B3%95.pdf">下载地址</a></td>
</tr>
<tr>
<td style="text-align:center">CY/T 154—2017</td>
<td style="text-align:center">中文出版物夹用英文的编辑规范</td>
<td style="text-align:center"><a href="https://onedrive-blue.vercel.app/api/raw/?path=/%E6%A0%87%E5%87%86%E6%96%87%E4%BB%B6/CYT154-2017-%E4%B8%AD%E6%96%87%E5%87%BA%E7%89%88%E7%89%A9%E5%A4%B9%E7%94%A8%E8%8B%B1%E6%96%87%E7%9A%84%E7%BC%96%E8%BE%91%E6%A0%87%E5%87%86.pdf">下载地址</a></td>
</tr>
<tr>
<td style="text-align:center">CY/T 170—2019</td>
<td style="text-align:center">学术出版规范表格</td>
<td style="text-align:center"><a href="https://onedrive-blue.vercel.app/api/raw/?path=/%E6%A0%87%E5%87%86%E6%96%87%E4%BB%B6/CYT170-2019-%E5%AD%A6%E6%9C%AF%E5%87%BA%E7%89%88%E8%A7%84%E8%8C%83%E8%A1%A8%E6%A0%BC.pdf">下载地址</a></td>
</tr>
<tr>
<td style="text-align:center">CY/T 171—2019</td>
<td style="text-align:center">学术出版规范插图</td>
<td style="text-align:center"><a href="https://onedrive-blue.vercel.app/api/raw/?path=/%E6%A0%87%E5%87%86%E6%96%87%E4%BB%B6/CYT171-2019-%E5%AD%A6%E6%9C%AF%E5%87%BA%E7%89%88%E8%A7%84%E8%8C%83%E6%8F%92%E5%9B%BE.pdf">下载地址</a></td>
</tr>
<tr>
<td style="text-align:center">CY/T 171—2019</td>
<td style="text-align:center">学术出版规范插图 (visio模板)</td>
<td style="text-align:center"><a href="https://onedrive-blue.vercel.app/api/raw/?path=/%E6%A0%87%E5%87%86%E6%96%87%E4%BB%B6/gb1526-1989-visio%E6%A8%A1%E6%9D%BF.vssx">下载地址</a></td>
</tr>
<tr>
<td style="text-align:center">GB 7714—2015</td>
<td style="text-align:center">参考文献（biblatex说明）</td>
<td style="text-align:center"><a href="https://onedrive-blue.vercel.app/api/raw/?path=/%E6%A0%87%E5%87%86%E6%96%87%E4%BB%B6/biblatex-gb7714-2015.pdf">下载地址</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">汉英深圳公示语辞典</td>
<td style="text-align:center"><a href="https://onedrive-blue.vercel.app/api/raw/?path=/%E6%A0%87%E5%87%86%E6%96%87%E4%BB%B6/%E6%B1%89%E8%8B%B1%E6%B7%B1%E5%9C%B3%E5%85%AC%E7%A4%BA%E8%AF%AD%E8%BE%9E%E5%85%B8.pdf">下载地址</a></td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>学术</tag>
      </tags>
  </entry>
  <entry>
    <title>CUDA 环境配置</title>
    <url>/posts/a1546b3a.html</url>
    <content><![CDATA[<h2 id="1-cuda安装"><a href="#1-cuda安装" class="headerlink" title="1 cuda安装"></a>1 cuda安装</h2><p>首先查看操作系统版本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat /proc/version</span><br></pre></td></tr></table></figure>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202410101440777.png" alt="image">​</p>
<p>前往官网，找到对应的版本<a href="https://developer.nvidia.com/cuda-downloads">CUDA Toolkit  Downloads | NVIDIA Developer</a> ，选择runfile即可，操作比较简单。选择后，下面会给出相应的操作指南。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202410101442652.png" alt="image">​</p>
<p>为了方便管理建议直接在/usr/local 目录下新建子目录用以存放，最好修改文件的权限使得所有人都可以执行，如果你不想每次掉驱动都自己来安装。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod o+x cuda_12.6.2_560.35.03_linux.run </span><br></pre></td></tr></table></figure>
<p>在执行安装前，先执行如下命令，确定有无驱动。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nvdia-smi</span><br></pre></td></tr></table></figure>
<p>有驱动：<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202410101452947.png" alt="image">​</p>
<p>无驱动：</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202410101453297.png" alt="image">​</p>
<p>执行脚本,进入安装界面，输入accept，回车即可。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202410101456121.png" alt="image">​</p>
<p>根据需要选择相应的选项，如果前面的测试驱动已经安装了，这里的Driver就不用选了。若是只想安装驱动，则只选择驱动这项就可以。选择好后install，如果已经安装过其他版本会提示升级，yes即可。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202410101459572.png" alt="image">​</p>
<p>‍</p>
<h2 id="2-环境配置"><a href="#2-环境配置" class="headerlink" title="2 环境配置"></a>2 环境配置</h2><p>创建一个cuda_env.sh 文件将下面的内容写入，注意nsight需要根据实际版本切换。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export CUDA_HOME=/usr/local/cuda</span><br><span class="line">export PATH=$CUDA_HOME/bin:$PATH</span><br><span class="line">export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH</span><br><span class="line">export CPLUS_INCLUDE_PATH=$CUDA_HOME/include:$CPLUS_INCLUDE_PATH</span><br><span class="line">export PATH=$CUDA_HOME/nsight-compute-2024.3.0:$PATH</span><br><span class="line">export PATH=$CUDA_HOME/nsight-systems-2024.4.2:$PATH</span><br></pre></td></tr></table></figure>
<p>然后追加到自己的.bashrc中，并更新一下环境。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo &quot;source /usr/local/cuda_env.sh&quot;  &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>
<h2 id="3-版本切换"><a href="#3-版本切换" class="headerlink" title="3 版本切换"></a>3 版本切换</h2><p>切换就是先删除原有版本的cuda链接，然后创建新的链接就行</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo rm -rf  /usr/local/cuda</span><br><span class="line">sudo ln -s /usr/local/cuda-10.6 /usr/local/cuda</span><br></pre></td></tr></table></figure>
<h2 id="4-卸载"><a href="#4-卸载" class="headerlink" title="4 卸载"></a>4 卸载</h2><p>进入对应版本的目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/cuda-12.3/bin</span><br></pre></td></tr></table></figure>
<p>执行卸载程序</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo ./cuda-uninstaller</span><br></pre></td></tr></table></figure>
<p>选择要删除的项目即可。删除成功后，删除对应的目录。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rm -rf cuda-*</span><br></pre></td></tr></table></figure>
<h2 id="5-问题"><a href="#5-问题" class="headerlink" title="5 问题"></a>5 问题</h2><p>有时候安装会失败，查看日志，多半是已经安装过的原因,卸载旧版本，以及安装失败的新版本就行。如果驱动存在就不要选择安装驱动只安装其他部分就行。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202410101511097.png" alt="image">​</p>
<p>‍</p>
]]></content>
      <categories>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
        <tag>环境</tag>
      </tags>
  </entry>
  <entry>
    <title>Shared Memory 大小限制</title>
    <url>/posts/1ea709cb.html</url>
    <content><![CDATA[<h2 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1 问题描述"></a>1 问题描述</h2><p>cuda代码有时会报如下的错误，即非法变量，这是因为外部设置共享内存的大小是有限制的。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Error code:1</span><br><span class="line">Error text:invalid argument</span><br></pre></td></tr></table></figure>
<p>因为核函数对共享内存的需求是不定的为了更好的利用资源以及帮助编译器进行优化，通常会采取传递共享内存大小的方式。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kernelFunc&lt;&lt;&lt;gridDim，blockDim，sharedmem&gt;&gt;&gt;()</span><br></pre></td></tr></table></figure>
<p>共享内存和一级缓存共用同一硬件存储单元。因此共享内存有最高上限，且该上限不等同于硬件上限。例如H100 L1和共享内存大小之和为256KB，而单个SM共享内存最多使用228KB，而每个block最多使用227KB，但是出于资源调度等考虑会默认限制为48KB。</p>
<h2 id="2-解决"><a href="#2-解决" class="headerlink" title="2 解决"></a>2 解决</h2><p>可以使用下面的函数进行设置。目前只有函数级的设置，全局级没有相关的设置。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cudaFuncSetAttribute( KernelFunc,  cudaFuncAttributeMaxDynamicSharedMemorySize, 128 \* 1024 // 128 KB);</span><br></pre></td></tr></table></figure>
<p>‍</p>
]]></content>
      <categories>
        <category>并行计算</category>
        <category>Nvidia</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
        <tag>共享内存</tag>
      </tags>
  </entry>
  <entry>
    <title>NVTX</title>
    <url>/posts/89d9e386.html</url>
    <content><![CDATA[<h2 id="1-介绍："><a href="#1-介绍：" class="headerlink" title="1 介绍："></a>1 介绍：</h2><p>NVTX 是一种基于 C/C++ 的 API，用于标注程序中的代码范围、事件和资源。此标注支持在应用程序运行时收集更多信息，这些信息可用于在分析CUDA代码时改进数据呈现。</p>
<h2 id="2-使用"><a href="#2-使用" class="headerlink" title="2 使用"></a>2 使用</h2><h3 id="2-1-引用头文件"><a href="#2-1-引用头文件" class="headerlink" title="2.1 引用头文件"></a>2.1 引用头文件</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;nvtx3/nvtx3.hpp&gt;</span><span class="comment">//C++，有可能没有安装上，直接用c的就行。</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;nvtx3/nvToolsExt.h&gt;</span><span class="comment">//C</span></span></span><br></pre></td></tr></table></figure>
<h3 id="2-2-常用功能"><a href="#2-2-常用功能" class="headerlink" title="2.2 常用功能"></a>2.2 常用功能</h3><h4 id="2-2-1-范围描述"><a href="#2-2-1-范围描述" class="headerlink" title="2.2.1 范围描述"></a>2.2.1 范围描述</h4><p><strong>nvtx3::scoped_range：</strong> 用于标记该类所创建对象存在的时间段，传递区间的名字进行初始化。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">some_function</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   nvtx3::scoped_range r&#123;<span class="string">&quot;some_function&quot;</span>&#125;;<span class="comment">//对象r的存在域是some_function()</span></span><br><span class="line">   <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">6</span>; ++i) &#123;</span><br><span class="line">      nvtx3::scoped_range loop&#123;<span class="string">&quot;loop range&quot;</span>&#125;;<span class="comment">//对象loop存在的域是for循环的每个轮次。</span></span><br><span class="line">      std::this_thread::<span class="built_in">sleep_for</span>(std::chrono::seconds&#123;<span class="number">1</span>&#125;);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​​</p>
<p><strong>nvtxRange:nvtxRang：</strong> 通过使用nvtxRangePushA( )和nvtxRangePop( )手动标记。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"> <span class="function"><span class="type">void</span> <span class="title">my_function</span><span class="params">(...)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">   <span class="built_in">nvtxRangePushA</span>(<span class="string">&quot;my_function&quot;</span>); <span class="comment">// 区间开始位置</span></span><br><span class="line"></span><br><span class="line">   <span class="comment">//</span></span><br><span class="line"></span><br><span class="line">   <span class="built_in">nvtxRangePop</span>(); <span class="comment">// 区间结束位置</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-2-2-标记事件点"><a href="#2-2-2-标记事件点" class="headerlink" title="2.2.2 标记事件点"></a>2.2.2 标记事件点</h3><p><strong>nvtx3::mark:</strong></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">bool</span> success = <span class="built_in">do_operation</span>(...);</span><br><span class="line"><span class="keyword">if</span> (!success) &#123;</span><br><span class="line">   nvtx3::<span class="built_in">mark</span>(<span class="string">&quot;operation failed!&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-3-实际使用"><a href="#2-3-实际使用" class="headerlink" title="2.3 实际使用"></a>2.3 实际使用</h3><p>插桩后会的影响代码性能，因此应当只在需要的时候对相关代码进行编译。可以宏对代码进行控制。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> NVTX</span></span><br><span class="line">    <span class="comment">//相关命令</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span>	</span></span><br></pre></td></tr></table></figure>
<p>然后再cmake 中添加相应的控制指令</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">if</span>(NVTX)</span><br><span class="line">	<span class="keyword">add_definitions</span>(-DNVTX)</span><br><span class="line"><span class="keyword">ENDIF</span>()</span><br></pre></td></tr></table></figure>
<p>在执行编译时添加参数。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cmake -D NVTX=1 ..</span><br><span class="line">make</span><br></pre></td></tr></table></figure>
<h2 id="3-问题"><a href="#3-问题" class="headerlink" title="3 问题"></a>3 问题</h2><p>如果没有nvtx3.hpp，可以从<a href="https://github.com/NVIDIA/NVTX/tree/release-v3/c/include/nvtx3">NVTX/c/include/nvtx3 at release-v3 · NVIDIA/NVTX (github.com)</a>中下载，添加到 /usr/local/cuda-12.3/include/nvtx3 目录下即可。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1]CUDA Pro Tip: Generate Custom Application Profile Timelines with NVTX[EB/OL]//NVIDIA Technical Blog. (2013-09-04)[2024-09-11]. <a href="https://developer.nvidia.com/blog/cuda-pro-tip-generate-custom-application-profile-timelines-nvtx/">https://developer.nvidia.com/blog/cuda-pro-tip-generate-custom-application-profile-timelines-nvtx/</a>.</p>
<p>[2]NVIDIA/NVTX[CP/OL]. NVIDIA Corporation, 2024[2024-09-11]. <a href="https://github.com/NVIDIA/NVTX">https://github.com/NVIDIA/NVTX</a>.</p>
<p>[3]NVTX C++ API Reference: NVTX C++ API Reference[EB/OL]. [2024-09-11]. <a href="https://nvidia.github.io/NVTX/doxygen-cpp/index.html">https://nvidia.github.io/NVTX/doxygen-cpp/index.html</a>.</p>
<p>‍</p>
]]></content>
      <categories>
        <category>并行计算</category>
        <category>Nvidia</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
        <tag>性能分析</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorCore WMMA 编程</title>
    <url>/posts/ed5d8a1b.html</url>
    <content><![CDATA[<h2 id="1-Tensor-Core"><a href="#1-Tensor-Core" class="headerlink" title="1 Tensor Core"></a>1 Tensor Core</h2><p>矩阵乘法在进行行列相乘时需要逐元素的相乘累加。这个过程可以使用乘积累加指令FMA（Fused Multiply–accumulate operation）完成。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061546301.png" alt="矩阵乘法" title="矩阵乘法">​</p>
<p>TensorCore是一种用于快速计算矩阵乘法的硬件（matrix multiply-and accumulation ，MAC）。</p>
<p>TensorCore可以原生计算$4 \times 4\times4$ 规模的矩阵乘法。CUDA 9.0以后支持$16 \times 16 \times 16$ 规模的矩阵乘法。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061546129.png" alt="image">​</p>
<h2 id="2-WMMA-编程"><a href="#2-WMMA-编程" class="headerlink" title="2 WMMA 编程"></a>2 WMMA 编程</h2><p>在利用cuda进行矩阵计算时需要对矩阵进行切片划分，要将矩阵切分至合适的大小。通常每个warp计算$16 \times 16 \times 16$规模的矩阵计算。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202407080957806.png" alt="image">​</p>
<p>cuda提供了WMMA API用于调用TensorCore进行矩阵计算。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Use, <span class="type">int</span> m, <span class="type">int</span> n, <span class="type">int</span> k, <span class="keyword">typename</span> T, <span class="keyword">typename</span> Layout=<span class="type">void</span>&gt; <span class="keyword">class</span> fragment;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">load_matrix_sync</span><span class="params">(fragment&lt;...&gt; &amp;a, <span class="type">const</span> T* mptr, <span class="type">unsigned</span> ldm)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">load_matrix_sync</span><span class="params">(fragment&lt;...&gt; &amp;a, <span class="type">const</span> T* mptr, <span class="type">unsigned</span> ldm, <span class="type">layout_t</span> layout)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">store_matrix_sync</span><span class="params">(T* mptr, <span class="type">const</span> fragment&lt;...&gt; &amp;a, <span class="type">unsigned</span> ldm, <span class="type">layout_t</span> layout)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">fill_fragment</span><span class="params">(fragment&lt;...&gt; &amp;a, <span class="type">const</span> T&amp; v)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">mma_sync</span><span class="params">(fragment&lt;...&gt; &amp;d, <span class="type">const</span> fragment&lt;...&gt; &amp;a, <span class="type">const</span> fragment&lt;...&gt; &amp;b, <span class="type">const</span> fragment&lt;...&gt; &amp;c, <span class="type">bool</span> satf=<span class="literal">false</span>)</span></span>;</span><br></pre></td></tr></table></figure>
<p><strong>fragment：</strong> 用于声明矩阵片段。</p>
<p><strong>load_matrix_sync：</strong> 用于将数据加载到矩阵片段中。</p>
<p><strong>store_matrix_sync：</strong> 用于将矩阵片段存储回存储空间。</p>
<p><strong>fill_fragment：</strong> 填充矩阵片段。</p>
<p><strong>mma_sync：</strong> 计算矩阵。</p>
<p>注意_sync表示的线程同步，所以相应的API接口必须同一线程束内的所有线程均可到达。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mma.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> nvcuda;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">wmma_ker</span><span class="params">(<span class="type">uint8_t</span> *a, <span class="type">uint8_t</span> *b, uint_32 *c)</span> </span>&#123;</span><br><span class="line">   <span class="comment">// Declare the fragments</span></span><br><span class="line">   wmma::fragment&lt;wmma::matrix_a, <span class="number">16</span>, <span class="number">16</span>, <span class="number">16</span>, <span class="type">uint8_t</span>, wmma::row_major&gt; a_frag;</span><br><span class="line">   wmma::fragment&lt;wmma::matrix_b, <span class="number">16</span>, <span class="number">16</span>, <span class="number">16</span>, <span class="type">uint8_t</span>, wmma::col_major&gt; b_frag;</span><br><span class="line">   wmma::fragment&lt;wmma::accumulator, <span class="number">16</span>, <span class="number">16</span>, <span class="number">16</span>, <span class="type">uint32_t</span>&gt; c_frag;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Initialize the output to zero</span></span><br><span class="line">   wmma::<span class="built_in">fill_fragment</span>(c_frag, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Load the inputs</span></span><br><span class="line">   wmma::<span class="built_in">load_matrix_sync</span>(a_frag, a, <span class="number">16</span>);</span><br><span class="line">   wmma::<span class="built_in">load_matrix_sync</span>(b_frag, b, <span class="number">16</span>);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Perform the matrix multiplication</span></span><br><span class="line">   wmma::<span class="built_in">mma_sync</span>(c_frag, a_frag, b_frag, c_frag);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Store the output</span></span><br><span class="line">   wmma::<span class="built_in">store_matrix_sync</span>(c, c_frag, <span class="number">16</span>, wmma::mem_row_major);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面给出的是利用CudaCore进行计算的示例代码。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">simtNaiveKernel</span><span class="params">(<span class="type">const</span> uint8 *__restrict__ A, <span class="type">const</span> uint8 *__restrict__ B, <span class="type">uint32_t</span> *__restrict__ C, <span class="type">size_t</span> M,</span></span></span><br><span class="line"><span class="params"><span class="function">                                <span class="type">size_t</span> N, <span class="type">size_t</span> K)</span> </span>&#123;</span><br><span class="line">    <span class="type">size_t</span> row = threadIdx.y + blockDim.y * blockIdx.y;</span><br><span class="line">    <span class="type">size_t</span> col = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (row &gt;= M &amp;&amp; col &gt;= N) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> tmp = <span class="number">0.0</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; K; ++i) &#123;</span><br><span class="line">        tmp += <span class="built_in">int</span>(A[row * K + i]) * <span class="built_in">int</span>(B[i + col * K]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    C[row * N + col] = <span class="built_in">uint</span>(tmp);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">simtNaive</span><span class="params">(<span class="type">uint8_t</span> *A, <span class="type">uint8_t</span> *B, <span class="type">uint32_t</span> *C, <span class="type">size_t</span> M, <span class="type">size_t</span> N, <span class="type">size_t</span> K)</span> </span>&#123;</span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(div_ceil(N, block.x), div_ceil(M, block.y))</span></span>;</span><br><span class="line"></span><br><span class="line">    simtNaiveKernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;(A, B, C, M, N, K);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>CudaCore和TensorCore对比参考如下示意图。CudaCore以线程为单位，TensorCore以线程束为单位。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061546556.gif" alt="图片2">​</p>
<h2 id="3-线程映射"><a href="#3-线程映射" class="headerlink" title="3 线程映射"></a>3 线程映射</h2><p>$16 \times 16 \times 16$ 矩阵乘法中每一个线程对应8个uint8数据，数据和线程的映射关系如下图所示。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;&gt; <span class="keyword">class</span> <span class="title class_">fragment</span>&lt;matrix_a, <span class="number">16</span>, <span class="number">16</span>, <span class="number">16</span>, <span class="type">unsigned</span> <span class="type">char</span>, row_major&gt; : <span class="keyword">public</span> __frag_base&lt;<span class="type">unsigned</span> <span class="type">char</span>, <span class="number">8</span>&gt; &#123;&#125;;</span><br><span class="line"><span class="keyword">template</span>&lt;&gt; <span class="keyword">class</span> <span class="title class_">fragment</span>&lt;matrix_a, <span class="number">16</span>, <span class="number">16</span>, <span class="number">16</span>, <span class="type">unsigned</span> <span class="type">char</span>, col_major&gt; : <span class="keyword">public</span> __frag_base&lt;<span class="type">unsigned</span> <span class="type">char</span>, <span class="number">8</span>&gt; &#123;&#125;;</span><br></pre></td></tr></table></figure>
<p>‍<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202407292032010.svg" alt="数据映射"></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1]PTX ISA 8.5[EB/OL]. [2024-07-03]. <a href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-multiply-accumulate-instructions">https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-multiply-accumulate-instructions</a>.</p>
<p>[2]Programming Tensor Cores in CUDA 9 | NVIDIA Technical Blog[EB/OL]. [2024-07-03]. <a href="https://developer.nvidia.com/blog/programming-tensor-cores-cuda-9/">https://developer.nvidia.com/blog/programming-tensor-cores-cuda-9/</a>.</p>
<p>[3]NVIDIA深度学习Tensor Core全面解析（上篇） | 雷峰网[EB/OL]. [2024-07-03]. <a href="https://www.leiphone.com/category/ai/RsZr7QRlQMfhMwOU.html">https://www.leiphone.com/category/ai/RsZr7QRlQMfhMwOU.html</a>.</p>
<p>[4]BRUCE-LEE-LY. Nvidia Tensor Core-Preliminary Exploration[EB/OL]//Medium. (2023-09-25)[2024-07-03]. <a href="https://bruce-lee-ly.medium.com/nvidia-tensor-core-preliminary-exploration-10618787615a">https://bruce-lee-ly.medium.com/nvidia-tensor-core-preliminary-exploration-10618787615a</a>.</p>
<p>[5]BRUCE-LEE-LY. Nvidia Tensor Core-Getting Started with WMMA API Programming[EB/OL]//Medium. (2023-09-25)[2024-07-03]. <a href="https://bruce-lee-ly.medium.com/nvidia-tensor-core-introduction-to-wmma-api-programming-21bcfee4ec45">https://bruce-lee-ly.medium.com/nvidia-tensor-core-introduction-to-wmma-api-programming-21bcfee4ec45</a>.</p>
<p>[6]BRUCE-LEE-LY. Nvidia Tensor Core-Getting Started with MMA PTX Programming[EB/OL]//Medium. (2023-09-25)[2024-07-03]. <a href="https://bruce-lee-ly.medium.com/nvidia-tensor-core-getting-started-with-mma-ptx-programming-508e44a6cb7d">https://bruce-lee-ly.medium.com/nvidia-tensor-core-getting-started-with-mma-ptx-programming-508e44a6cb7d</a>.</p>
<p>[7]BRUCE-LEE-LY. Nvidia Tensor Core-Getting Started with MMA PTX Programming[EB/OL]//Medium. (2023-09-25)[2024-07-03]. <a href="https://bruce-lee-ly.medium.com/nvidia-tensor-core-getting-started-with-mma-ptx-programming-508e44a6cb7d">https://bruce-lee-ly.medium.com/nvidia-tensor-core-getting-started-with-mma-ptx-programming-508e44a6cb7d</a>.</p>
<p>[8]YEH T T. Accelerator Architectures for Machine Learning[EB/OL].[2024-07-03].<a href="https://people.cs.nycu.edu.tw/~ttyeh/course/2023_Fall/IOC5009/slide/lecture-8.pdf">lecture-8.pdf (nycu.edu.tw)</a></p>
<p>‍</p>
]]></content>
      <categories>
        <category>并行计算</category>
        <category>Nvidia</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
        <tag>张量核心</tag>
      </tags>
  </entry>
  <entry>
    <title>bib 国标模板</title>
    <url>/posts/c0dc4c.html</url>
    <content><![CDATA[<h2 id="1-参考文献常用条目类型"><a href="#1-参考文献常用条目类型" class="headerlink" title="1 参考文献常用条目类型"></a>1 参考文献常用条目类型</h2><script type="math/tex; mode=display">
\text{表 1：文献常用条目类型}\\
\begin{array}{ccc}
\hline
\text{国标条目}& \text{biblatex条目}& \text{类型标识代码 }\\
\hline
专著 & \text{book} &\text{[M]}\\
标准 & \text{standard} &\text{[S]}\\
专著析出文献 & \text{inbook} &\text{[M]}\\
连续出版物 & \text{periodical} &\text{[J]}\\
连续出版物析出文献 & \text{artical} &\text{[J]}\\
报纸析出文献 & \text{newspaper} &\text{[N]}\\
专利 & \text{patent} &\text{[P]}\\
电子资源或电子公告 & \text{onine} &\text{[EB]}\\
会议文集 & \text{proceedings} &\text{[C]}\\
会议文集析出 & \text{inproceedings} &\text{[C]}\\
汇编、论文集 & \text{collection} &\text{[G]}\\
汇编、论文集析出 & \text{incollection} &\text{[G]}\\
学位论文（本） & \text{thesis} &\text{[D]}\\
学位论文（硕） & \text{mastersthesis} &\text{[D]}\\
学位论文（博） & \text{phdthesis} &\text{[D]}\\
报告 & \text{report/techreport} &\text{[R]}\\
手册 & \text{manual} &\text{[A]}\\
档案 & \text{archive} &\text{[A]}\\
数据库 & \text{database} &\text{[DB]}\\
数据集 & \text{dataset} &\text{[DS]}\\\
计算机程序 & \text{software} &\text{[CP]}\\
舆图 & \text{map} &\text{[CM]}\\
未出版物 & \text{unpublished} &\text{[Z]}\\
其它 & \text{misc} &\text{[Z]}\\

\hline
\end{array}</script><h5 id="著录"><a href="#著录" class="headerlink" title="著录"></a>著录</h5><p>主要责任者.题名:其他题名信息[文献类型标识/文献载体标识].年,卷(期)-年,卷(期).出版地: 出版者,出版年[引用日期].获取和访问路径.数字对象唯一标识符.</p>
<h5 id="著录中析出文献"><a href="#著录中析出文献" class="headerlink" title="著录中析出文献"></a>著录中析出文献</h5><p>析出文献主要责任者.析出文献题名[文献类型标识/文献载体标识].连续出版物题名:其他题名 信息,年,卷(期):页码[引用日期].获取和访问路径.数字对象唯一标识符.</p>
<h5 id="专利"><a href="#专利" class="headerlink" title="专利"></a>专利</h5><p>专利申请者或所有者.专利题名:专利号[文献类型标识/文献载体标识].公告日期或公开日期[引用日期].获取和访问路径.数字对象唯一标识符.</p>
<h5 id="电子资源"><a href="#电子资源" class="headerlink" title="电子资源"></a>电子资源</h5><p>主要责任者.题名:其他题名信息[文献类型标识/文献载体标识].出版地:出版者,出版年:引文页 码(更新或修改日期)[引用日期].获取和访问路径.数字对象唯一标识符.</p>
<p>‍</p>
<h2 id="2-参考文舆图献常用信息域"><a href="#2-参考文舆图献常用信息域" class="headerlink" title="2 参考文舆图献常用信息域"></a>2 参考文舆图献常用信息域</h2><script type="math/tex; mode=display">
\text{表 2：参考文献常用信息域}\\
\begin{array}{cc}
\hline
\text{国标文献著录项目}& \text{biblatex 中地域 }\\
\hline
责任者 & \text{author/editor} \\
题名   & \text{title} \\
译者   & \text{translator} \\
出版物版本   &\text{ edition} \\
软件或手册版本   & \text{version} \\
出版地   & \text{location/address} \\
出版者   &\text{ publisher} \\
出版者（大学和研究所）   &\text{ school/institution} \\
出版者（会议举办者、资源出品方）&\text{organization} \\
日期   & \text{data} \\
日期（不可解析的日期）   & \text{year} \\
页码   & \text{pages} \\
析出文献来源的责任者   & \text{bookauthor/editor}\\
析出文献来源的标题   & \text{booktitle} \\
连续出版物题名（期刊、报纸）   & \text{journal/journaltitle} \\
期刊的卷   & \text{volume} \\
期号、专利号   & \text{number} \\
访问路径   & \text{url} \\
引用日期   & \text{urldate} \\
数字对象标识符   & \text{doi} \\
杂项   & \text{note} \\
\hline
\end{array}</script><h5 id="author、translator、bookauthor、editor"><a href="#author、translator、bookauthor、editor" class="headerlink" title="author、translator、bookauthor、editor"></a>author、translator、bookauthor、editor</h5><p>各姓名间用and连接，当 姓名过多省略时，用others代替。</p>
<p>对于中文作者直接输入中文姓名即可。比如: 于潇and刘义and柴跃廷andothers 。</p>
<p>对于英文作者: prefix lastname, suffix, firstname middlename.</p>
<p>对于中文的机构作者，不需要解析，直接输入机构名，比如: 中国企业投资协会and台湾并购与私募股权协会and汇盈国际投资集团。</p>
<p>对于英文的机构作者，由于机构名可能存在空格或and等字符串，因此最好用{}包 起来，避免解析出错，比如： {International Federation of Library Association and Institutions} and NASA。</p>
<h5 id="title"><a href="#title" class="headerlink" title="title"></a>title</h5><p>直接输入需要打印的内容</p>
<h5 id="edition"><a href="#edition" class="headerlink" title="edition"></a>edition</h5><p>直接输入整数或者要打印的内容</p>
<h5 id="location"><a href="#location" class="headerlink" title="location"></a>location</h5><p>直接输入需要打印的地址内容，而address域在biblatex中作为location别名，表示相同的内容。</p>
<h5 id="publisher、institution、organization"><a href="#publisher、institution、organization" class="headerlink" title="publisher、institution、organization"></a>publisher、institution、organization</h5><p>直接输入需要打印的出版者内容</p>
<h5 id="date、urldate、origdate"><a href="#date、urldate、origdate" class="headerlink" title="date、urldate、origdate"></a>date、urldate、origdate</h5><p>日期可以格式化输入，格式化输入biblatex会自动解析，如果无法解析会忽略该域。 格式化的输入方式是: 年-月-日/年-月-日，数字格式为：yyyy-mm-dd 比如:2001-05-06</p>
<h5 id="year"><a href="#year" class="headerlink" title="year"></a>year</h5><p>year可以处理仅有年的信息或者需要原样打印的内容。</p>
<h5 id="pages"><a href="#pages" class="headerlink" title="pages"></a>pages</h5><p>可以格式化输入或输入需要打印的内容。格式化输入时，页码用整数，当有范围时， 用单个或多个短横线-隔开。比如:59-60或59—60。</p>
<h5 id="url"><a href="#url" class="headerlink" title="url"></a>url</h5><p>直接输入需要打印的网址内容。</p>
<h5 id="doi"><a href="#doi" class="headerlink" title="doi"></a>doi</h5><p>直接输入需要打印的DOI内容</p>
<h5 id="note"><a href="#note" class="headerlink" title="note"></a>note</h5><p>在本样式中note域可以有特殊功能，当其内容为standard或news|newspaper时， 判断条目类型为标准和报纸析出的文献。</p>
<h5 id="journal"><a href="#journal" class="headerlink" title="journal"></a>journal</h5><p> 用于连续出版物析出文献，表示连续出版物的题名，比如期刊、报纸的提名，直接输 入需要打印的内容。</p>
<p>‍</p>
<h5 id="volume"><a href="#volume" class="headerlink" title="volume"></a>volume</h5><p>连续出版物的卷，格式化输入用整数，当有范围时中间用短横线连接，比如:1-4。当 无法解析时，输入内容被认为是需要完整打印的内容。</p>
<h5 id="number"><a href="#number" class="headerlink" title="number"></a>number</h5><p>连续出版物的期或报纸的版次，输入与volume类似。或者是专利等的号时，直接输 入需要打印的内容。</p>
<h5 id="version"><a href="#version" class="headerlink" title="version"></a>version</h5><p>用于report 和manual 的版本信息，直接输入需要打印的内容</p>
<h2 id="3-示例"><a href="#3-示例" class="headerlink" title="3 示例"></a>3 示例</h2><h5 id="专著"><a href="#专著" class="headerlink" title="专著"></a>专著</h5><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">@book&#123;专著,</span><br><span class="line">  author=&#123;主要作者&#125;,</span><br><span class="line">  series=&#123;系列图书&#125;,</span><br><span class="line">  editor=&#123;负责人&#125;,</span><br><span class="line">  translator=&#123;译者&#125;,</span><br><span class="line">  volume=&#123;卷号&#125;,</span><br><span class="line">  title=&#123;题名&#125;,</span><br><span class="line">  year=&#123;出版年&#125;,</span><br><span class="line">  edition=&#123;版本&#125;,</span><br><span class="line">  address=&#123;出版地&#125;,</span><br><span class="line">  publisher=&#123;出版者&#125;,</span><br><span class="line">  pages=&#123;引用页码&#125;,</span><br><span class="line">  language=&#123;语言&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@book&#123;chuban2011,</span><br><span class="line">  editor=&#123;&#123;全国出版专业职业资格考试办公室&#125;&#125;,</span><br><span class="line">  title=&#123;出版专业实务（初级）&#125;,</span><br><span class="line">  edition=&#123;2011年版&#125;,</span><br><span class="line">  series=&#123;全国出版专业职业资格考试辅导教材&#125;,</span><br><span class="line">  address=&#123;湖北&#125;,</span><br><span class="line">  publisher=&#123;长江出版集团&#125;,</span><br><span class="line">  year=&#123;2011&#125;,</span><br><span class="line">  language=&#123;zh&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@book&#123;anwen1988b,</span><br><span class="line">  author=&#123;昂温, G. and 昂温, P. S.&#125;,</span><br><span class="line">  title=&#123;美国独立战争&#125;,</span><br><span class="line">  series=&#123;世界历史丛书&#125;,</span><br><span class="line">  editor=&#123;张三 and 李四&#125;,</span><br><span class="line">  translator=&#123;陈生铮&#125;,</span><br><span class="line">  address=&#123;北京&#125;,</span><br><span class="line">  publisher=&#123;中国书籍出版社&#125;,</span><br><span class="line">  year=&#123;1988&#125;,</span><br><span class="line">  language=&#123;zh&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="专著析出"><a href="#专著析出" class="headerlink" title="专著析出"></a>专著析出</h5><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">@inbook&#123;专著析出,</span><br><span class="line">  author=&#123;主要作者&#125;,</span><br><span class="line">  editor=&#123;负责人&#125;,</span><br><span class="line">  volume=&#123;卷号&#125;,</span><br><span class="line">  title=&#123;题名&#125;,</span><br><span class="line">  booktitle=&#123;专著名称&#125;,</span><br><span class="line">  year=&#123;出版年&#125;,</span><br><span class="line">  edition=&#123;版本&#125;,</span><br><span class="line">  address=&#123;出版地&#125;,</span><br><span class="line">  publisher=&#123;出版者&#125;,</span><br><span class="line">  pages=&#123;引用页码&#125;,</span><br><span class="line">  language=&#123;语言&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@inbook&#123;zhendan1980,</span><br><span class="line">  author=&#123;陈晋镶 and 张惠民 and 朱士兴 and 其他作者&#125;,</span><br><span class="line">  title=&#123;蓟县震旦亚界研究&#125;,</span><br><span class="line">  editor=&#123;中国地质科学院天津地质矿产研究所&#125;,</span><br><span class="line">  booktitle=&#123;中国震旦亚界&#125;,</span><br><span class="line">  address=&#123;天津&#125;,</span><br><span class="line">  publisher=&#123;天津科学技术出版社&#125;,</span><br><span class="line">  year=&#123;1980&#125;,</span><br><span class="line">  pages=&#123;56-114&#125;,</span><br><span class="line">  language=&#123;zh&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="标准"><a href="#标准" class="headerlink" title="标准"></a>标准</h5><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">@standard&#123;标准,</span><br><span class="line">  author=&#123;主要责任者&#125;,</span><br><span class="line">  title=&#123;题名&#125;,</span><br><span class="line">  year=&#123;出版年&#125;,</span><br><span class="line">  address=&#123;出版地&#125;,</span><br><span class="line">  publisher=&#123;出版者&#125;,</span><br><span class="line">  language=&#123;语言&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@standard&#123;gbt7156-2003,</span><br><span class="line">  author=&#123;&#123;中国国家标准化管理委员会&#125;&#125;,</span><br><span class="line">  title=&#123;GB/T 7156-2003: 文献保密等级代码与标识&#125;,</span><br><span class="line">  address=&#123;北京&#125;,</span><br><span class="line">  publisher=&#123;科技出版社&#125;,</span><br><span class="line">  year=&#123;2003&#125;,</span><br><span class="line">  language=&#123;zh&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="连续出版物"><a href="#连续出版物" class="headerlink" title="连续出版物"></a>连续出版物</h5><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">@periodical&#123;连续出版物,</span><br><span class="line">  author=&#123;主要责任者&#125;,</span><br><span class="line">  title=&#123;题名&#125;,</span><br><span class="line">  year=&#123;出版年&#125;,</span><br><span class="line">  volume=&#123;卷&#125;,</span><br><span class="line">  number=&#123;期&#125;,</span><br><span class="line">  pages=&#123;引用页码&#125;,</span><br><span class="line">  publisher=&#123;出版者&#125;,</span><br><span class="line">  language=&#123;语言&#125;,</span><br><span class="line">&#125;</span><br><span class="line">@periodical&#123;science1983,</span><br><span class="line">  editor=&#123;&#123;American Association for the Advancement of Science&#125;&#125;,</span><br><span class="line">  title=&#123;Science&#125;,</span><br><span class="line">  year=&#123;1883&#125;,</span><br><span class="line">  volume=&#123;1&#125;,</span><br><span class="line">  number=&#123;1&#125;,</span><br><span class="line">  address=&#123;Washington&#125;,</span><br><span class="line">  publisher=&#123;American Association for the Advancement of Science&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@periodical&#123;dizhipinlun1936,</span><br><span class="line">  editor=&#123;&#123;中国地质学会&#125;&#125;,</span><br><span class="line">  title=&#123;地质论评&#125;,</span><br><span class="line">  year=&#123;1936&#125;,</span><br><span class="line">  volume=&#123;1&#125;,</span><br><span class="line">  number=&#123;1&#125;,</span><br><span class="line">  address=&#123;北京&#125;,</span><br><span class="line">  publisher=&#123;地质出版社&#125;,</span><br><span class="line">  language=&#123;zh&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="连续出版物析出"><a href="#连续出版物析出" class="headerlink" title="连续出版物析出"></a>连续出版物析出</h5><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">@article&#123;连续出版物析出,</span><br><span class="line">  author=&#123;主要责任者&#125;,</span><br><span class="line">  title=&#123;题名&#125;,</span><br><span class="line">  journal=&#123;连续出版物名称&#125;,</span><br><span class="line">  year=&#123;出版年&#125;,</span><br><span class="line">  volume=&#123;卷&#125;,</span><br><span class="line">  number=&#123;期&#125;,</span><br><span class="line">  pages=&#123;引用页码&#125;,</span><br><span class="line">  language=&#123;语言&#125;,</span><br><span class="line">&#125;</span><br><span class="line">@article&#123;kanamori1998,</span><br><span class="line">  author=&#123;Kanamori, H.&#125;,</span><br><span class="line">  title=&#123;Shaking without quaking&#125;,</span><br><span class="line">  journal=&#123;Science&#125;,</span><br><span class="line">  year=&#123;1998&#125;,</span><br><span class="line">  volume=&#123;279&#125;,</span><br><span class="line">  number=&#123;5359&#125;,</span><br><span class="line">  pages=&#123;2063-2064&#125;,</span><br><span class="line">&#125;</span><br><span class="line">@article&#123;jiangxiangdong1999,</span><br><span class="line">  author=&#123;江向东&#125;,</span><br><span class="line">  title=&#123;互联网环境下的信息处理与图书管理系统解决方案&#125;,</span><br><span class="line">  journal=&#123;情报学报&#125;,</span><br><span class="line">  year=&#123;1999&#125;,</span><br><span class="line">  volume=&#123;18&#125;,</span><br><span class="line">  number=&#123;2&#125;,</span><br><span class="line">  pages=&#123;4&#125;,</span><br><span class="line">  language=&#123;zh&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="报纸"><a href="#报纸" class="headerlink" title="报纸"></a>报纸</h5><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">@newspaper&#123;报纸,</span><br><span class="line">  author=&#123;主要责任者&#125;,</span><br><span class="line">  title=&#123;题名&#125;,</span><br><span class="line">  journal=&#123;报纸名称&#125;,</span><br><span class="line">  year=&#123;出版年&#125;,</span><br><span class="line">  volume=&#123;卷&#125;,</span><br><span class="line">  language=&#123;语言&#125;,</span><br><span class="line">  publisher=&#123;出版者&#125;,</span><br><span class="line">  address=&#123;出版地&#125;,</span><br><span class="line">  language=&#123;语言&#125;,</span><br><span class="line">&#125;</span><br><span class="line">@newspaper&#123;renminribao,</span><br><span class="line">  editor=&#123;&#123;人民日报编辑部&#125;&#125;,</span><br><span class="line">  title=&#123;人民日报&#125;,</span><br><span class="line">  year=&#123;2011&#125;,</span><br><span class="line">  volume=&#123;22892&#125;,</span><br><span class="line">  address=&#123;北京&#125;,</span><br><span class="line">  publisher=&#123;人民日报出版社&#125;,</span><br><span class="line">  language=&#123;zh&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="专利-1"><a href="#专利-1" class="headerlink" title="专利"></a>专利</h5><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">@patent&#123;专利,</span><br><span class="line">  author=&#123;专利权所有者&#125;,</span><br><span class="line">  title=&#123;题名&#125;,</span><br><span class="line">  patentid=&#123;专利号&#125;,</span><br><span class="line">  date=&#123;日期&#125;,</span><br><span class="line">  country=&#123;国家&#125;,</span><br><span class="line">  langauge=&#123;zh&#125;,</span><br><span class="line">&#125;</span><br><span class="line">@patent&#123;p88105607.3,</span><br><span class="line">  author=&#123;姜锡洲&#125;,</span><br><span class="line">  title=&#123;一种温热外敷药制备方案&#125;,</span><br><span class="line">  country=&#123;中国&#125;,</span><br><span class="line">  patentid=&#123;88105607.3&#125;,</span><br><span class="line">  date=&#123;1989-07-26&#125;,</span><br><span class="line">  langauge=&#123;zh&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="电子资源-1"><a href="#电子资源-1" class="headerlink" title="电子资源"></a>电子资源</h5><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">@online&#123;电子资源,</span><br><span class="line">  author=&#123;主要责任者&#125;,</span><br><span class="line">  title=&#123;题名&#125;,</span><br><span class="line">  modifydate=&#123;修订日期&#125;,</span><br><span class="line">  url=&#123;检索地址&#125;,</span><br><span class="line">  citedate=&#123;引用日期&#125;,</span><br><span class="line">&#125;</span><br><span class="line">@online&#123;chuban2001,</span><br><span class="line">  author=&#123;萧钰&#125;,</span><br><span class="line">  title=&#123;出版业信息化迈入快车道&#125;,</span><br><span class="line">  modifydate=&#123;2001-12-19&#125;,</span><br><span class="line">  url=&#123;http://www.creader.com/news/20011219/200112190019.html&#125;,</span><br><span class="line">  citedate=&#123;2002-04-15&#125;,</span><br><span class="line">  langauge=&#123;zh&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="文集"><a href="#文集" class="headerlink" title="文集"></a>文集</h5><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">@collection&#123;文集,</span><br><span class="line">  editor=&#123;主编&#125;,</span><br><span class="line">  title=&#123;题名&#125;,</span><br><span class="line">  year=&#123;出版年&#125;,</span><br><span class="line">  address=&#123;出版地&#125;,</span><br><span class="line">  publisher=&#123;出版者&#125;,</span><br><span class="line">  pages=&#123;引用页码&#125;,</span><br><span class="line">  language=&#123;语言&#125;,</span><br><span class="line">&#125;</span><br><span class="line">@collection&#123;maxis1982,</span><br><span class="line">  author=&#123;马克思 and 恩格斯&#125;,</span><br><span class="line">  title=&#123;马克思恩格斯全集&#125;,</span><br><span class="line">  volume=&#123;44&#125;,</span><br><span class="line">  address=&#123;北京&#125;,</span><br><span class="line">  publisher=&#123;人民出版社&#125;,</span><br><span class="line">  year=&#123;1982&#125;,</span><br><span class="line">  language=&#123;zh&#125;,</span><br><span class="line">&#125;</span><br><span class="line">@incollection&#123;文集析出,</span><br><span class="line">  author=&#123;作者&#125;,</span><br><span class="line">  title=&#123;题名&#125;,</span><br><span class="line">  booktitle=&#123;文集名称&#125;,</span><br><span class="line">  year=&#123;出版年&#125;,</span><br><span class="line">  editor=&#123;主编&#125;,</span><br><span class="line">  pages=&#123;引用页码&#125;,</span><br><span class="line">  address=&#123;出版地&#125;,</span><br><span class="line">  publisher=&#123;出版者&#125;,</span><br><span class="line">  language=&#123;语言&#125;,</span><br><span class="line">&#125;</span><br><span class="line">@incollection&#123;gongzi,</span><br><span class="line">  author=&#123;马克思&#125;,</span><br><span class="line">  title=&#123;关于《工资、价格和利润》的报告札记&#125;,</span><br><span class="line">  editor=&#123;马克思 and 恩格斯&#125;,</span><br><span class="line">  booktitle=&#123;马克思恩格斯全集&#125;,</span><br><span class="line">  volume=&#123;44&#125;,</span><br><span class="line">  address=&#123;北京&#125;,</span><br><span class="line">  publisher=&#123;人民出版社&#125;,</span><br><span class="line">  year=&#123;1982&#125;,</span><br><span class="line">  pages=&#123;505&#125;,</span><br><span class="line">  language=&#123;zh&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="会议记录"><a href="#会议记录" class="headerlink" title="会议记录"></a>会议记录</h5><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">@proceedings&#123;会议录,</span><br><span class="line">  editor=&#123;主编&#125;,</span><br><span class="line">  title=&#123;题名&#125;,</span><br><span class="line">  year=&#123;出版年&#125;,</span><br><span class="line">  address=&#123;出版地&#125;,</span><br><span class="line">  publisher=&#123;出版者&#125;,</span><br><span class="line">  language=&#123;语言&#125;,</span><br><span class="line">&#125;</span><br><span class="line">@proceedings&#123;1-11,</span><br><span class="line">  editor=&#123;Yufin, S. A.&#125;,</span><br><span class="line">  title=&#123;Geoecology and computers: proceedings of the Third International</span><br><span class="line">             Conference on Advance of Computer Methods in Geotechnical and</span><br><span class="line">             Geoenvironmental Engineering, Moscow, Russia, February 1--4, 2000&#125;,</span><br><span class="line">  address=&#123;Rotterdam&#125;,</span><br><span class="line">  publisher=&#123;A. A. Balkema&#125;,</span><br><span class="line">    year=&#123;2000&#125;,</span><br><span class="line">&#125;</span><br><span class="line">@inproceedings&#123;会议录析出,</span><br><span class="line">  author=&#123;作者&#125;,</span><br><span class="line">  title=&#123;题名&#125;,</span><br><span class="line">  booktitle=&#123;会议录名称&#125;,</span><br><span class="line">  year=&#123;出版年&#125;,</span><br><span class="line">  editor=&#123;主编&#125;,</span><br><span class="line">  pages=&#123;引用页码&#125;,</span><br><span class="line">  address=&#123;出版地&#125;,</span><br><span class="line">  publisher=&#123;出版者&#125;,</span><br><span class="line">  language=&#123;语言&#125;,</span><br><span class="line">&#125;</span><br><span class="line">@inproceedings&#123;nonlinear1996,</span><br><span class="line">  author=&#123;钟文发&#125;,</span><br><span class="line">  title=&#123;非线性规划在可燃毒物配置中的应用&#125;,</span><br><span class="line">  editor =&#123;赵玮&#125;,</span><br><span class="line">  booktitle=&#123;运筹学的理论与应用：中国运筹学会第五届大会论文集&#125;,</span><br><span class="line">  address=&#123;西安&#125;,</span><br><span class="line">  publisher=&#123;西安电子科技大学出版社&#125;,</span><br><span class="line">  year=&#123;1996&#125;,</span><br><span class="line">  pages=&#123;468-471&#125;,</span><br><span class="line">  language=&#123;zh&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="报告手册"><a href="#报告手册" class="headerlink" title="报告手册"></a>报告手册</h5><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">@report&#123;报告,</span><br><span class="line">  author=&#123;作者&#125;,</span><br><span class="line">  title=&#123;题名&#125;,</span><br><span class="line">  year=&#123;出版年&#125;,</span><br><span class="line">  address=&#123;出版地&#125;,</span><br><span class="line">  institution=&#123;机构&#125;,</span><br><span class="line">&#125;</span><br><span class="line">@techreport&#123;a3-1,</span><br><span class="line">  author=&#123;&#123;U.S. Department of Transportation Federal Highway Administration&#125;&#125;,</span><br><span class="line">  title=&#123;Guidelines for handling excavated acid-producing materials, PB 91-194001&#125;,</span><br><span class="line">  address=&#123;Springfield&#125;,</span><br><span class="line">  institution=&#123;U.S. Department of Commerce National Information Service&#125;,</span><br><span class="line">  year=&#123;1990&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@manual&#123;手册,</span><br><span class="line">  author=&#123;作者&#125;,</span><br><span class="line">  title=&#123;题名&#125;,</span><br><span class="line">  year=&#123;出版年&#125;,</span><br><span class="line">  address=&#123;出版地&#125;,</span><br><span class="line">  organization=&#123;组织&#125;,</span><br><span class="line">  language=&#123;语言&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@manual&#123;ipad,</span><br><span class="line">  author=&#123;&#123;Apple Inc&#125;&#125;,</span><br><span class="line">  title=&#123;iPad User Manual&#125;,</span><br><span class="line">  address=&#123;Cupertino&#125;,</span><br><span class="line">  publisher=&#123;Apple Inc&#125;,</span><br><span class="line">  year=&#123;2008&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h5><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line">@thesis&#123;学位论文,</span><br><span class="line">  author=&#123;作者&#125;,</span><br><span class="line">  title=&#123;题名&#125;,</span><br><span class="line">  year=&#123;完成年&#125;,</span><br><span class="line">  address=&#123;学位授予单位地址&#125;,</span><br><span class="line">  school=&#123;学位授予单位&#125;,</span><br><span class="line">  language=&#123;语言&#125;,</span><br><span class="line">&#125;</span><br><span class="line">@phdthesis&#123;1-5,</span><br><span class="line">  author=&#123;孙玉文&#125;,</span><br><span class="line">  title=&#123;汉语变调构词研究&#125;,</span><br><span class="line">  address=&#123;北京&#125;,</span><br><span class="line">  school=&#123;北京大学中文系&#125;,</span><br><span class="line">  year=&#123;2000&#125;,</span><br><span class="line">  language=&#123;zh&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@masterthesis&#123;a4-1,</span><br><span class="line">  author=&#123;张志祥&#125;,</span><br><span class="line">  title=&#123;间断动力系统的随机扰动及其在守恒律方程中的应用&#125;,</span><br><span class="line">  address=&#123;南京&#125;,</span><br><span class="line">  school=&#123;南京大学数学学院&#125;,</span><br><span class="line">  year=&#123;1998&#125;,</span><br><span class="line">  language=&#123;zh&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>‍</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1]中 国 国 家 标 准 化 管 理 委 员 会. 信息与文献 参考文献著录规则：GB/T7714—2015[S]. 北京: 中国标准出版社出版, 2015.</p>
<p>[2]国家标准《GB/T 7714-2005: 文后参考文献著录规则》BibTeX样式[EB/OL]. [2024-06-21]. <a href="https://www.latexstudio.net/archives/1541.html">https://www.latexstudio.net/archives/1541.html</a>.</p>
<p>‍</p>
]]></content>
      <categories>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>参考文献</tag>
        <tag>学术</tag>
      </tags>
  </entry>
  <entry>
    <title>ZKP 发展脉络</title>
    <url>/posts/e16561b3.html</url>
    <content><![CDATA[<h2 id="1-ZKP基础概念"><a href="#1-ZKP基础概念" class="headerlink" title="1 ZKP基础概念"></a>1 ZKP基础概念</h2><h3 id="1-1-简要介绍"><a href="#1-1-简要介绍" class="headerlink" title="1.1 简要介绍"></a>1.1 简要介绍</h3><h4 id="1-1-1-ZKP-定义"><a href="#1-1-1-ZKP-定义" class="headerlink" title="1.1.1 ZKP 定义"></a>1.1.1 ZKP 定义</h4><p>零知识证明（Zero-knowledge proofs）可以证明一个陈述（State­ment）为真，同时不泄露任何秘密信息。</p>
<p>需要明确的是无论验证者（Ver­i­fier）是否知道证明者（Prover）的秘密信息（或秘密信息的一部分），ZKP都是有意义的。因为证明者仍然需要像验证者证明自己掌握完整的秘密，同时确保不向验证者泄露更多秘密信息。</p>
<p><strong>知识：</strong> 能够提高验证者获得证明者秘密能力的信息均可以被称为知识。</p>
<p><strong>Proof 和 Argument：</strong> 在Proof 系统中哪怕证明者用于无线计算能力也无法欺骗验证者。 在Argument 系统中，只有拥有多项式时间计算能力的证明者才没办法欺骗，如果破解了椭圆曲线离散对数问题，证明者就可以欺骗验证者。</p>
<h4 id="1-1-2-ZKP-基本性质"><a href="#1-1-2-ZKP-基本性质" class="headerlink" title="1.1.2  ZKP 基本性质"></a>1.1.2  ZKP 基本性质</h4><p>零知识证明需具备的三个基本性质：</p>
<ul>
<li>完备性：如果陈述（Statement）是正确的的，证明者（Prover）一定可以说服验证者（Verifier）</li>
<li>可靠性：如果陈述（Statement）是错误的，证明者（Prover）无法说服验证者（Verifier）</li>
<li>零知识性：协议的交互仅揭露陈述的正确性，不泄露其他信息。</li>
</ul>
<h3 id="1-2-预备知识"><a href="#1-2-预备知识" class="headerlink" title="1.2 预备知识"></a>1.2 预备知识</h3><h4 id="1-2-1-术语"><a href="#1-2-1-术语" class="headerlink" title="1.2.1 术语"></a>1.2.1 术语</h4><p><strong>实例（Instance）：</strong> 这是证明者和验证者双方都知道的输入，用于支撑需要被证明的陈述。记为：$x$。</p>
<p><strong>证据（Witness）：</strong> 这里的证据是指用于支持陈述的证据，即证明者所知的秘密信息（隐私输入）。记为：$w$。</p>
<p><strong>关系（Relation）：</strong> 关系用于明确instance和witness之间联系，关系可以被视为一组合理的(instance,witness)对。记为：$R$。</p>
<p><strong>语言（Language）：</strong> 在关系中出现为允许配对的实例集合。记为：$L$。</p>
<p><strong>陈述 （Statement）：</strong> 通过实例和关系来定义。声称实例在关系中有一个证据（可以是真或假）。记为：$x \in L$。</p>
<p><strong>安全参数（Security Parameter）：</strong> 全参数为一个正整数（通常为$128$或$256$），越大表示系统越安全，大部分构造中将安全参数区分计算安全参数（记为：$k$）和统计安全参数（记为：$s$）,或者统一记为：$\lambda$。</p>
<p><strong>设置（Setup）：</strong> 给证明者和验证者的输入，除了实例$x$和证据$w$之外，每个参与者的设置可以分解为私有组件（PrivateSetupP或PrivateSetupV）和公共组件（如公共参考串 ,CRS）。</p>
<blockquote>
<p>例：证明自己拥有付款能力但是又不泄露银行余额。拥有付款能力（statement）需要依赖于银行签名的加密资料（instance），而加密密钥和资料明文（witness）是证明者的隐私，验证者不应当知道。</p>
</blockquote>
<h4 id="1-2-2-符号"><a href="#1-2-2-符号" class="headerlink" title="1.2.2 符号"></a>1.2.2 符号</h4><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">符号</th>
<th style="text-align:center">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$\vec{a}\in \mathbb{F}^{1\times n}$​</td>
<td style="text-align:center">表示域$\mathbb{F}$上长度为$n$的向量</td>
</tr>
<tr>
<td style="text-align:center">$A\in \mathbb{F}^{m \times n}$<br /></td>
<td style="text-align:center">表示$m$行$n$列的矩阵</td>
</tr>
<tr>
<td style="text-align:center">$f(\cdot )$​</td>
<td style="text-align:center">多项式</td>
</tr>
<tr>
<td style="text-align:center">$\vec{f(\cdot)}$<br /></td>
<td style="text-align:center">向量多项式</td>
</tr>
<tr>
<td style="text-align:center">$A\vec{a}$<br /></td>
<td style="text-align:center">矩阵向量的成绩</td>
</tr>
<tr>
<td style="text-align:center">$\vec{a} \cdot \vec{b} =\sum_{i=1}^{n} a_i \cdot b_i$​</td>
<td style="text-align:center">表示向量 $\vec{a}$ 与向量 $\vec{b}$的内积.</td>
</tr>
<tr>
<td style="text-align:center">$\odot$​</td>
<td style="text-align:center">哈达玛积</td>
</tr>
<tr>
<td style="text-align:center">$[n]$​</td>
<td style="text-align:center">$\{1,2,\dots ,n \}$​</td>
</tr>
<tr>
<td style="text-align:center">$y  \overset{$}{\leftarrow} S$​</td>
<td style="text-align:center">从集合$S$中随机挑选$y$​</td>
</tr>
</tbody>
</table>
</div>
<p>‍</p>
<h4 id="1-2-3-缩略词"><a href="#1-2-3-缩略词" class="headerlink" title="1.2.3 缩略词"></a>1.2.3 缩略词</h4><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">缩略词</th>
<th style="text-align:center">英文含义</th>
<th style="text-align:center">中文含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">IP</td>
<td style="text-align:center">interactive proof</td>
<td style="text-align:center">交互式证明</td>
</tr>
<tr>
<td style="text-align:center">LIP</td>
<td style="text-align:center">linear interactive proof</td>
<td style="text-align:center">线性交互式证明</td>
</tr>
<tr>
<td style="text-align:center">PCP</td>
<td style="text-align:center">probabilistic checkable proof</td>
<td style="text-align:center">概率可验证证明</td>
</tr>
<tr>
<td style="text-align:center">DEIP</td>
<td style="text-align:center">doubly efficient interactive proof</td>
<td style="text-align:center">双向高效的交互式证明</td>
</tr>
<tr>
<td style="text-align:center">linear-PCP</td>
<td style="text-align:center">-</td>
<td style="text-align:center">线性 PCP</td>
</tr>
<tr>
<td style="text-align:center">sum-check协议</td>
<td style="text-align:center">-</td>
<td style="text-align:center">求和验证协议</td>
</tr>
<tr>
<td style="text-align:center">IPCP</td>
<td style="text-align:center">interactive PCP</td>
<td style="text-align:center">交互式概率可验证证明</td>
</tr>
<tr>
<td style="text-align:center">R1CS</td>
<td style="text-align:center">rank-1 constraint system</td>
<td style="text-align:center">一阶约束系统</td>
</tr>
<tr>
<td style="text-align:center">IOP</td>
<td style="text-align:center">interactive oracle proof</td>
<td style="text-align:center">交互式谕示证明</td>
</tr>
<tr>
<td style="text-align:center">IPA</td>
<td style="text-align:center">inner product argument</td>
<td style="text-align:center">内积论证</td>
</tr>
<tr>
<td style="text-align:center">CRS</td>
<td style="text-align:center">common reference string</td>
<td style="text-align:center">公共参考字符串</td>
</tr>
<tr>
<td style="text-align:center">URS</td>
<td style="text-align:center"></td>
<td style="text-align:center">统一参考字符串</td>
</tr>
<tr>
<td style="text-align:center">SRS</td>
<td style="text-align:center">structured reference string</td>
<td style="text-align:center">结构化引用字符串</td>
</tr>
<tr>
<td style="text-align:center">DLOG</td>
<td style="text-align:center">discrete logarithm assumption</td>
<td style="text-align:center">离散对数假设</td>
</tr>
<tr>
<td style="text-align:center">ROM</td>
<td style="text-align:center">random oracle model</td>
<td style="text-align:center">随机谕言模型</td>
</tr>
<tr>
<td style="text-align:center">MPC</td>
<td style="text-align:center">secure multiparty computation</td>
<td style="text-align:center">安全多方计算</td>
</tr>
<tr>
<td style="text-align:center">C-SAT问题</td>
<td style="text-align:center">circuit satisfiability problem</td>
<td style="text-align:center">电路可满足问题</td>
</tr>
<tr>
<td style="text-align:center">RS 码</td>
<td style="text-align:center">reed solomon code</td>
<td style="text-align:center">里德-所罗门码</td>
</tr>
<tr>
<td style="text-align:center">CRHF</td>
<td style="text-align:center">collision-resistant hash function</td>
<td style="text-align:center">抗碰撞哈希函数</td>
</tr>
<tr>
<td style="text-align:center">NIZKAoK</td>
<td style="text-align:center">non-interactive zero-knowledge argument of knowledge</td>
<td style="text-align:center">非交互零知识知识论证</td>
</tr>
<tr>
<td style="text-align:center">QAP</td>
<td style="text-align:center">quadratic arithmetic program</td>
<td style="text-align:center">二次算术程序</td>
</tr>
</tbody>
</table>
</div>
<p>‍</p>
<h3 id="1-3-构建ZKP系统"><a href="#1-3-构建ZKP系统" class="headerlink" title="1.3 构建ZKP系统"></a>1.3 构建ZKP系统</h3><ol>
<li>将待证明陈述归约为 C-SAT 问题。C-SAT问题是一个NPC问题，任何NP问题都可在多项式时间内归约为C-SAT问题，同时大多数实际问题都可用电路形式表达，因此待证明陈述表示形式大都为C-SAT问题。</li>
<li>将 C-SAT 问题转换为易证明的语言。需要将C-SAT问题表现形式转换为容易证明的表现形式，例如QAP问题等。</li>
<li>针对易证明的语言构造信息论安全证明。</li>
<li>利用密码编译器将信息论安全证明转换为简洁非交互零知识证明。​</li>
</ol>
<h4 id="1-3-1-待证明陈述表达方式"><a href="#1-3-1-待证明陈述表达方式" class="headerlink" title="1.3.1 待证明陈述表达方式"></a>1.3.1 待证明陈述表达方式</h4><h5 id="算术电路"><a href="#算术电路" class="headerlink" title="算术电路"></a>算术电路</h5><p>算数电路是一种计算模型，可以表示为有向无环图。电路中的每个节点均有若干域上的加法门和乘法门。</p>
<h5 id="布尔电路"><a href="#布尔电路" class="headerlink" title="布尔电路"></a>布尔电路</h5><p>布尔电路是算数电路的子类，其仅有与门、异或门等布尔逻辑门，变量取值仅为0或1。通过增加常数级别的电路门和深度, 任何布尔电路都可以转换为算术电路</p>
<h5 id="分层算术电路"><a href="#分层算术电路" class="headerlink" title="分层算术电路"></a>分层算术电路</h5><p>分层算术电路是一种特殊的算术电路，其中的门（或操作）被分成不同的层次，每一层的门只能使用前一层门的输出作为输入。这种结构使得电路的计算过程可以进行有效的并行化，同时也能够减少电路的深度。在零知识证明的构建中，分层算术电路可以帮助降低证明的复杂性。</p>
<h5 id="数据并行电路"><a href="#数据并行电路" class="headerlink" title="数据并行电路"></a>数据并行电路</h5><p>数据并行电路是一种可以处理多个输入数据并同时执行多个操作的电路。在这种电路中，同一操作可以在不同数据上并行执行，从而实现高效计算。数据并行电路在处理大规模数据时非常有效，因为它们可以利用现代硬件的并行计算能力来加速运算。</p>
<h5 id="对数空间可计算电路"><a href="#对数空间可计算电路" class="headerlink" title="对数空间可计算电路"></a>对数空间可计算电路</h5><p>对数空间可计算电路是一种特殊类型的电路，其计算过程只需要对数级别的内存空间。这类电路在复杂性理论和计算机科学中有重要应用，因为它们可以有效地解决一些具有特定属性的问题。对数空间电路的一个关键特性是它们能够在非常有限的空间内执行复杂的计算，这使得它们在处理大规模数据集或者内存受限的环境中特别有用。</p>
<h5 id="一阶约束系统"><a href="#一阶约束系统" class="headerlink" title="一阶约束系统"></a>一阶约束系统</h5><p>阶约束系统（Rank-1 Constraint Systems, R1CS）是一种特定的代数约束系统，广泛应用于零知识证明的构造。在R1CS中，每一个约束都要求一组变量的线性组合、另一组变量的线性组合和第三组变量的线性组合的乘积相等。这种约束系统对于构造零知识证明非常有用，因为它可以有效地编码许多不同类型的计算和条件。</p>
<h5 id="二次算术程序（QAP）双线性配对"><a href="#二次算术程序（QAP）双线性配对" class="headerlink" title="二次算术程序（QAP）双线性配对"></a>二次算术程序（QAP）双线性配对</h5><p>这可能是指在零知识证明中使用双线性配对来处理次算术程序。双线性配对是一种数学工具，可以用于构造各种密码学协议，包括一些零知识证明系统。二次算术程序是一种特殊类型的算术电路，其中的每个门只能执行乘法或者加法操作，并且所有的乘法门的输入必须来自于前一层的门或者输入层。</p>
<h4 id="1-3-2-信息论证明"><a href="#1-3-2-信息论证明" class="headerlink" title="1.3.2 信息论证明"></a>1.3.2 信息论证明</h4><h5 id="IP-Interactive-Proof-Systems-交互证明系统"><a href="#IP-Interactive-Proof-Systems-交互证明系统" class="headerlink" title="IP (Interactive Proof Systems) 交互证明系统"></a>IP (Interactive Proof Systems) 交互证明系统</h5><p>IP系统由证明者(Prover)和验证者(Verifier)组成,通过交互验证某个语句的正确性。</p>
<p>IP系统通常有以下特点:</p>
<ul>
<li>证明者和验证者交替发送信息(回合交互)</li>
<li>信息量每轮都很小(通常是多项式大小)</li>
<li>通过有限回合交互,验证者可以判断语句正确性</li>
<li>可提供完全性和可靠性保证</li>
</ul>
<h5 id="PCP-Probabilistically-Checkable-Proofs-概率检查可证明"><a href="#PCP-Probabilistically-Checkable-Proofs-概率检查可证明" class="headerlink" title="PCP(Probabilistically Checkable Proofs) 概率检查可证明"></a>PCP(Probabilistically Checkable Proofs) 概率检查可证明</h5><p>对于一个长证明,验证者只需要读取证明的少数位置,就可以以非常高的概率判断整个证明是否正确。Prover 不会直接把 PCP 证明发送给 Verifier，而是向 Verifier 发送一个预言机 (Oracle)，叫做 PCP 预言机。Verifier 可以随意查询 PCP 预言机，获取 PCP 字符串任意位置的比特。</p>
<h5 id="IPCP-Interactive-PCP-交互式概率可验证证明"><a href="#IPCP-Interactive-PCP-交互式概率可验证证明" class="headerlink" title="IPCP (Interactive PCP)交互式概率可验证证明"></a>IPCP (Interactive PCP)交互式概率可验证证明</h5><p>交互式概率可验证证明模型可以看做 IP 模型和 PCP 模型的相加。在 IPCP 模型中，Prover 向 Verifier 发送了 PCP 预言机后，Prover 和 Verifier 继续进行交互。交互过程中，Verifier 可以不时地访问 PCP 预言机。</p>
<h5 id="IOP-Interactive-Oracle-Proof-交互式谕示证明"><a href="#IOP-Interactive-Oracle-Proof-交互式谕示证明" class="headerlink" title="IOP(Interactive Oracle Proof)交互式谕示证明"></a>IOP(Interactive Oracle Proof)交互式谕示证明</h5><p>IOP是一个交互协议,包括一个验证者和一个预言机(具有特定功能的黑盒)。验证者可以交互查询预言机,以此验证某个语句的正确性。是构建SNARK的一个关键概念。</p>
<p>IOP的特点:</p>
<ul>
<li>验证者只与预言机进行交互,不需要了解预言机的内部构造</li>
<li>通过有限的交互,验证者可以验证复杂语句的正确性</li>
<li>预言机无需保密,只需要正确回答查询</li>
</ul>
<p>可分为如下几类</p>
<ul>
<li>多项式IOP(PIOP):预言机是计算多项式的黑盒</li>
<li>多线性IOP:预言机是计算线性多项式的黑盒</li>
<li>向量IOP:预言机支持向量运算的黑盒</li>
</ul>
<h5 id="Linear-PCP-线性概率可验证证明"><a href="#Linear-PCP-线性概率可验证证明" class="headerlink" title="Linear-PCP 线性概率可验证证明"></a>Linear-PCP 线性概率可验证证明</h5><p>与PCP相比，增加了一个限制这里的预言机只能是线性的。</p>
<h4 id="1-3-3-承诺"><a href="#1-3-3-承诺" class="headerlink" title="1.3.3 承诺"></a>1.3.3 承诺</h4><h5 id="默克尔树-抗碰撞哈希函数"><a href="#默克尔树-抗碰撞哈希函数" class="headerlink" title="默克尔树:抗碰撞哈希函数"></a>默克尔树:抗碰撞哈希函数</h5><p>默克尔树（Merkle Tree）是一种数据结构，通常用于对大量数据进行有效的验证和校验。它使用抗碰撞哈希函数来创建一个“树”结构，其中每个节点是其子节点内容的哈希值。这使得任何对数据的更改都会导致树中相应节点的哈希值改变，从而能够方便地检测出数据的篡改。</p>
<h5 id="里德-所罗门码"><a href="#里德-所罗门码" class="headerlink" title="里德-所罗门码"></a>里德-所罗门码</h5><p>里德-所罗门码（Reed-Solomon codes）是一种纠错码，能够有效地处理信息传输过程中的错误。在零知识证明中，里德-所罗门码可以用于低度检查，这是一种验证电路或者函数是否为低度的方法。通过对求和验证或者其他方法的使用，可以有效地验证一个里德-所罗门码是否满足特定的属性或者条件。</p>
<h5 id="FRI-Fast-Reed-Solomon-In­ter­ac­tive-Or­a­cle-Proofs-of-Prox­im­ity"><a href="#FRI-Fast-Reed-Solomon-In­ter­ac­tive-Or­a­cle-Proofs-of-Prox­im­ity" class="headerlink" title="FRI(Fast Reed-Solomon In­ter­ac­tive Or­a­cle Proofs of Prox­im­ity)"></a>FRI(Fast Reed-Solomon In­ter­ac­tive Or­a­cle Proofs of Prox­im­ity)</h5><p>主要用于检查一个点集是否都在一个给定的多项式上。</p>
<h5 id="IPA-Inner-Product-Arguments-内积论证"><a href="#IPA-Inner-Product-Arguments-内积论证" class="headerlink" title="IPA (Inner Product Arguments)内积论证"></a>IPA (Inner Product Arguments)内积论证</h5><p>内积论证是一种证明两个向量内积值的有效方法。在零知识证明中，内积论证常常用于证明两个向量的内积满足某个特定值，而不需要揭示这两个向量的具体内容。这对于保护证明者的隐私非常有用。</p>
<h5 id="KZG承诺"><a href="#KZG承诺" class="headerlink" title="KZG承诺"></a>KZG承诺</h5><p>一种由椭圆曲线和多项式组成的承诺方案</p>
<p>‍</p>
<h4 id="1-3-4-ZKP系统的前后端"><a href="#1-3-4-ZKP系统的前后端" class="headerlink" title="1.3.4 ZKP系统的前后端"></a>1.3.4 ZKP系统的前后端</h4><p>ZKP证明系统可以分为前端和后端两个部分。</p>
<p>前端：是算术化步骤，将语句的高级表示转换为本地表示。在大多数情况下，将完整的计算机程序转变为电路。</p>
<p>后端：包含低级加密协议实现的软件部分。它证明了实例和见证被表示为变量赋值的语句，并且关系通过低级语言表示。通常由ZKP方案的具体实现组成。</p>
<h3 id="1-4-评价标准"><a href="#1-4-评价标准" class="headerlink" title="1.4 评价标准"></a>1.4 评价标准</h3><p>证明复杂度：线性级别、准线性级别</p>
<p>通信复杂度（证明规模）：根号级别、对数级别、常数级别</p>
<p>验证复杂度：：线性级别、亚线性级别</p>
<p>系统参数生成方式：系统参数私密生成、 系统参数公开生成。</p>
<p>抗量子性</p>
<p>通用性</p>
<h3 id="1-5-其他概念"><a href="#1-5-其他概念" class="headerlink" title="1.5 其他概念"></a>1.5 其他概念</h3><h5 id="Fiat-Shamir启发式-6"><a href="#Fiat-Shamir启发式-6" class="headerlink" title="Fiat-Shamir启发式[6]"></a>Fiat-Shamir启发式[6]</h5><p>这是一种将交互式证明系统转换为非交互式签名方案的通用方法。</p>
<h5 id="Sumcheck-protocol"><a href="#Sumcheck-protocol" class="headerlink" title="Sumcheck protocol"></a><strong>Sumcheck protocol</strong></h5><p>Sumcheck协议是一种交互式证明系统，它允许证明者证明一个关于多项式的性质，例如多项式在一个域上的和。这种协议被广泛应用于一些基于PCP的零知识证明系统。</p>
<h5 id="递归零知识证明"><a href="#递归零知识证明" class="headerlink" title="递归零知识证明"></a>递归零知识证明</h5><p>递归零知识证明是一种特殊的零知识证明方案，它允许你在一个证明中嵌入另一个证明。可以将多个证明压缩成一个单一的证明，而无需透露任何关于原始证明或其所证明的声明的信息。可以有效地处理和验证大量的证明，特别是在资源受限或者需要高效率的环境中。</p>
<h5 id="Proof-Carrying-Data"><a href="#Proof-Carrying-Data" class="headerlink" title="Proof-Carrying Data"></a>Proof-Carrying Data</h5><p>在分布式计算任务的每个步骤,节点会生成一个证明,证明它执行这一步的计算是正确的。然后将这个证明与下一步的计算输入一起传递给下一个节点。所以每个节点接收到的输入都附带了证明,证明这个输入的计算是正确的。节点可以验证上一步的证明,确保自己接收到的输入是合法的,然后再执行下一步计算。最终结果也会附带一个证明,可以被验证器全面验证整个计算的正确性。</p>
<h5 id="Folding-schemes"><a href="#Folding-schemes" class="headerlink" title="Folding schemes"></a>Folding schemes</h5><p>折叠方案最初由 Nova 引入。 它是一种将两个待证明的实例压缩为一个实例的方法。</p>
<h2 id="2-发展脉络"><a href="#2-发展脉络" class="headerlink" title="2 发展脉络"></a>2 发展脉络</h2><h3 id="2-1-发展历史"><a href="#2-1-发展历史" class="headerlink" title="2.1  发展历史"></a>2.1  发展历史</h3><h4 id="2-1-1-起源"><a href="#2-1-1-起源" class="headerlink" title="2.1.1 起源"></a>2.1.1 起源</h4><h5 id="GMR98-7"><a href="#GMR98-7" class="headerlink" title="GMR98[7]"></a>GMR98[7]</h5><p>零知识证明的概念由Shafi Goldwasser、S. Micali和C. Rackoff在1985年的论文《The Knowledge Complexity of Interactive Proof Systems》中首次提出。他们定义了交互式证明系统的知识复杂性，并引入了零知识证明的概念。</p>
<h4 id="2-1-2-早期发展"><a href="#2-1-2-早期发展" class="headerlink" title="2.1.2 早期发展"></a>2.1.2 早期发展</h4><h5 id="Pinocchio13-8"><a href="#Pinocchio13-8" class="headerlink" title="Pinocchio13[8]"></a>Pinocchio13[8]</h5><p>Pinocchio是零知识简洁非交互式知识论证 (zk-SNARK) 证明系统的第一个概念验证实现之一。证明生成和密钥设置的渐近在计算大小上是线性的，验证时间在公共输入和输出的大小上是线性的。也是 Zcash 使用的基础协议。</p>
<ul>
<li><strong>信息论安全证明：</strong> Linear -PCP</li>
<li><strong>待证明表示方式：</strong> ​算数电路</li>
<li><strong>证明复杂度：</strong>​<strong>$O(|C|) \mathbb{G}_o$</strong>​</li>
<li><strong>验证复杂度：</strong>​<strong>$O(|io|)E$</strong>、$4P$</li>
<li><strong>证明大小：</strong> 288 B</li>
<li><strong>参数生成方式：</strong> 私密</li>
<li><strong>密码学假设：</strong> 椭圆曲线</li>
</ul>
<h5 id="Groth16-9"><a href="#Groth16-9" class="headerlink" title="Groth16[9]"></a>Groth16[9]</h5><p>Groth 于 2016 年推出，是使 zkSnarks 高效且极其实用的首批协议之一。提高了由 R1CS 描述问题的性能，主要缺点是待证明的每个程序都需要不同的可信设置。应用于ZCash，当下仍有很多基于该协议的应用。</p>
<ul>
<li><strong>信息论安全证明：</strong> Linear -PCP</li>
<li><strong>待证明表示方式：</strong> 算数电路</li>
<li><strong>证明复杂度：</strong>​<strong>$O(|C|) \mathbb{G}_o$</strong></li>
<li><strong>验证复杂度：</strong>​<strong>$O(|io|)E$</strong>、$4P$</li>
<li><strong>证明大小：</strong> 0.2KB</li>
<li><strong>参数生成方式：</strong> 私密</li>
<li><strong>密码学假设：</strong> 椭圆曲线</li>
</ul>
<h4 id="2-1-3-透明"><a href="#2-1-3-透明" class="headerlink" title="2.1.3 透明"></a>2.1.3 透明</h4><h5 id="Bulletproofs16-10"><a href="#Bulletproofs16-10" class="headerlink" title="Bulletproofs16[10]"></a>Bulletproofs16[10]</h5><p>一种新的非交互式零知识证明协议，其证明非常简短，并且无需可信设置；该协议可以用于证明秘密在给定范围内。证明大小只是见证大小的对数。应用于 Monero。</p>
<ul>
<li><strong>信息论安全证明：</strong> ?</li>
<li><strong>待证明表示方式：</strong> 算数电路</li>
<li><strong>证明复杂度：</strong>​<strong>$O(|C|) \mathbb{F}_o$</strong></li>
<li><strong>验证复杂度：</strong>​<strong>$O(|C|)\mathbb{G}_o$</strong>​</li>
<li><strong>证明大小：</strong>​<strong>$O(\log N)$</strong></li>
<li><strong>参数生成方式：</strong> 公开</li>
<li><strong>密码学假设：</strong> 椭圆曲线</li>
</ul>
<h5 id="Ligero-17-11"><a href="#Ligero-17-11" class="headerlink" title="Ligero 17[11]"></a>Ligero 17[11]</h5><p>Ligero 引入了一个证明系统，该系统实现了大小为的证明，其中电路的大小。它以矩阵形式排列多项式系数并使用线性代码。</p>
<ul>
<li><strong>信息论安全证明：IPCP</strong></li>
<li><strong>待证明表示方式：</strong> 算数/布尔电路</li>
<li><strong>证明复杂度：</strong>​<strong>$O(|C| \log^2 |C|)\mathbb{F}_o$</strong></li>
<li><strong>验证复杂度：</strong>​<strong>$O(\sqrt{n}) \mathbb{G}_o$</strong> <strong>或</strong>​<strong>$O(|C|) \mathbb{F}_o$</strong></li>
<li><strong>证明大小：</strong>​$O(\sqrt{n})$</li>
<li><strong>参数生成方式：</strong> 公开</li>
<li><strong>密码学假设：</strong> 抗碰撞哈希函数</li>
</ul>
<h5 id="STARKs18-12"><a href="#STARKs18-12" class="headerlink" title="STARKs18[12]"></a>STARKs18[12]</h5><p>STARKS（Zero-Knowledge Scalable Transparent ARguments of Knowledge)零知识可扩展透明知识论证。可快速证明和验证，不需要可信设置，并且被认为是后量子安全的。其首先由Starkware/Starknet 与 Cairo 虚拟机一起使用。STARKs 也被其他项目（Polygon Miden、Risc0、Winterfell、Neptune）使用，或对其的一些改编（ZK-Sync 的 Boojum、Plonky2、Starky）,此外还有zilch框架。</p>
<ul>
<li><strong>信息论安全证明：IOP</strong></li>
<li><strong>待证明表示方式：</strong> 对数空间可计算电路</li>
<li><strong>证明复杂度：</strong>​<strong>$O(T \log T ) \mathbb{F}_o$</strong></li>
<li><strong>验证复杂度：</strong>​<strong>$O(\log T ) \mathbb{F}_o$</strong></li>
<li><strong>证明大小：</strong>​<strong>$O(\log^2 n)$</strong></li>
<li><strong>参数生成方式：</strong> 公开</li>
<li><strong>密码学假设：</strong> 抗碰撞哈希函数</li>
</ul>
<h5 id="Spartan19-13"><a href="#Spartan19-13" class="headerlink" title="Spartan19[13]"></a>Spartan19[13]</h5><p>Spartan 为使用 R1CS 描述的电路提供了 IOP，利用多变量多项式和 sumcheck 协议的属性。使用合适的多项式承诺方案，它会产生带有线性时长 prover 的透明 SNARK。</p>
<ul>
<li><strong>信息论安全证明：IOP</strong></li>
<li><strong>待证明表示方式：</strong> 一阶约束系统</li>
<li><strong>证明复杂度：</strong>​<strong>$O(n) \mathbb{G}_o$</strong> <strong>或</strong>​<strong>$O(n \log n)\mathbb{ F}_o$</strong></li>
<li><strong>验证复杂度：</strong>​<strong>$O(\sqrt{n}) \mathbb{G}_o$</strong> <strong>或</strong>​<strong>$O( \log^2 n)\mathbb{ F}_o$</strong>​</li>
<li><strong>证明大小：</strong>​<strong>$O( \log^2 n)$</strong>~$O(\sqrt{n})$</li>
<li><strong>参数生成方式：</strong> 公开</li>
<li><strong>密码学假设：</strong> 抗碰撞哈希函数</li>
</ul>
<h4 id="2-1-4-通用化"><a href="#2-1-4-通用化" class="headerlink" title="2.1.4 通用化"></a>2.1.4 通用化</h4><h5 id="SONIC19-14"><a href="#SONIC19-14" class="headerlink" title="SONIC19[14]"></a><strong>SONIC19[14]</strong></h5><p>Sonic 是早期的通用 zk-SNARK 协议。CRS 满足通用性的同时，支持连续可更新，同时大小与待证明的关系呈线性。Sonic 还具有恒定的证明大小但是验证时间很长。</p>
<ul>
<li><strong>信息论安全证明：</strong></li>
<li><strong>待证明表示方式：</strong></li>
<li><strong>证明复杂度：</strong>​<strong>$O(n\log n)$</strong></li>
<li><strong>验证复杂度：</strong>​<strong>$O(I+\log n)$</strong></li>
<li><strong>证明大小：</strong>​$O(1)$</li>
<li><strong>参数生成方式：</strong></li>
<li><strong>密码学假设：</strong> 椭圆曲线</li>
</ul>
<h5 id="MARLIN19-15"><a href="#MARLIN19-15" class="headerlink" title="MARLIN19[15]"></a><strong>MARLIN19[15]</strong></h5><p>Marlin 是 Sonic 的显著改进版本，证明时间减少了 10 倍。它还提供了更快的验证而无需批处理，并将验证时间缩短了 3 倍。</p>
<ul>
<li><strong>信息论安全证明：</strong></li>
<li><strong>待证明表示方式：</strong></li>
<li><strong>证明复杂度：</strong>​<strong>$O(n\log n)$</strong></li>
<li><strong>验证复杂度：</strong>​<strong>$O(I+\log n)$</strong></li>
<li><strong>证明大小：</strong>​$O(1)$</li>
<li><strong>参数生成方式：</strong></li>
<li><strong>密码学假设：</strong> 椭圆曲线</li>
</ul>
<h5 id="PLONK19-16"><a href="#PLONK19-16" class="headerlink" title="PLONK19[16]"></a><strong>PLONK19[16]</strong></h5><p>PLONK 是 SONIC 的另一个改进版本，引入了一种新的算术化方案(Plonkish),允许自定义门。多个项目都有 Plonk 的定制版本，包括 Aztec、ZK-Sync、Polygon ZKEVM、Mina’s Kimchi、Plonky2、Halo 2 和 Scroll 等。</p>
<ul>
<li><strong>信息论安全证明：</strong></li>
<li><strong>待证明表示方式：</strong></li>
<li><strong>证明复杂度：</strong>​<strong>$O(n\log n)$</strong></li>
<li><strong>验证复杂度：</strong>​<strong>$O(I)$</strong></li>
<li><strong>证明大小：</strong>​$O(1)$</li>
<li><strong>参数生成方式：</strong></li>
<li><strong>密码学假设：</strong> 椭圆曲线</li>
</ul>
<h5 id="Plonkup22-17"><a href="#Plonkup22-17" class="headerlink" title="Plonkup22[17]"></a>Plonkup22[17]</h5><p>在 Plonk 中引入 plookup 参数。这些查找参数的问题在于，它们迫使证明者为整个表付出代价，而与他的查找次数无关。这意味着大型表的成本相当高，并且已经投入了大量精力来降低证明者的成本，仅减少他使用的查找次数。</p>
<h5 id="HALO2"><a href="#HALO2" class="headerlink" title="HALO2"></a><strong>HALO2</strong></h5><p>2020 年，Zcash 团队推出了 HALO 2（HALO 的继后继者），它结合了 PLONK 和 Bulletproofs 的优点，然后允许在没有可信设置的情况下进行快速验证。</p>
<p>‍</p>
<h5 id="HYPERPLONK23-18"><a href="#HYPERPLONK23-18" class="headerlink" title="HYPERPLONK23[18]"></a><strong>HYPERPLONK23[18]</strong></h5><p>HyperPlonk 建立在 Plonk 的思想之上，使用多元多项式。依赖于 sumcheck 协议检查约束执行。由于它依赖于多元多项式，因此无需进行FFT，并且证明者的运行时间在电路尺寸上是线性的。HyperPlonk 引入了适用于较小字段的新排列 IOP 和基于总和检查的批量打开协议，从而减少了证明者的工作量、证明大小和验证者的时间。</p>
<h5 id="HyperPlonk"><a href="#HyperPlonk" class="headerlink" title="HyperPlonk+"></a>HyperPlonk+</h5><p>将查找门集成到 Hy­per­Plonk 的约束系统。</p>
<h5 id="PLONKY2-19"><a href="#PLONKY2-19" class="headerlink" title="PLONKY2[19]"></a><strong>PLONKY2[19]</strong></h5><p>最近，Polygon 于 2022 年 1 月发布的 Plonky2 是 ZKP 世界中最新的。它是一种递归 SNARK，比现有其他方案快 100 倍。它结合了 PLONK 和 FRI，以获得最好的 STARK（即快速证明和无可信设置）和最好的 SNARK（即支持递归和以太坊上的低验证成本）。</p>
<ul>
<li><strong>信息论安全证明：</strong></li>
<li><strong>待证明表示方式：</strong></li>
<li><strong>证明复杂度：</strong>​<strong>$O(\log n)$</strong></li>
<li><strong>验证复杂度：</strong>​<strong>$O(\log n)$</strong></li>
<li><strong>证明大小：</strong>​$O(n\log n)$</li>
<li><strong>参数生成方式：</strong></li>
<li><strong>密码学假设：</strong> 抗碰撞哈希函数</li>
</ul>
<p>‍</p>
<h4 id="2-1-5-折叠"><a href="#2-1-5-折叠" class="headerlink" title="2.1.5 折叠"></a>2.1.5 折叠</h4><h5 id="Nova21-19"><a href="#Nova21-19" class="headerlink" title="Nova21[19]"></a>Nova21[19]</h5><p>Nova 引入了折叠方案的概念，这是一种实现增量可验证计算 （IVC） 的新方法。Nova 使用 R1CS 的宽松版本，并在友好的椭圆曲线上工作。使用曲线的友好循环来实现 IVC，也用于 Pickles，这是 Mina 的主要构建块，以实现简洁状态。</p>
<h5 id="SuperNova22-20"><a href="#SuperNova22-20" class="headerlink" title="SuperNova22[20]"></a>SuperNova22[20]</h5><p>将Nova扩展到处理不同类型的电路。</p>
<h5 id="Sangria"><a href="#Sangria" class="headerlink" title="Sangria"></a>Sangria</h5><p>San­gria 借鉴了 Nova 的思想，为 Plonk 的变体构建了一个折叠方案</p>
<h3 id="2-2-发展趋势"><a href="#2-2-发展趋势" class="headerlink" title="2.2 发展趋势"></a>2.2 发展趋势</h3><h5 id="新的多项式承诺方案"><a href="#新的多项式承诺方案" class="headerlink" title="新的多项式承诺方案"></a>新的多项式承诺方案</h5><p>随着基于多元多项式的高效 SNARK 的出现，例如 Spartan 或 HyperPlonk，人们对适合此类多项式的新承诺方案越来越感兴趣。Binius、Zeromorph 和 Basefold 都提出了新的形式来致力于多线性多项式。Binius 的优点是表示数据类型的开销为零（而许多证明系统至少使用至少 32 位字段元素来表示单个位），并且适用于二进制字段。该承诺调整了制动，该制动被设计为与现场无关。Basefold 将 FRI 推广到 Reed-Solomon 以外的代码，从而产生与字段无关的 PCS。</p>
<h5 id="可定制约束系统"><a href="#可定制约束系统" class="headerlink" title="可定制约束系统"></a>可定制约束系统</h5><p>CCS 泛化 R1CS，同时捕获 R1CS、Plonkish 和 AIR 算术，无需开销。将 CCS 与 Spartan IOP 结合使用会产生 SuperSpartan，它支持高度约束，而无需证明者产生随约束程度而扩展的加密成本。特别是，SuperSpartan 为具有线性时间证明器的 AIR 生成了 SNARK。</p>
<p>‍</p>
<p>‍</p>
<p>‍</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1]李威翰, 张宗洋, 周子博, 等. 简洁非交互零知识证明综述[J/OL]. 密码学报, 2022, 9(3): 379-447. DOI:<a href="https://doi.org/10.13868/j.cnki.jcr.000525">10.13868/j.cnki.jcr.000525</a>.</p>
<p>[2]Community Reference - ZKProof Resources[EB/OL]. [2024-06-07]. <a href="https://docs.zkproof.org/reference">https://docs.zkproof.org/reference</a>.</p>
<p>[3]SNOWOLF. ZKP Part 1：Background and Preliminary - 三两老友杂的小岛[EB/OL]//ZKP Part 1：Background and Preliminary - 三两老友杂的小岛. (2022-11-10)[2024-06-09]. <a href="https://snowolf0620.xyz/index.php/zkp/798.html">https://snowolf0620.xyz/index.php/zkp/798.html</a>.</p>
<p>[4]GE 戈文波Geir-Wenbo. 第一部分：零知识证明[EB/OL]//Medium. (2024-01-26)[2024-06-10]. <a href="https://medium.com/@gewenbo888/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E-c21379e3ea83">https://medium.com/@gewenbo888/第一部分-零知识证明-c21379e3ea83</a></p>
<p>[5]FEIYU. 零知识zhe —Zkpass[EB/OL]//Medium. (2022-09-20)[2024-06-12]. <a href="https://medium.com/@chong599llj/%E9%9B%B6%E7%9F%A5%E8%AF%86zhe-zkpass-8950b00cd9a2">https://medium.com/@chong599llj/%E9%9B%B6%E7%9F%A5%E8%AF%86zhe-zkpass-8950b00cd9a2</a>.</p>
<p>[6]FIAT A, SHAMIR A. How To Prove Yourself: Practical Solutions to Identification and Signature Problems[C/OL]//ODLYZKO A M. Advances in Cryptology — CRYPTO’ 86. Berlin, Heidelberg: Springer, 1987: 186-194. DOI:<a href="https://doi.org/10.1007/3-540-47721-7_12">10.1007/3-540-47721-7_12</a>.</p>
<p>[7]GOLDWASSER S, MICALI S, RACKOFF C. The Knowledge Complexity of Interactive Proof Systems[J/OL]. SIAM Journal on Computing, 1989, 18: 186-208. DOI:<a href="https://doi.org/10.1137/0218012">10.1137/0218012</a>.</p>
<p>[8]Pinocchio: Nearly Practical Verifiable Computation | IEEE Conference Publication | IEEE Xplore[EB/OL]. [2024-06-11]. <a href="https://ieeexplore.ieee.org/document/6547113">https://ieeexplore.ieee.org/document/6547113</a>.</p>
<p>[9]GROTH J. On the Size of Pairing-Based Non-interactive Arguments[C/OL]//FISCHLIN M, CORON J S. Advances in Cryptology – EUROCRYPT 2016. Berlin, Heidelberg: Springer, 2016: 305-326. DOI:<a href="https://doi.org/10.1007/978-3-662-49896-5_11">10.1007/978-3-662-49896-5_11</a>.</p>
<p>[10]BOOTLE J, CERULLI A, CHAIDOS P, 等. Efficient Zero-Knowledge Arguments for Arithmetic Circuits in the Discrete Log Setting[C/OL]//FISCHLIN M, CORON J S. Advances in Cryptology – EUROCRYPT 2016. Berlin, Heidelberg: Springer, 2016: 327-357. DOI:<a href="https://doi.org/10.1007/978-3-662-49896-5_12">10.1007/978-3-662-49896-5_12</a>.</p>
<p>[11]AMES S, HAZAY C, ISHAI Y, 等. Ligero: Lightweight Sublinear Arguments Without a Trusted Setup[C/OL]//Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. New York, NY, USA: Association for Computing Machinery, 2017: 2087-2104[2024-06-11]. <a href="https://dl.acm.org/doi/10.1145/3133956.3134104">https://dl.acm.org/doi/10.1145/3133956.3134104</a>. DOI:<a href="https://doi.org/10.1145/3133956.3134104">10.1145/3133956.3134104</a>.</p>
<p>[12]BEN-SASSON E, BENTOV I, HORESH Y, 等. Scalable, transparent, and post-quantum secure computational integrity[A/OL]. (2018)[2024-06-12]. <a href="https://eprint.iacr.org/2018/046">https://eprint.iacr.org/2018/046</a>.</p>
<p>[13]SETTY S. Spartan: Efficient and General-Purpose zkSNARKs Without Trusted Setup[C/OL]//Advances in Cryptology – CRYPTO 2020. Springer, Cham, 2020: 704-737[2024-06-12]. <a href="https://link.springer.com/chapter/10.1007/978-3-030-56877-1_25">https://link.springer.com/chapter/10.1007/978-3-030-56877-1_25</a>. DOI:<a href="https://doi.org/10.1007/978-3-030-56877-1_25">10.1007/978-3-030-56877-1_25</a>.</p>
<p>[14]MALLER M, BOWE S, KOHLWEISS M, 等. Sonic: Zero-Knowledge SNARKs from Linear-Size Universal and Updatable Structured Reference Strings[C/OL]//Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. New York, NY, USA: Association for Computing Machinery, 2019: 2111-2128[2024-06-11]. <a href="https://doi.org/10.1145/3319535.3339817">https://doi.org/10.1145/3319535.3339817</a>. DOI:<a href="https://doi.org/10.1145/3319535.3339817">10.1145/3319535.3339817</a>.</p>
<p>[15]CHIESA A, HU Y, MALLER M, 等. Marlin: Preprocessing zkSNARKs with Universal and Updatable SRS[C/OL]//CANTEAUT A, ISHAI Y. Advances in Cryptology – EUROCRYPT 2020. Cham: Springer International Publishing, 2020: 738-768. DOI:<a href="https://doi.org/10.1007/978-3-030-45721-1_26">10.1007/978-3-030-45721-1_26</a>.</p>
<p>[16]GABIZON A, WILLIAMSON Z J, CIOBOTARU O. PLONK: Permutations over Lagrange-bases for Oecumenical Noninteractive arguments of Knowledge[A/OL]. (2019)[2024-06-12]. <a href="https://eprint.iacr.org/2019/953">https://eprint.iacr.org/2019/953</a>.</p>
<p>[17]PEARSON L, FITZGERALD J, MASIP H, 等. PlonKup: Reconciling PlonK with plookup[A/OL]. (2022)[2024-06-12]. <a href="https://eprint.iacr.org/2022/086">https://eprint.iacr.org/2022/086</a>.</p>
<p>[18]CHEN B, BÜNZ B, BONEH D, 等. HyperPlonk: Plonk with Linear-Time Prover and High-Degree Custom Gates[C/OL]//Advances in Cryptology – EUROCRYPT 2023. Springer, Cham, 2023: 499-530[2024-06-12]. <a href="https://link.springer.com/chapter/10.1007/978-3-031-30617-4_17">https://link.springer.com/chapter/10.1007/978-3-031-30617-4_17</a>. DOI:<a href="https://doi.org/10.1007/978-3-031-30617-4_17">10.1007/978-3-031-30617-4_17</a>.</p>
<p>[19]KOTHAPALLI A, SETTY S, TZIALLA I. Nova: Recursive Zero-Knowledge Arguments from Folding Schemes[C/OL]//DODIS Y, SHRIMPTON T. Advances in Cryptology – CRYPTO 2022. Cham: Springer Nature Switzerland, 2022: 359-388. DOI:<a href="https://doi.org/10.1007/978-3-031-15985-5_13">10.1007/978-3-031-15985-5_13</a>.</p>
<p>[20]KOTHAPALLI A, SETTY S. SuperNova: Proving universal machine executions without universal circuits[A/OL]. (2022)[2024-06-12]. <a href="https://eprint.iacr.org/2022/1758">https://eprint.iacr.org/2022/1758</a>.</p>
]]></content>
      <categories>
        <category>ZKP</category>
      </categories>
      <tags>
        <tag>ZKP</tag>
      </tags>
  </entry>
  <entry>
    <title>clang 环境配置</title>
    <url>/posts/15893855.html</url>
    <content><![CDATA[<p>在<code>/etc/apt/sources.list.d</code>​目录下创建一个llvm.list文件</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">sudo vi llvm.list</span><br></pre></td></tr></table></figure>
<p>然后前往<a href="https://apt-llvm-org.translate.goog/?_x_tr_sl=en&amp;_x_tr_tl=zh-CN&amp;_x_tr_hl=zh-CN&amp;_x_tr_pto=sc">LLVM 网站</a> 查找对应linux版本的包资源地址，写进文件按中即可。</p>
<figure class="highlight vim"><table><tr><td class="code"><pre><span class="line"><span class="keyword">deb</span>  [arch=amd64] http://apt.llvm.org/noble/ llvm-toolchain-noble main</span><br><span class="line"><span class="keyword">deb</span>-src http://apt.llvm.org/noble/ llvm-toolchain-noble main</span><br><span class="line"># <span class="number">17</span></span><br><span class="line"><span class="keyword">deb</span>  [arch=amd64] http://apt.llvm.org/noble/ llvm-toolchain-noble-<span class="number">17</span> main</span><br><span class="line"><span class="keyword">deb</span>-src http://apt.llvm.org/noble/ llvm-toolchain-noble-<span class="number">17</span> main</span><br><span class="line"># <span class="number">18</span></span><br><span class="line"><span class="keyword">deb</span>  [arch=amd64] http://apt.llvm.org/noble/ llvm-toolchain-noble-<span class="number">18</span> main</span><br><span class="line"><span class="keyword">deb</span>-src http://apt.llvm.org/noble/ llvm-toolchain-noble-<span class="number">18</span> main</span><br></pre></td></tr></table></figure>
<p>然后更新apt：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure>
<p>通常汇报一个错误，提示没有公钥来验证包签名，需要将报错中提示的公钥<code>NO_PUBKEY 15CF4D18AF4F7421</code>​添加到apt密钥环中</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 15CF4D18AF4F7421</span><br></pre></td></tr></table></figure>
<p>修改完在更新一次即可。</p>
<p>执行下面的命令安装相应软件：</p>
<p>llvm</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install libllvm-18-ocaml-dev libllvm18 llvm-18 llvm-18-dev llvm-18-doc llvm-18-examples llvm-18-runtime</span><br></pre></td></tr></table></figure>
<p>lldb</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install lldb-18</span><br></pre></td></tr></table></figure>
<p>lld</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install lld-18</span><br></pre></td></tr></table></figure>
<p>clang</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install clang-18 clang-tools-18 clang-18-doc libclang-common-18-dev libclang-18-dev libclang1-18 clang-format-18 python3-clang-18 clangd-18 clang-tidy-18</span><br></pre></td></tr></table></figure>
<p>compiler-rt</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install libclang-rt-18-dev</span><br></pre></td></tr></table></figure>
<p>libc++</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install libc++-18-dev libc++abi-18-dev</span><br></pre></td></tr></table></figure>
<p>然后安装clangd</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install clangd-18</span><br></pre></td></tr></table></figure>
<p>使用vscode插件需要在插件设置中填写clangd的路径</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1]Install and configure LLVM 18 on Ubuntu 20.04[EB/OL]//Amir’s Homepage. (2024-01-10)[2024-06-15]. <a href="https://amirsojoodi.github.io/posts/Install-LLVM-on-Ubuntu/">https://amirsojoodi.github.io/posts/Install-LLVM-on-Ubuntu/</a>.</p>
]]></content>
      <categories>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>环境</tag>
        <tag>clang</tag>
      </tags>
  </entry>
  <entry>
    <title>连接GitHub</title>
    <url>/posts/d10c5bba.html</url>
    <content><![CDATA[<h1 id="连接GitHub"><a href="#连接GitHub" class="headerlink" title="连接GitHub"></a>连接GitHub</h1><h2 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h2><p>访问不了主要是DNS被污染了，在本机DNS即可。打开如下文件将下面的内容后缀在文件中即可，修改需要管理员权限，确保自己真的修改成功了<code>C:\Windows\System32\drivers\etc\hosts</code>​。在 CMD 窗口输入：<code>ipconfig /flushdns</code>​</p>
<p>linux则是修改<code>/etc/hosts</code>​ 保存可以执行<code>sudo nscd restart</code>​确保其生效。</p>
<p>下面的内容可以在下面的网站中找到最新的：</p>
<p><a href="https://gitee.com/frankwuzp/github-host/blob/main/hosts">hosts · frankwuzp/github-host - Gitee.com</a></p>
<p><a href="https://github.com/maxiaof/github-hosts">maxiaof/github-hosts: 通过修改Hosts解决国内Github经常抽风访问不到,每日更新</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Github Hosts Start</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Project Address: https://github.com/maxiaof/github-hosts</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Update URL: https://raw.githubusercontent.com/maxiaof/github-hosts/master/hosts</span></span><br><span class="line">151.101.129.194	github.global.ssl.fastly.net</span><br><span class="line">185.199.109.153	assets-cdn.github.com</span><br><span class="line">185.199.108.153	documentcloud.github.com</span><br><span class="line">140.82.112.3	gist.github.com</span><br><span class="line">185.199.109.133	gist.githubusercontent.com</span><br><span class="line">185.199.108.154	github.githubassets.com</span><br><span class="line">140.82.112.18	help.github.com</span><br><span class="line">140.82.114.9	nodeload.github.com</span><br><span class="line">185.199.109.133	raw.github.com</span><br><span class="line">140.82.112.17	status.github.com</span><br><span class="line">185.199.111.153	training.github.com</span><br><span class="line">185.199.109.133	avatars.githubusercontent.com</span><br><span class="line">185.199.109.133	avatars0.githubusercontent.com</span><br><span class="line">185.199.109.133	avatars1.githubusercontent.com</span><br><span class="line">185.199.108.133	avatars2.githubusercontent.com</span><br><span class="line">185.199.111.133	avatars3.githubusercontent.com</span><br><span class="line">185.199.110.133	avatars4.githubusercontent.com</span><br><span class="line">185.199.111.133	avatars5.githubusercontent.com</span><br><span class="line">185.199.109.133	avatars6.githubusercontent.com</span><br><span class="line">185.199.109.133	avatars7.githubusercontent.com</span><br><span class="line">185.199.111.133	avatars8.githubusercontent.com</span><br><span class="line">185.199.109.133	favicons.githubusercontent.com</span><br><span class="line">140.82.114.9	codeload.github.com</span><br><span class="line">52.217.116.57	github-cloud.s3.amazonaws.com</span><br><span class="line">52.216.48.177	github-com.s3.amazonaws.com</span><br><span class="line">3.5.25.27	github-production-release-asset-2e65be.s3.amazonaws.com</span><br><span class="line">52.216.221.89	github-production-user-asset-6210df.s3.amazonaws.com</span><br><span class="line">3.5.29.126	github-production-repository-file-5c1aeb.s3.amazonaws.com</span><br><span class="line">185.199.111.153	githubstatus.com</span><br><span class="line">140.82.114.18	github.community</span><br><span class="line">185.199.110.133	media.githubusercontent.com</span><br><span class="line">185.199.109.133	camo.githubusercontent.com</span><br><span class="line">185.199.110.133	raw.githubusercontent.com</span><br><span class="line">185.199.109.133	cloud.githubusercontent.com</span><br><span class="line">185.199.110.133	user-images.githubusercontent.com</span><br><span class="line">2606:50c0:8003::153	customer-stories-feed.github.com</span><br><span class="line">185.199.108.153	pages.github.com</span><br><span class="line">140.82.112.5	api.github.com</span><br><span class="line">140.82.114.26	live.github.com</span><br><span class="line">140.82.112.30	githubapp.com</span><br><span class="line">140.82.113.3	github.com</span><br><span class="line">52.224.38.193	github.dev</span><br><span class="line">140.82.112.21	central.github.com</span><br><span class="line">140.82.113.25	alive.github.com</span><br><span class="line">185.199.111.133	desktop.githubusercontent.com</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">Github Hosts End</span></span><br></pre></td></tr></table></figure>
<h2 id="SSH"><a href="#SSH" class="headerlink" title="SSH"></a>SSH</h2><p>命令行中输入如下指令。</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;your_email@example.com&quot;</span><br><span class="line">#github注册账号的邮箱，其他的不知道可不可以</span><br></pre></td></tr></table></figure>
<p>去用户目录（C:\\Users\\用户）下找到.ssh目录，没有该目录，设置显示隐藏目录，在.ssh目录下找到id_rsa.pub，前往GitHub，创建一个SSH keys，把id_rsa.pub复制过来就可以。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403281530899.png" alt=""><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403281530228.png" alt="">​</p>
<p>将下面内容添加到.ssh/config中,如果没有可以自己创建一个。</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">Host github.com</span><br><span class="line">    User git</span><br><span class="line">    Hostname ssh.github.com</span><br><span class="line">    PreferredAuthentications publickey</span><br><span class="line">    IdentityFile ~/.ssh/id_rsa</span><br><span class="line">    Port <span class="number">443</span></span><br></pre></td></tr></table></figure>
<p>在cmd中输入，验证。</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure>
<p>‍</p>
<p>‍</p>
]]></content>
      <categories>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title>赛博土木B-CUDA系列01：认识GPU</title>
    <url>/posts/50b55d72.html</url>
    <content><![CDATA[<h2 id="1-GPU简单介绍"><a href="#1-GPU简单介绍" class="headerlink" title="1 GPU简单介绍"></a>1 GPU简单介绍</h2><p>GPU(Graphics Processing Unit)也叫做图形处理单元，是一种专用电子电路，最初设计使用来加速计算机图形处理，但后续因其并行结构非常适合与并行计算领域。GPU一共经历了三个历史发展阶段。下面是显卡示意图，主要由GPU和显存组成。<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061543299.png" alt="GPU示意图" title="GPU示意图"></p>
<h2 id="1-1-GPU的发展阶段"><a href="#1-1-GPU的发展阶段" class="headerlink" title="1.1 GPU的发展阶段"></a>1.1 GPU的发展阶段</h2><h4 id="1-1-1-硬件加速阶段"><a href="#1-1-1-硬件加速阶段" class="headerlink" title="1.1.1 硬件加速阶段"></a>1.1.1 硬件加速阶段</h4><p>在1999年以前，将CPU的部分功能剥离出来，形成单独的硬件，实现对图像的硬件加速，只起到3D图像处理的加速作用，不具备软件编程特征。</p>
<h4 id="1-1-2有限编程阶段"><a href="#1-1-2有限编程阶段" class="headerlink" title="1.1.2有限编程阶段"></a>1.1.2有限编程阶段</h4><p>1999-2005年，进一步的硬件加速，但是出现了有限编程性。</p>
<p>1999年，Nvidia发布了专为执行复杂的数学和几何计算的GeForce256图像处理芯片，不同于CPU将晶体管主要用作控制单元和缓存，更多的作为执行单元,将图形变换以及照明等功能从CPU剥离出来，通过变换引擎和照明引擎实现了图形的快速变换以及光照计算，成为GPU出现的标志。</p>
<p>2000-2005，GPU技术快速发展，运算速度迅速超过GPU。Nvidia和ATI（被AMD收购）分别推出的GeForce3和Radeon 8500 ,出现顶点可编程性和像素级可编程性，但是总体上编程性十分有限。</p>
<h4 id="1-1-3-软件可编程阶段"><a href="#1-1-3-软件可编程阶段" class="headerlink" title="1.1.3 软件可编程阶段"></a>1.1.3 软件可编程阶段</h4><p>2006年，Nvidia和ATI分别推出了CUDA（Compute United Device Architecture)和CTM（Close To Metal)编程环境，使得GPU打破图形语言的局限成为真正的额并行数据处理超级加速器。</p>
<p>2008年，苹果提出通用的并行计算编程平台OpenCL,与具体平台无关，迅速成为移动端GPU的编程环境业界标准。<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061544076.webp" alt="Nvidia软件生态.png" title="Nvidia软件生态.png"></p>
<h3 id="1-2-GPU工作原理"><a href="#1-2-GPU工作原理" class="headerlink" title="1.2 GPU工作原理"></a>1.2 GPU工作原理</h3><h4 id="1-2-1基本概念解释"><a href="#1-2-1基本概念解释" class="headerlink" title="1.2.1基本概念解释"></a>1.2.1基本概念解释</h4><p>GPU的设计目标是最大化吞吐量（Throughout）和并行度（Parallelism）。而CPU更关心延迟（Latency）和并发（concurrency）。于是GPU采用了SIMT架构，单核CPU通常采用SIMD架构，多核CPU则通常采用MIMD架构。</p>
<p>CPU旨在以尽可能快的速度执行线程，并且可以并行执行几十个这些线程。而GPU试图通过并行执行数千个线程从而分摊时延以实现更高的吞吐量。 GPU专门用于高度并行计算，因此设计时更多的晶体管用于数据处理而不是数据缓存和流程控制。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202404101935078.svg" alt="CPU 与 GPU" title="CPU 与 GPU">​</p>
<p>​<strong>吞吐量：</strong> 单位时间内能够完成的操作。</p>
<p><strong>延迟：</strong> 完成单项任务所消耗的时间。</p>
<p><strong>并行：</strong> 同时处理多个任务，任务之间存在干扰。</p>
<p><strong>并发：</strong> 一段时间内处理多个任务，任务之间可能互相干扰。</p>
<p><strong>SIMD：</strong> SIMD(单指令多数据流)是从SISD（单指令单数据流）发展出来的。想要执行并行需要通过堆叠多个核心从而实现并行，每个核心执行一个线程，即MIMD（多指令多数据流）。而SIMD的想法是通过给每个核心中增加计算单元和寄存器，减少硬件开销。然后增加指令的操作数个数，使得一条指令可以驱动多个计算元件同时执行多个数据运算。</p>
<p><strong>SIMT：</strong> SIMD看起来很好，但是对于高级语言的支持并不好。SIMT（单指令多线程）从本质上还是一套控制单元带多个计算单元，但是从一条指令控制多个计算单元和寄存器，变为将一条指令分发给多组计算单元和寄存器，从而优化高级语言的支持。</p>
<h4 id="1-2-2-缓存机制"><a href="#1-2-2-缓存机制" class="headerlink" title="1.2.2 缓存机制"></a>1.2.2 缓存机制</h4><p>CPU中的缓存是为了存储下一步要计算的数据，从而减少访问数据的时延，提高线程的执行速度，从而实现高并发。而在GPU中缓存是为Thread提供服务的，缓存会合并线程相同的数据访问，让后从DRAM中访问数据，分发给线程。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061544897.svg" alt="A100 内存示意图" title="A100 内存示意图">​</p>
<p>​<strong>SM(Streaming Multiprocessor)</strong>  ：SM是是GPU的主要计算单元，负责执行并行计算任务。每个SM都包含多个流多处理器（CUDA核心），可以同时执行多个线程块中的指令。SM通过分配线程、调度指令和管理内存等操作，实现高效的并行计算。</p>
<p><strong>HBM：</strong> 高带宽内存，也就是显存。它通过将内存芯片直接堆叠在逻辑芯片上，提供了极高的带宽和更低的能耗，从而实现了高密度和高带宽的数据传输。</p>
<p><strong>L1 Cache/SMEM</strong>：L1 Cache包含指令缓存(Instruction Cache)和数据缓存（Data Cache），在SM内部存储最常用的指令和数据，每个SM独享一个L1 Cache，提供低延迟和高带宽的访问。</p>
<p><strong>Register File</strong>: 用于存储临时数据、计算中间结果和变量。离计算单元最近，访问速度非常快。</p>
<p><strong>带宽（BandWidth）：</strong> 单位时间内传输的数据量，主要有内存频率（Memory Data Rate）以及位宽（Memory Interface）决定的。例如A100的位宽是5210bit，频率是1215MHz,所以带宽为$\frac{(\frac{5210}{8}\times1215\times10^6\times2)}{10^{9}}=1555GB/s$,乘2是因为DDR技术每个时钟周期传输两次数据，计算存储和传输时进制是$10^3$。</p>
<p><strong>计算强度：</strong> 计算时间/内存读取时间。存储带宽越小计算强度应该越高，从而提高效率。</p>
<h4 id="1-2-3-线程机制："><a href="#1-2-3-线程机制：" class="headerlink" title="1.2.3 线程机制："></a>1.2.3 线程机制：</h4><p><strong>Warp：</strong>  线程束。逻辑上，所有Thread是并行；但是，从硬件的角度来说，并不是所有的 Thread能够在同一时刻执行，这里就需要Warp的引入。</p>
<p>Warp 是 SM 基本执行单元，一个 Warp 包含32个并行 Thread，这32个 Thread 执行于 SIMT模式。也就是说所有 Thread 以锁步的方式执行同一条指令，但每个 Thread 会使用各自的 Data 执行指令分支。如果在 Warp 中没有32个 Thread 需要工作，那么 Warp 虽然还是作为一个整体运行，但这部分 Thread 是处于非激活状态的</p>
<h2 id="2-Nvidia-GPU-介绍"><a href="#2-Nvidia-GPU-介绍" class="headerlink" title="2 Nvidia GPU 介绍"></a>2 Nvidia GPU 介绍</h2><h3 id="2-1-基础概念"><a href="#2-1-基础概念" class="headerlink" title="2.1 基础概念"></a>2.1 基础概念</h3><h4 id="2-1-1-CUDA线程层次结构"><a href="#2-1-1-CUDA线程层次结构" class="headerlink" title="2.1.1 CUDA线程层次结构"></a>2.1.1 CUDA线程层次结构</h4><p>在A100的线程层次中由三层构成，grid（网格）、block（线程块）、thread（线程）。但是在H100中有引入了新的一层Cluster（簇）这里暂且不管。</p>
<p>这里姑且将在GPU上的任务称为kernel，一个kernel所调用的所有线程组成了grid。网格又可以拆分成拥有相同线程数的block。</p>
<p><strong>Grid：</strong> 同一个网格上的线程共享相同的全局内存空间。grid是线程结构的第一层次。对应于GPU设备device。</p>
<p><strong>Block：</strong> Block 间并行执行，并且无法通信，==没有执行顺序==，每个 block 包含共享内存（Shared Memory），可以里面的 Thread 共享。对应由于SM，A100中一个block包含2048个thread。</p>
<p><strong>Thread：</strong> 同一个 block 中 thread 可以同步，也可以通过 Shared memory 通信,对应于cuda core。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061544578.png" alt="Grid-Block-Thread" title="Grid-Block-Thread"></p>
<h4 id="2-1-2-CUDA-内存层次结构"><a href="#2-1-2-CUDA-内存层次结构" class="headerlink" title="2.1.2 CUDA 内存层次结构"></a>2.1.2 CUDA 内存层次结构</h4><p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061544289.svg" alt="CUDA 内存层次" title="CUDA 内存层次"></p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061544343.svg" alt="存储结构示意" title="存储结构示意"></p>
<p><strong>寄存器(Register)：</strong> 寄存器对于每个线程来说都是私有的，一个核函数通常使用寄存器来保存需要频繁访问的线程私有变量。寄存器变量与核函数的生命周期相同。一旦核函数执行完毕，就不能对寄存器变量进行访问了。</p>
<p><strong>局部内存(Local Memory)：</strong> 局部内存是私有的，只有本线程才能进行读写访问。主要存储超出寄存器存储上线的数据，以及编译器无法静态确定的数据，局部内存在HBM上。</p>
<p><strong>共享内存(Shared Memory)：</strong> 一个块可以被同一block中的所有线程访问的可读写存储器。访问共享存储器的速度几乎和访问寄存器一样快。是实现线程间通信的延迟最小的方法。</p>
<p><strong>常量内存(Constant Memory)：</strong> 常量内存（const memory）是只读全局内存，在HBM中，但是其中的数据可以缓存在SM内部的常量缓存中（const cache）只。</p>
<p><strong>纹理内存(Texture Memory)：</strong> 纹理内存类似于常量缓存，也是一种具有缓存的只读全局内存，与常量内存具有相同的生命周期和作用范围。纹理内存通常比常量内存要大，适合实现图像处理和查找表等操作。</p>
<p><strong>全局内存(Global Memory)：</strong> 全局内存由于存放在HBM上，是GPU中容量最大、延迟最高的内存，主要作用是给核函数提供数据。GPU内核的所有线程都能对全局内存进行访问，但是访存的开销很大。</p>
<h4 id="2-1-4-计算性能"><a href="#2-1-4-计算性能" class="headerlink" title="2.1.4 计算性能"></a>2.1.4 计算性能</h4><script type="math/tex; mode=display">
𝑃𝑒𝑎𝑘 \ 𝐹𝐿𝑂𝑃𝑆=𝐹_{𝑐𝑙𝑘}∗𝑁_{𝑆𝑀}∗𝐹_{𝑟𝑒𝑞}</script><p>$F_{clk}$：为 GPU 时钟周期内指令执行数 (FLOPS/Cycle)。</p>
<p>$N_{SM}$：为 GPU SM 数量 (Cores)。</p>
<p>$F_{req}$：为运行频率 (GHz)。</p>
<h3 id="2-2-Nvidia架构"><a href="#2-2-Nvidia架构" class="headerlink" title="2.2 Nvidia架构"></a>2.2 Nvidia架构</h3><p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061544095.svg" alt="图片1">​</p>
<p>注意同同一架构不同型号的GPU存在差异。</p>
<h4 id="2-2-1-Fermi-费米架构"><a href="#2-2-1-Fermi-费米架构" class="headerlink" title="2.2.1 Fermi 费米架构"></a>2.2.1 Fermi 费米架构</h4><p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061544844.png" alt="Fermi 架构" title="Fermi 架构">​</p>
<p>首先从总体角度进行分析：GPU通过HostInterface，接收来自主机的指令与数据。使用一个Giga Thread Engine来管理所有正在进行的工作。GPU被划分成多个Graphics Processing Cluster（图形处理簇），每个GPC拥有多个SM和一个Raster Engine(光栅化引擎)。它们其中有很多的连接，最显著的是Crossbar，它可以实现GPC之间的通信并来连接其它功能性模块（例如ROP或其他子系统）。</p>
<p>Raster Engine：主要负责将图形管线中的矢量图形数据（如顶点）转换为像素信息（光栅图像）的部分。</p>
<p>ROP（Raster Operations Pipeline）：光栅操作单元，负责将光栅化引擎生成的像素数据进行最终处理，并将处理后的像素输出到帧缓冲区中，最终生成可在显示设备上显示的图像。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061545043.png" alt="Fermi SM" title="Fermi SM"></p>
<p>‍</p>
<p>32 个 CUDA Core（分在两条 lane 上，每条分别是 16 个）, 每个 CUDA Core 里面是 1 个单精浮点单元（FPU）和 1 个整数单元（ALU）。</p>
<ol>
<li>SM：从 G80 提出的概念，中文称流式多处理器，核心组件包括CUDA核心、共享内存、寄存器等。SM包含许多为线程执行数学运算的Core，是 NVIDA 的核心。</li>
<li><p>CUDA Core：向量运行单元</p>
<ul>
<li>SP（Streaming processor）：流式处理器最基本的处理单元，Fermi 架构后，SP被改称为CUDA Core，最后线程具体的指令和任务都是在SP上处理的。GPU进行并行计算，也就是很多个SP同时做处理。一个SP对应一个线程。</li>
<li>FP32-FPU：单精度浮点数运算单元</li>
<li>FP64-DPU：双精度浮点数运算单元</li>
<li>INT32-ALU：整数运算单元</li>
</ul>
</li>
<li>Special Function Units：特殊函数单元 SFU，计算超越函数和数学函数，例如余弦函数，但是存在精度损失。</li>
<li>Warp Scheduler：线程束调度器，用于将一批批的Warp发送给特定的计算核心SP执行计算。一个Warp由32个线程组成。</li>
<li>Dispatch Unit：指令分发单元，Dispatch Units负责将Warp Scheduler的指令送往Core执行（也就是上面的SP）。</li>
<li>Load/Store：加载/存储模块。辅助一个Warp（线程组）从Share Memory或显存加载(Load)或存储(Store)数据。这个单元处理操作都是异步的，也就是说其他单元在高速处理指令的时候，如果需要加载或者写回数据，则不会在这里等待LD/ST返回数据，而是跳转执行其他指令，待LD/ST把数据取到或者写回之后，再继续执行需要这些数据的后续指令。</li>
<li>Tex Unit：纹理(texture)读取单元,texture指通常理解的1D/2D/3D结构数据，相邻数据之间存在一定关系，或者相邻数据之间需要进行相同的运算。在一个运算周期最多可取4个采样器，这时刚好喂给一个线程束，每个Texture Uint有16K的Texture Cache，并且在往下有L2 Cache的支持。</li>
<li><p>PolyMorph Engine： 负责属性装配（attribute Setup）、顶点拉取（Vertex Fetch）、曲面细分、栅格化（这个模块可以理解专门处理顶点相关的东西）</p>
<ul>
<li>Vertex Fetch模块：顶点处理前期的通过三角形索引取出三角形数据。</li>
<li>Tesselator模块：对应着DX11引入的新特性曲面细分。</li>
<li>Stream Output模块：对应着DX10引入的新特性Stream Output。</li>
<li>Viewport Transform模块：对应着顶点的视口变换，三角形会被裁剪准备栅格化。</li>
<li>Attribute Setup模块：负责顶点的插值运算并输出给后续像素处理阶段使用。</li>
</ul>
</li>
<li>Instruction Cache：指令缓存。存放将要执行的指令，通过Dispatch Units填装到每个运算核心（Core）进行运算。</li>
<li>Uniform Cache：用于提高对uniform变量访问的效率。Uniform变量是在着色器程序中使用的常量，它们对于一个渲染调用中的所有顶点或片元是相同的。这些变量包括但不限于矩阵（用于变换或投影）、光照参数、或者其他在着色器执行期间不会改变的全局状态信息。后续演化为constant cache。</li>
<li>Interconnect Network：是一个关键组件，它负责处理GPU内部各个部分之间的数据传输和通信。这个网络使得多个处理核心（CUDA核心）、内存控制器、缓存系统等可以高效地交换数据，从而提高整体的处理速度和效率。</li>
</ol>
<h4 id="2-2-2-Kepler-开普勒架构"><a href="#2-2-2-Kepler-开普勒架构" class="headerlink" title="2.2.2 Kepler 开普勒架构"></a>2.2.2 Kepler 开普勒架构</h4><p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061545878.png" alt="Kepler架构" title="Kepler架构"><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061545686.png" alt="Kepler SMX" title="Kepler SMX"></p>
<p>相较于Fermi架构的变化不大。</p>
<ul>
<li>SM改名成了SMX，但是所代表的概念没有大变化；</li>
<li>单个SMX的Cuda Core数量从32个增加到了192个（$4\times3\times16$），很奇怪的数字。</li>
<li>Kepler架构在硬件上直接有双精运算单元的架构；</li>
<li>提出 GPU Direct 技术，可以绕过 CPU/System Memory，完成与本机其他 GPU 或者其他机器 GPU 的直接数据交换。</li>
</ul>
<h4 id="2-2-3-Maxwell-麦克斯韦架构"><a href="#2-2-3-Maxwell-麦克斯韦架构" class="headerlink" title="2.2.3 Maxwell 麦克斯韦架构"></a>2.2.3 Maxwell 麦克斯韦架构</h4><p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061549614.jpg" alt="Maxwell  电路示意图" title="Maxwell 电路示意图"></p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061549757.png" alt="Maxwell架构" title="Maxwell架构"></p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061545780.png" alt="Maxwll SMM示意图" title="Maxwll SMM示意图"></p>
<p>Kepler架构的SMX过于庞杂，因此Maxwwll 的SMM砍掉了很多元件，将类似于Fermi架构的四个SM（Process Block）拼成了一个SMM。</p>
<h4 id="2-2-4-Pascal-帕斯卡架构"><a href="#2-2-4-Pascal-帕斯卡架构" class="headerlink" title="2.2.4 Pascal 帕斯卡架构"></a>2.2.4 Pascal 帕斯卡架构</h4><p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061550820.png" alt="Pascal架构" title="Pascal架构"><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061545005.png" alt="Pascal SM" title="Pascal SM">​</p>
<ul>
<li>单个SM只有64个FP32 CUDA Cores，相比Maxwell的128和Kepler的192，这个数量要少很多，并且64个CUDA Cores分为了两个区块；</li>
<li>Register File 保持相同大小，每个线程可以使用更多寄存器，单个SM也可以并发更多 thread/warp/block；</li>
<li>增加 32个FP64 CUDA Cores (DP Unit)，FP32 CUDA Core 具备处理FP16的能力。</li>
<li>出现了TPC层次</li>
<li>引入了NVLink</li>
</ul>
<h4 id="2-2-5-Volta-伏特架构"><a href="#2-2-5-Volta-伏特架构" class="headerlink" title="2.2.5 Volta 伏特架构"></a>2.2.5 Volta 伏特架构</h4><p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061545087.png" alt="Volta 架构" title="Volta 架构"><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061545020.png" alt="Volta SM" title="Volta SM"></p>
<p>最显著的变化就是cuda core被拆分，整形计算单元和FP32计算单元独立出现在流水线中。可以在一个时钟周期内同时执行整形计算和单精度浮点数运算。同时相对于Pascal每个区块又被一分为二。不难看出在减小每个区块以及每个SM运算单元的数量，同时增加SM的数量。</p>
<p>最重要的是引入了张量核心(Tensor Core)。</p>
<h4 id="2-2-6-Turing-图灵架构"><a href="#2-2-6-Turing-图灵架构" class="headerlink" title="2.2.6 Turing 图灵架构"></a>2.2.6 Turing 图灵架构</h4><p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061551818.png" alt="Turing 架构" title="Turing 架构"><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061545455.png" alt="Turing SM" title="Turing SM">除了在Tensor Core中引入int 8 和int4，以及砍掉FP64单元外变动不大，主要集中在渲染管线和新加的这个 RT Core 光线追踪能力上。</p>
<h4 id="2-2-7-Ampere-安培架构"><a href="#2-2-7-Ampere-安培架构" class="headerlink" title="2.2.7 Ampere 安培架构"></a>2.2.7 Ampere 安培架构</h4><p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061552794.png" alt="Ampere 架构图" title="Ampere 架构图"></p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061552558.png" alt="Ampere SM结构" title="Ampere SM结构"></p>
<p>增加了FP64单元，Tensor Core变为原来的一半，但是计算能力其实增强了，单个时钟周期吞吐量量提高了，同时引入了结构化稀疏能力。增加了多实例GPU（Multi-Instance GPU），将单个A100GPU划分为多达七个独立GPU，为不同任务提供不同算力。</p>
<p>引入了TF32 和BF16的支持：</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061545369.png" alt="image"></p>
<h4 id="2-2-8-Hopper-赫柏架构"><a href="#2-2-8-Hopper-赫柏架构" class="headerlink" title="2.2.8 Hopper 赫柏架构"></a>2.2.8 Hopper 赫柏架构</h4><p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061545299.png" alt="Hopper 架构" title="Hopper 架构"><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061546471.png" alt="Hopper SM" title="Hopper SM"></p>
<p>​​<strong>SM 结构：</strong></p>
<ul>
<li>4 个 Warp Scheduler，4 个 Dispatch Unit（与 A100 一致）</li>
<li>128 个 FP32 Core（4 * 32）（相比 A100 翻倍）</li>
<li>64 个 INT32 Core（4 * 16）（与 A100 一致）</li>
<li>64 个 FP64 Core（4 * 16）（相比 A100 翻倍）</li>
<li>4 个 TensorCore（4 * 1）</li>
<li>32 个 LD/ST Unit（4 * 8）（与 A100 一致）</li>
<li>16 个 SFU（4 * 4）（与 A100 一致）</li>
<li>相比 A100 增加了一个 Tensor Memory Accelerator</li>
</ul>
<p><strong>Process Block：</strong></p>
<ul>
<li>1 个 Warp Scheduler，1 个 Dispatch Unit（与 A100 一致）</li>
<li>32 个 FP32 Core（相比 A100 翻倍）</li>
<li>16 个 INT32 Core（与 A100 一致）</li>
<li>16 个 FP64 Core（相比 A100 翻倍）</li>
<li>1 个 TensorCore</li>
<li>8 个 LD/ST Unit（与 A100 一致）</li>
<li>4 个 SFU（与 A100 一致）</li>
</ul>
<p>引入了线程块簇，簇是一组保证可以并发调度的线程块，支持跨多个 SM 的线程进行高效协作和数据共享。簇还可以更高效地协同驱动Tensor 内存加速器和 Tensor Core 等异步单元。在物理层次上对应的是GPC,可以直接访问同簇内其他SM的共享内存而不用经过显存中转。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061546643.png" alt="线程层次" title="线程层次"><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061553946.png" alt="">​</p>
<h3 id="2-3-TensorCore"><a href="#2-3-TensorCore" class="headerlink" title="2.3 TensorCore"></a>2.3 TensorCore</h3><p>矩阵乘法在进行行列相乘时需要逐元素的相乘累加。这个过程可以使用乘积累加指令FMA（Fused Multiply–accumulate operation）完成。</p>
<p>所谓的FMA指令就是：$a=a+(b\times c)$下图示例需要$5\times 5\times 5$次FMA 完成。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061546301.png" alt="矩阵乘法" title="矩阵乘法"></p>
<p>每个 Tensor Core 每周期能执行 $4\times4\times4$ GEMM，64 个 FMA。执行运算 D=AB+C，其中A、B、C 和 D是$4\times4$ 矩阵。矩阵乘法输入 A 和 B 是 FP16 矩阵，而累加矩阵 C 和 D 可以是 FP16或 FP32 矩阵。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061546129.png" alt="image">​</p>
<p>Tensor Core执行融合乘法加法，其中两个$4\times4$FP16矩阵相乘，然后将结果添加到$4\times4$ FP16或FP32矩阵中，最终输出新的$4\times4$ FP16或FP32矩阵。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061546753.png" alt="image">每个 Tensor Core 每个时钟执行 64 个 FP32 FMA 混合精度运算，SM中8个 Tensor Core，每个时钟周期内总共执行 512 个浮点运算。</p>
<p>因此在 AI 应用中， Volta V100 GPU的吞吐量与Pascal P100 GPU相比，每个 SM 的 AI 吞吐量增加了 8 倍，总共增加了12倍。</p>
<p><img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403061546556.gif" alt="图片2">​</p>
<h3 id="2-4-NVlink"><a href="#2-4-NVlink" class="headerlink" title="2.4 NVlink"></a>2.4 NVlink</h3><p>NVLink：英伟达（NVIDIA）开发并推出的一种总线及其通信协议。NVLink采用点对点结构、串列传输，用于中央处理器（CPU）与图形处理器（GPU）之间的连接，也可用于多个图形处理器（GPU）之间的相互连接。<br>NVSwitch：是一种高速互连技术，同时作为一块独立的 NVLink 芯片，其提供了高达18路 NVLink 的接口，可以在多个 GPU 之间实现高速数据传输。</p>
<p>NCCL / HCCL： GPU/NPU 通信优化库，支持集中式通信。</p>
<p>‍</p>
<h2 id="资料来源"><a href="#资料来源" class="headerlink" title="资料来源"></a>资料来源</h2><p>[1] <a href="https://github.com/chenzomi12/DeepLearningSystem">chenzomi12/DeepLearningSystem: Deep Learning System core principles introduction. (github.com)</a></p>
<p>[2]<a href="https://developer.download.nvidia.com/assets/gamedev/docs/TransformAndLighting.pdf">TransformAndLighting.pdf (nvidia.com)</a></p>
<p>[3] <a href="https://www.cnblogs.com/timlly/p/11471507.html">深入GPU硬件架构及运行机制 - 0向往0 - 博客园 (cnblogs.com)</a></p>
<p>[4]<a href="https://zhuanlan.zhihu.com/p/577412348">NVIDIA GPU性能优化基础 - 知乎 (zhihu.com)</a></p>
<p>[5]<a href="https://arxiv.org/pdf/1509.02308.pdf">1509.02308.pdf (arxiv.org)</a></p>
<p>[6] <a href="https://developer.nvidia.com/content/life-triangle-nvidias-logical-pipeline">Life of a triangle - NVIDIA&apos;s logical pipeline | NVIDIA Developer</a></p>
<p>[7] <a href="https://zhuanlan.zhihu.com/p/441610596">GPU架构和渲染 - 知乎 (zhihu.com)</a></p>
<p>[8]<a href="https://jcf94.com/2020/05/24/2020-05-24-nvidia-arch/">NVIDIA GPU 架构演进 | Chenfan Blog (jcf94.com)</a></p>
<p>‍</p>
]]></content>
      <categories>
        <category>并行计算</category>
        <category>Nvidia</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
        <tag>架构</tag>
        <tag>GPU</tag>
        <tag>赛博土木B</tag>
      </tags>
  </entry>
  <entry>
    <title>cublas 列优先问题</title>
    <url>/posts/f191b528.html</url>
    <content><![CDATA[<h3 id="函数功能："><a href="#函数功能：" class="headerlink" title="函数功能："></a>函数功能：</h3><script type="math/tex; mode=display">
C=\alpha AB+\beta C</script><h3 id="函数示例"><a href="#函数示例" class="headerlink" title="函数示例"></a>函数示例</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">cublasStatus_t <span class="title">cublasSgemm</span><span class="params">(cublasHandle_t handle,</span></span></span><br><span class="line"><span class="params"><span class="function">                           cublasOperation_t transa, cublasOperation_t transb,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">int</span> m, <span class="type">int</span> n, <span class="type">int</span> k,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">const</span> <span class="type">float</span> *alpha,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">const</span> <span class="type">float</span> *A, <span class="type">int</span> lda,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">const</span> <span class="type">float</span> *B, <span class="type">int</span> ldb,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">const</span> <span class="type">float</span> *beta,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">float</span> *C, <span class="type">int</span> ldc)</span></span></span><br></pre></td></tr></table></figure>
<h3 id="参数解释："><a href="#参数解释：" class="headerlink" title="参数解释："></a>参数解释：</h3><div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th style="text-align:center">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>handle</td>
<td style="text-align:center">cublas的上下文</td>
</tr>
<tr>
<td>transa</td>
<td style="text-align:center">是否对矩阵A进行转置</td>
</tr>
<tr>
<td>transb</td>
<td style="text-align:center">是否对矩阵B进行转置</td>
</tr>
<tr>
<td>m</td>
<td style="text-align:center">矩阵C、A的行</td>
</tr>
<tr>
<td>n</td>
<td style="text-align:center">矩阵C、B的列</td>
</tr>
<tr>
<td>k</td>
<td style="text-align:center">矩阵A的列，矩阵B的行</td>
</tr>
<tr>
<td>alpha</td>
<td style="text-align:center">参数 $\alpha $​</td>
</tr>
<tr>
<td>A</td>
<td style="text-align:center">矩阵A</td>
</tr>
<tr>
<td>lda</td>
<td style="text-align:center">用于存储矩阵A的二维数组的主导维度。</td>
</tr>
<tr>
<td>B</td>
<td style="text-align:center">矩阵B</td>
</tr>
<tr>
<td>ldb</td>
<td style="text-align:center">用于存储矩阵B的二维数组的主导维度。</td>
</tr>
<tr>
<td>beta</td>
<td style="text-align:center">参数 $\beta$​</td>
</tr>
<tr>
<td>C</td>
<td style="text-align:center">矩阵C</td>
</tr>
<tr>
<td>ldc</td>
<td style="text-align:center">用于存储矩阵C的二维数组的主导维度。</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>所谓的主导维度就是将一维向量映射为二维矩阵时优先填充维度的长度。cuBLAS按照列主序所以主导维度就是矩阵的行高。</p>
</blockquote>
<h3 id="踩空点"><a href="#踩空点" class="headerlink" title="踩空点"></a>踩空点</h3><p>由于最初的BLAS库使用FORTRAN语言编写的，因此它使用的是以列优先的数组存储。如下面的示例所示，在将一维向量映射为二维矩阵是列优先。</p>
<p>‍</p>
<script type="math/tex; mode=display">
\left[1,2,3,4,5,6,7,8,9\right]
=
\left[ \begin{array}{ccc}
       1 & 4 & 7 \\
        2 & 5 & 8 \\
        3 & 6 & 9 
\end{array} \right]</script><p>‍</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>我们下面的矩阵$A$举个例子.</p>
<script type="math/tex; mode=display">
\left[ \begin{array}{ccc}
     1 & 2 & 3 \\
     4 & 5 & 6 
\end{array} \right]</script><p>在存储中的表现形式如下：</p>
<script type="math/tex; mode=display">
A：[1,2,3,4,5,6]</script><p>因为是列排布优先如果不改变矩阵的行列，则矩阵A如下所示，看上去完全无法进行合理计算。</p>
<script type="math/tex; mode=display">
\left[ \begin{array}{ccc}
     1 & 3 & 5 \\
     2 & 4 & 6 
\end{array} \right]</script><p>但是如果我们颠倒一下行列，那么我们就可以获得矩阵A的转置$A^T$，同时按列存储的话在内存中的排序与矩阵A是完全一致的。</p>
<script type="math/tex; mode=display">
\left[ \begin{array}{cc}
        1 & 4  \\
        2 & 5  \\
    3 & 6  
\end{array} \right]</script><blockquote>
<p>结论：对于矩阵$A$,$A$按行存取和$A^T$的案列存取在最终结果上是一致的。</p>
</blockquote>
<p>所以我们从求矩阵$C$转变为求$C^T$</p>
<script type="math/tex; mode=display">
C^T=(AB)^T=B^T A^T</script><p>所以我们只需要颠倒一下A和B以及他们的行列就可以获得正确的结果。</p>
<p>这样只需要稍微改动一下参数，就可以获得行优先的结果：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th style="text-align:center">列优先取值</th>
<th>行优先取值</th>
</tr>
</thead>
<tbody>
<tr>
<td>handle</td>
<td style="text-align:center">cublas的上下文</td>
<td>cublas的上下文</td>
</tr>
<tr>
<td>transa</td>
<td style="text-align:center">CUBLAS_OP_N</td>
<td>CUBLAS_OP_N</td>
</tr>
<tr>
<td>transb</td>
<td style="text-align:center">CUBLAS_OP_N</td>
<td>CUBLAS_OP_N</td>
</tr>
<tr>
<td>m</td>
<td style="text-align:center">矩阵C、A的行</td>
<td>矩阵C,B的列</td>
</tr>
<tr>
<td>n</td>
<td style="text-align:center">矩阵C、B的列</td>
<td>矩阵C,A的行</td>
</tr>
<tr>
<td>k</td>
<td style="text-align:center">矩阵A的列，矩阵B的行</td>
<td>矩阵A的列，矩阵B的行</td>
</tr>
<tr>
<td>alpha</td>
<td style="text-align:center">参数 $\alpha $</td>
<td>参数 $\alpha $</td>
</tr>
<tr>
<td>A</td>
<td style="text-align:center">矩阵A</td>
<td>矩阵B</td>
</tr>
<tr>
<td>lda</td>
<td style="text-align:center">矩阵A的行</td>
<td>矩阵A的列</td>
</tr>
<tr>
<td>B</td>
<td style="text-align:center">矩阵B</td>
<td>矩阵A</td>
</tr>
<tr>
<td>ldb</td>
<td style="text-align:center">矩阵B的行</td>
<td>矩阵B的列</td>
</tr>
<tr>
<td>beta</td>
<td style="text-align:center">参数 $\beta$</td>
<td>参数 $\beta$</td>
</tr>
<tr>
<td>C</td>
<td style="text-align:center">矩阵C</td>
<td>矩阵C</td>
</tr>
<tr>
<td>ldc</td>
<td style="text-align:center">矩阵C的行</td>
<td>矩阵C的列</td>
</tr>
</tbody>
</table>
</div>
<p>‍</p>
]]></content>
      <categories>
        <category>debug</category>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
        <tag>debug</tag>
        <tag>cublas</tag>
      </tags>
  </entry>
  <entry>
    <title>Ascend 全栈 AI 软硬件平台</title>
    <url>/posts/d4440279.html</url>
    <content><![CDATA[<h2 id="1-总览"><a href="#1-总览" class="headerlink" title="1 总览"></a>1 总览</h2><p>Ascend 全栈 AI软硬件平台如图1所示。昇腾全栈 AI 软硬件平台是基于昇腾系列处理器和基础软件构建的全栈 AI 计算基础设施、行业应用及服务，平台一共分为五层，自底向上依次为 Atlas 系列硬件、异构计算架构、AI 框架、应用使能和行业应用。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202404121641067.png" alt="图1 Ascend 全栈 AI软硬件平台" title="图1 Ascend 全栈 AI软硬件平台">​</p>
<h2 id="2-Atlas-硬件平台"><a href="#2-Atlas-硬件平台" class="headerlink" title="2 Atlas 硬件平台"></a>2 Atlas 硬件平台</h2><p>Atlas 系列硬件基于昇腾系列 AI 处理器（Ascend310 用于推理场景，Ascend910 用于训练场景），通过模块、标卡、小站、服务器、集群等丰富的产品形态，打造面向 “端、边、云” 的全场景 AI 基础设施方案。<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202404121646015.svg" alt="图2 Atlas 设备" title="图2 Atlas 设备">​</p>
<p><strong>Ascend 310：</strong> 是一款高效、灵活、可编程的AI处理器。典型配置下可输出16个TOPS INT8和8个TOPS FP16，功耗仅8W。华为Ascend 310采用华为自研的达芬奇架构，集成多种计算单元，扩展了应用范围。人工智能芯片。通过全AI业务流程的加速，AI系统整体性能大幅提升，部署成本大幅降低。</p>
<ul>
<li>架构：DaVinci</li>
<li>AI Core： 2</li>
<li>计算能力：16 TOPS INT8  8 TFLOPS FP16</li>
</ul>
<p><strong>Ascend 910：</strong> 是华为基于昇腾AI处理器逻辑架构，面向AI模型训练任务打造的处理器。设计之初可以提供512 TOPS 整数精度算力，经过软件架构层面的优化可以达到640 TOPS。</p>
<ul>
<li>架构：DaVinci</li>
<li>AI Core： 32</li>
<li>计算能力：512 TOPS INT8  256 TFLOPS FP16</li>
</ul>
<p><strong>Atlas 200 AI 加速器模块（型号：3000）：</strong> 集成了 Ascend 310 人工智能处理器，可在设备端实现视频分析和图像分类。Atlas 200 广泛应用于智能相机、机器人和无人机等人工智能场景。</p>
<ul>
<li>处理器： Ascend 310</li>
<li>计算能力： 22/16/8 TOPS INT8   11/8/4 TFLOPS FP16</li>
<li>存储： LPDDR4X, 8 GB/4 GB, 带宽 51.2 GB/s</li>
</ul>
<p><strong>Atlas 200 DK AI 开发套件（型号：3000）：</strong> 是一款高性能 AI 应用开发板，集成了 Ascend 310 AI 处理器，便于快速开发和验证。它已被广泛应用于开发人员解决方案验证等场景。</p>
<ul>
<li>处理器： Ascend 310</li>
<li>计算能力： 22/16/8 TOPS INT8   11/8/4 TFLOPS FP16</li>
<li>存储： LPDDR4X, 8 GB/4 GB, 带宽 51.2 GB/s</li>
</ul>
<p><strong>Atlas 300I AI 推理卡（型号: 3000）：</strong> 采用 Ascend 310 AI 处理器，具有卓越的 AI 推理性能。单卡可提供高达 88 TOPS INT8 的计算能力，并支持 80 通道实时高清视频分析，是智慧城市、交通和金融等智能场景的理想选择。</p>
<ul>
<li>处理器： Ascend 310</li>
<li>计算能力： 88 TOPS INT8   44 TFLOPS FP16</li>
<li>存储： LPDDR4X, 32 GB, 带宽 204.8 GB/s</li>
</ul>
<p><strong>Atlas 300T AI 训练卡（型号: 9000）：</strong> 基于 Ascend 910 AI 处理器，可与服务器配合使用，为数据中心提供强大的计算能力。单卡可提供 280 TFLOPS FP16 计算能力，加速深度学习和训练。Atlas 300T 具有最高的计算能力、集成度和带宽，可满足互联网、运营商和金融行业的人工智能培训和高性能计算需求。</p>
<ul>
<li>处理器： Ascend 910</li>
<li>计算能力： 280 TFLOPS FP16 (Pro)   256 TFLOPS FP16</li>
<li>存储： 32 GB HBM   16 GB DDR4</li>
</ul>
<p><strong>Atlas 500 AI 边缘站（型号：3000）：</strong> 专为边缘应用而设计。它具有体积小巧、计算性能卓越、环境适应性强、易于维护、云边协作等特点，可广泛部署于边缘。Atlas 500 AI 边缘站可满足安防、交通、社区、校园、商场和超市等场景的复杂需求。</p>
<ul>
<li>处理器： Ascend 310</li>
<li>计算能力： 22/16 TOPS INT8   11/8 TFLOPS FP16</li>
<li>存储： LPDDR4X, 8 GB/4 GB, 带宽 51.2 GB/s</li>
</ul>
<p><strong>Atlas 500 Pro AI 边缘服务器（型号：3000）：</strong> 专为边缘应用而设计。它具有卓越的计算性能、强大的环境适应能力、易于维护和云边协作等特点。它可广泛部署在边缘，以满足安防、交通、社区、校园、商场和超市等复杂场景和环境中的应用需求。</p>
<ul>
<li>处理器： 4 * Atlas 300I AI 推理卡</li>
<li>计算能力： 352 TOPS INT8</li>
</ul>
<p><strong>Atlas 800 AI 推理服务器（型号：3000）：</strong> 采用 Ascend 310 处理器，最多可支持 8 个 Atlas 300I 推理卡，提供强大的实时推理功能。它广泛应用于数据中心的人工智能推理。</p>
<ul>
<li>处理器：8 * Atlas 300I AI 推理卡</li>
<li>计算能力： 704 TOPS INT8</li>
</ul>
<p><strong>Atlas 800 AI 训练服务器（型号：9000）：</strong> 采用鲲鹏 920 和 Ascend 910 处理器。它具有业界最高的计算密度、超高能效和高网络带宽。该服务器广泛应用于深度学习模型开发和训练场景，是智慧城市、智慧医疗、天文探测、石油勘探等计算密集型行业的理想选择。</p>
<ul>
<li>处理器： 8 * Ascend 910</li>
<li>计算能力： 2.24 PFLOPS FP16      2 PFLOPS FP16</li>
<li>存储： 8 * 32 GB  HBM</li>
</ul>
<p><strong>Atlas 900 AI PoD（型号：9000）：</strong> 基于华为 Ascend 910 和鲲鹏 920 处理器的人工智能训练集群的基本单元。它具有强大的人工智能计算能力、最佳的人工智能能效和最佳的人工智能可扩展性。该集群基本单元广泛应用于深度学习模型开发和训练场景，是智慧城市、智慧医疗、天文探测、石油勘探等计算密集型行业的理想选择。</p>
<ul>
<li>处理器： 64 * Ascend 910</li>
<li>计算能力： 20.48 PFLOPS FP16</li>
<li>存储： 2048 GB HBM</li>
</ul>
<h2 id="3-CANN-异构计算架构"><a href="#3-CANN-异构计算架构" class="headerlink" title="3 CANN 异构计算架构"></a>3 CANN 异构计算架构</h2><p>异构计算架构 CANN 在平台中起到承上启下的作用，对标英伟达的 CUDA 和 CuDNN，提供高效易用的编程接口，对上支持多种 AI 框架（MindSpore、PyTorch 等），对下服务 AI 处理器，是提升昇腾 AI 处理器计算效率的关键平台，包括各种引擎、编译器、执行器、算子库。由于其需要负责将算子分配到对应的硬件上，因此叫做异构。对CANN从不同的角度观察可以形成五层逻辑结构或者三层逻辑结构。</p>
<h3 id="3-1-五层逻辑结构"><a href="#3-1-五层逻辑结构" class="headerlink" title="3.1 五层逻辑结构"></a>3.1 五层逻辑结构</h3><p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202404231015525.svg" alt="图3 CANN 五层逻辑结构" title="图3 CANN 五层逻辑结构">​</p>
<p><strong>昇腾计算语言：</strong> 昇腾计算语言是昇腾计算开放编程框架，是对低层昇腾计算服务接口的封装。它提供 Device（设备）管理、Context（上下文）管理、Stream（流）管理、内存管理、模型加载与执行、算子加载与执行、媒体数据处理、Graph（图）管理等 API 库，供用户开发人工智能应用调用。</p>
<p><strong>昇腾计算服务层：</strong> 本层主要提供昇腾计算库，例如神经网络（Neural Network，NN）库、线性代数计算库（Basic Linear Algebra Subprograms，BLAS）等；昇腾计算调优引擎库，例如算子调优、子图调优、梯度调优、模型压缩以及 AI 框架适配器。</p>
<p><strong>昇腾计算编译层：</strong> 本层主要提供图编译器（Graph Compiler）和 TBE（Tensor Boost Engine）算子开发支持。前者将用户输入中间表达（Intermediate Representation，IR）的计算图编译成 NPU 运行的模型。后者提供用户开发自定义算子所需的工具。</p>
<p><strong>昇腾计算执行层：</strong> 本层负责模型和算子的执行，提供如运行时（Runtime）库（执行内存分配、模型管理、数据收发等）、图执行器（Graph Executor）、数字视觉预处理（Digital Vision Pre-Processing，DVPP）、人工智能预处理（Artificial Intelligence Pre-Processing，AIPP）、华为集合通信库（Huawei Collective Communication Library，HCCL）等功能单元。</p>
<p><strong>昇腾计算基础层：</strong> 本层主要为其上各层提供基础服务，如共享虚拟内存（Shared Virtual Memory，SVM）、设备虚拟化（Virtual Machine，VM）、主机 - 设备通信（Host Device Communication，HDC）等。</p>
<h3 id="3-2-三层逻辑结构"><a href="#3-2-三层逻辑结构" class="headerlink" title="3.2 三层逻辑结构"></a>3.2 三层逻辑结构</h3><p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202404131903285.svg" alt="图4 CANN 三层逻辑架构" title="图4 CANN 三层逻辑架构">​</p>
<h4 id="3-2-1-应用层"><a href="#3-2-1-应用层" class="headerlink" title="3.2.1 应用层"></a>3.2.1 应用层</h4><p>包括基于 Ascend 平台开发的各种应用，以及 Ascend 提供给用户进行算法开发、调优的应用类工具。</p>
<p><strong>推理应用：</strong> 基于 AscendCL 提供的 API 构建推理应用</p>
<p><strong>AI 框架：</strong> 包括 TensorFlow、Caffe、MindSpore 以及第三方框架</p>
<p><strong>模型小型化工具：</strong> 实现对模型进行量化，加速模型</p>
<p><strong>AutoML 工具：</strong> 基于 MindSpore 自动学习工具，根据昇腾芯片特点进行搜索生成亲和性网络，充分发挥昇腾性能</p>
<p><strong>加速库：</strong> 基于 AscendCL 构建的加速库（当前支持 Blas 加速库）</p>
<p><strong>MindStudio：</strong> 提供给开发者的集成开发环境和调试工具，可以通过MindStudio进行离线模型转换、离线推理算法应用开发调试、算法调试、自定义算子开发和调试、日志查看、性能调优、系统故障查看等</p>
<h4 id="3-2-2-芯片使能层"><a href="#3-2-2-芯片使能层" class="headerlink" title="3.2.2 芯片使能层"></a>3.2.2 芯片使能层</h4><p>实现解决方案对外能力开放，以及基于计算图的业务流的控制和运行。</p>
<p><strong>AscendCL 昇腾计算语言库：</strong> 开放编程框架，提供 Device/Context/Stream/ 内存等的管理、模型及算子的加载与执行、媒体数据处理、Graph 管理等 API 库，供用户开发深度神经网络应用。</p>
<p><strong>图优化和编译：</strong> 统一的 IR 接口对接不同前端，支持 TensorFlow/Caffe/MindSpore 表达的计算图的解析/优化/编译，提供对后端计算引擎最优化部署能力</p>
<ul>
<li>Graph Engine：图编译和运行的控制中心</li>
<li>Fusion Engine：管理算子融合规则</li>
<li>AICPU Engine：AICPU 算子信息管理</li>
<li>HCCL：HCCL 算子信息管理</li>
</ul>
<p><strong>算子编译和算子库：</strong></p>
<ul>
<li>TBE：编译生成算子及算子开发工具</li>
<li>算子库：神经网络加速库</li>
</ul>
<p><strong>数字视觉预处理：</strong> 实现视频编解码（VENC/VDEC）、JPEG 编解码（JPEG/E）、PNG 解码（PNGD）、VPC（预处理）</p>
<p><strong>执行引擎：</strong></p>
<ul>
<li>Runtime：为神经网络的任务分配提供资源管理通道</li>
<li>Task Scheduler：计算图 Task 序列的管理和调度、执行</li>
</ul>
<h4 id="3-2-3-计算资源层"><a href="#3-2-3-计算资源层" class="headerlink" title="3.2.3 计算资源层"></a>3.2.3 计算资源层</h4><p>主要实现系统对数据的处理和对数据的运算执行。</p>
<p><strong>计算设备：</strong></p>
<ul>
<li>AI Core：执行 NN 类算子</li>
<li>AI CPU：执行 CPU 算子</li>
<li>DVPP：视频/图像编解码、预处理</li>
</ul>
<p><strong>通信链路：</strong></p>
<ul>
<li>PCIe：芯片间或芯片与 CPU 间高速互联</li>
<li>HCCS：实现芯片间缓存一致性功能</li>
<li>RoCE：实现芯片内存 RDMA 功能</li>
</ul>
<p>‍</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1]CANN-昇腾社区[EB/OL]. [2024-04-12]. <a href="https://www.hiascend.com/zh/software/cann">https://www.hiascend.com/zh/software/cann</a>.</p>
<p>[2]Ascend-昇腾社区[EB/OL]. [2024-04-12]. <a href="https://www.hiascend.com/">https://www.hiascend.com/</a>.</p>
<p>[3]昇腾Ascend 随记 —— 昇腾 AI 的基本架构 - 掘金[EB/OL]. [2024-04-12]. <a href="https://juejin.cn/post/7231013251836002364">https://juejin.cn/post/7231013251836002364</a>.</p>
<p>‍</p>
]]></content>
      <categories>
        <category>并行计算</category>
        <category>Ascend</category>
      </categories>
      <tags>
        <tag>Ascend</tag>
        <tag>NPU</tag>
      </tags>
  </entry>
  <entry>
    <title>Hugo+Github搭建个人主页</title>
    <url>/posts/a260d87d.html</url>
    <content><![CDATA[<h2 id="1-准备阶段"><a href="#1-准备阶段" class="headerlink" title="1 准备阶段"></a>1 准备阶段</h2><h3 id="1-1-安装hugo"><a href="#1-1-安装hugo" class="headerlink" title="1.1 安装hugo"></a>1.1 安装hugo</h3><p>这里为了省去环境路径的配置采用如下的cmd命令方式，也可以选择去github下载相应文件。如文档：<a href="https://www.gohugo.org/">Hugo中文文档 (gohugo.org)</a></p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">winget install Hugo.Hugo.Extended</span><br></pre></td></tr></table></figure>
<h3 id="1-2-安装git"><a href="#1-2-安装git" class="headerlink" title="1.2 安装git"></a>1.2 安装git</h3><p><a href="https://git-scm.com/downloads">Git - Downloads (git-scm.com)</a></p>
<p>选择合适的版本一直下一步即可。</p>
<p>在使用git前需要设置一下用户名和邮箱。</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">git config --<span class="keyword">global</span> user.name <span class="string">&quot;username&quot;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight typescript"><table><tr><td class="code"><pre><span class="line">git config --<span class="variable language_">global</span> user.<span class="property">email</span> useremail<span class="meta">@qq</span>.<span class="property">com</span> </span><br></pre></td></tr></table></figure>
<h3 id="1-3-创建Github仓库"><a href="#1-3-创建Github仓库" class="headerlink" title="1.3 创建Github仓库"></a>1.3 创建Github仓库</h3><p>需要创建两个仓库一个公开仓库名字是username.github.io，名字必须是这个格式。另外创建一个私有仓库，是为了方便管理源代码。</p>
<h2 id="2-创建-site"><a href="#2-创建-site" class="headerlink" title="2 创建 site"></a>2 创建 site</h2><p>参考：<a href="https://gohugo.io/getting-started/quick-start/">Quick start | Hugo (gohugo.io)</a></p>
<p>创建一个site</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">hugo new site WebSite</span><br></pre></td></tr></table></figure>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">cd WebSite</span><br></pre></td></tr></table></figure>
<p>初始化git仓库</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">git init</span><br><span class="line">git add .</span><br><span class="line">git commit <span class="literal">-m</span> <span class="string">&quot;first commit&quot;</span></span><br><span class="line">git branch <span class="literal">-M</span> main</span><br><span class="line">git remote add origin https://github.com/CATSLAB<span class="literal">-SDU</span>/WebSite.git</span><br><span class="line">git push <span class="literal">-u</span> origin main</span><br></pre></td></tr></table></figure>
<p>模板设置，可以更换自己喜欢的模板<a href="https://themes.gohugo.io/">Complete List | Hugo Themes (gohugo.io)</a></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/dillonzq/LoveIt.git themes/LoveIt</span><br></pre></td></tr></table></figure>
<p>修改hugo.toml文件，建议使用vscode</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">baseURL = <span class="string">&quot;https://CATSLAB-SDU.github.io/&quot;</span></span><br><span class="line"># 更改使用 Hugo 构建网站时使用的默认主题</span><br><span class="line">theme = <span class="string">&quot;LoveIt&quot;</span></span><br><span class="line"></span><br><span class="line">uglyURLs=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"># 网站语言, 仅在这里 CN 大写 [<span class="string">&quot;en&quot;</span>, <span class="string">&quot;zh-CN&quot;</span>, <span class="string">&quot;fr&quot;</span>, <span class="string">&quot;pl&quot;</span>, ...]</span><br><span class="line">languageCode = <span class="string">&quot;zh-CN&quot;</span></span><br><span class="line"># 语言名称 [<span class="string">&quot;English&quot;</span>, <span class="string">&quot;简体中文&quot;</span>, <span class="string">&quot;Français&quot;</span>, <span class="string">&quot;Polski&quot;</span>, ...]</span><br><span class="line">languageName = <span class="string">&quot;简体中文&quot;</span></span><br><span class="line"># 是否包括中日韩文字</span><br><span class="line">hasCJKLanguage = <span class="literal">true</span></span><br><span class="line"># 默认每页列表显示的文章数目</span><br><span class="line">paginate = <span class="number">12</span></span><br><span class="line"># 谷歌分析代号 [UA-XXXXXXXX-X]</span><br><span class="line"></span><br><span class="line"># 版权描述，仅仅用于 SEO</span><br><span class="line">copyright = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"># 是否使用 robots.txt</span><br><span class="line">enableRobotsTXT = <span class="literal">true</span></span><br><span class="line"># 是否使用 git 信息</span><br><span class="line">enableGitInfo = <span class="literal">true</span></span><br><span class="line"># 是否使用 emoji 代码</span><br><span class="line">enableEmoji = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"># 忽略一些构建错误</span><br><span class="line">ignoreErrors = [<span class="string">&quot;error-remote-getjson&quot;</span>, <span class="string">&quot;error-missing-instagram-accesstoken&quot;</span>]</span><br><span class="line"></span><br><span class="line"># 作者配置</span><br><span class="line">[author]</span><br><span class="line">  name = <span class="string">&quot;CATS LAB&quot;</span></span><br><span class="line">  email = <span class="string">&quot;&quot;</span></span><br><span class="line">  link = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"># 菜单配置</span><br><span class="line">[menu]</span><br><span class="line">  [[menu.main]]</span><br><span class="line">    weight = <span class="number">1</span></span><br><span class="line">    identifier = <span class="string">&quot;笔记&quot;</span></span><br><span class="line">    # 你可以在名称 (允许 HTML 格式) 之前添加其他信息, 例如图标</span><br><span class="line">    pre = <span class="string">&quot;&quot;</span></span><br><span class="line">    # 你可以在名称 (允许 HTML 格式) 之后添加其他信息, 例如图标</span><br><span class="line">    post = <span class="string">&quot;&quot;</span></span><br><span class="line">    name = <span class="string">&quot;笔记&quot;</span></span><br><span class="line">    url = <span class="string">&quot;/posts/&quot;</span></span><br><span class="line">    # 当你将鼠标悬停在此菜单链接上时, 将显示的标题</span><br><span class="line">    title = <span class="string">&quot;&quot;</span></span><br><span class="line">  [[menu.main]]</span><br><span class="line">    weight = <span class="number">2</span></span><br><span class="line">    identifier = <span class="string">&quot;标签&quot;</span></span><br><span class="line">    pre = <span class="string">&quot;&quot;</span></span><br><span class="line">    post = <span class="string">&quot;&quot;</span></span><br><span class="line">    name = <span class="string">&quot;标签&quot;</span></span><br><span class="line">    url = <span class="string">&quot;/tags/&quot;</span></span><br><span class="line">    title = <span class="string">&quot;&quot;</span></span><br><span class="line">  [[menu.main]]</span><br><span class="line">    weight = <span class="number">3</span></span><br><span class="line">    identifier = <span class="string">&quot;分类&quot;</span></span><br><span class="line">    pre = <span class="string">&quot;&quot;</span></span><br><span class="line">    post = <span class="string">&quot;&quot;</span></span><br><span class="line">    name = <span class="string">&quot;分类&quot;</span></span><br><span class="line">    url = <span class="string">&quot;/categories/&quot;</span></span><br><span class="line">    title = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">[params]</span><br><span class="line">  # 网站默认主题样式 [<span class="string">&quot;auto&quot;</span>, <span class="string">&quot;light&quot;</span>, <span class="string">&quot;dark&quot;</span>]</span><br><span class="line">  defaultTheme = <span class="string">&quot;light&quot;</span></span><br><span class="line">  # 公共 git 仓库路径，仅在 enableGitInfo 设为 <span class="literal">true</span> 时有效</span><br><span class="line">  gitRepo = <span class="string">&quot;&quot;</span></span><br><span class="line">  #  哪种哈希函数用来 SRI, 为空时表示不使用 SRI</span><br><span class="line">  # [<span class="string">&quot;sha256&quot;</span>, <span class="string">&quot;sha384&quot;</span>, <span class="string">&quot;sha512&quot;</span>, <span class="string">&quot;md5&quot;</span>]</span><br><span class="line">  fingerprint = <span class="string">&quot;sha256&quot;</span></span><br><span class="line">  #  日期格式</span><br><span class="line">  dateFormat = <span class="string">&quot;2006-01-02&quot;</span></span><br><span class="line">  # 网站标题, 用于 Open Graph 和 Twitter Cards</span><br><span class="line">  title = <span class="string">&quot;CATS LAB&quot;</span></span><br><span class="line">  # 网站描述, 用于 RSS, SEO, Open Graph 和 Twitter Cards</span><br><span class="line">  description= <span class="string">&quot;实验室学习资料共享博客&quot;</span></span><br><span class="line">  # 网站图片, 用于 Open Graph 和 Twitter Cards</span><br><span class="line">  images = []</span><br><span class="line"></span><br><span class="line">  # 页面头部导航栏配置</span><br><span class="line">  [params.header]</span><br><span class="line">    # 桌面端导航栏模式 [<span class="string">&quot;fixed&quot;</span>, <span class="string">&quot;normal&quot;</span>, <span class="string">&quot;auto&quot;</span>]</span><br><span class="line">    desktopMode = <span class="string">&quot;fixed&quot;</span></span><br><span class="line">    # 移动端导航栏模式 [<span class="string">&quot;fixed&quot;</span>, <span class="string">&quot;normal&quot;</span>, <span class="string">&quot;auto&quot;</span>]</span><br><span class="line">    mobileMode = <span class="string">&quot;auto&quot;</span></span><br><span class="line">    #  页面头部导航栏标题配置</span><br><span class="line">    [params.header.title]</span><br><span class="line">      # LOGO 的 URL</span><br><span class="line">      logo = <span class="string">&quot;/favicon.ico&quot;</span></span><br><span class="line">      # 标题名称</span><br><span class="line">      name = <span class="string">&quot;CATS LAB&quot;</span></span><br><span class="line">      # 你可以在名称 (允许 HTML 格式) 之前添加其他信息, 例如图标</span><br><span class="line">      pre = <span class="string">&quot;&quot;</span></span><br><span class="line">      # 你可以在名称 (允许 HTML 格式) 之后添加其他信息, 例如图标</span><br><span class="line">      post = <span class="string">&quot;&quot;</span></span><br><span class="line">      #  是否为标题显示打字机动画</span><br><span class="line">      typeit = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  # 页面底部信息配置</span><br><span class="line">  [params.footer]</span><br><span class="line">    enable = <span class="literal">true</span></span><br><span class="line">    #  自定义内容 (支持 HTML 格式)</span><br><span class="line">    custom = <span class="string">&#x27;&#x27; </span></span><br><span class="line"><span class="string">    #  是否显示 Hugo 和主题信息</span></span><br><span class="line"><span class="string">    hugo = true</span></span><br><span class="line"><span class="string">    #  是否显示版权信息</span></span><br><span class="line"><span class="string">    copyright = true</span></span><br><span class="line"><span class="string">    #  是否显示作者</span></span><br><span class="line"><span class="string">    author = true</span></span><br><span class="line"><span class="string">    # 网站创立年份</span></span><br><span class="line"><span class="string">    since = 2024</span></span><br><span class="line"><span class="string">    # ICP 备案信息，仅在中国使用 (支持 HTML 格式)</span></span><br><span class="line"><span class="string">    icp = &quot;&quot;</span></span><br><span class="line"><span class="string">    # 许可协议信息 (支持 HTML 格式)</span></span><br><span class="line"><span class="string">    license = &#x27;</span>&lt;a rel=<span class="string">&quot;license external nofollow noopener noreffer&quot;</span> href=<span class="string">&quot;https://creativecommons.org/licenses/by-nc/4.0/&quot;</span> target=<span class="string">&quot;_blank&quot;</span>&gt;CC BY-NC <span class="number">4.0</span>&lt;/a&gt;&#x27;</span><br><span class="line">   </span><br><span class="line">  #  <span class="built_in">Section</span> (所有文章) 页面配置</span><br><span class="line">  [params.section]</span><br><span class="line">    <span class="meta"># section 页面每页显示文章数量</span></span><br><span class="line">    paginate = <span class="number">20</span></span><br><span class="line">    # 日期格式 (月和日)</span><br><span class="line">    dateFormat = <span class="string">&quot;01-02&quot;</span></span><br><span class="line">    # RSS 文章数目</span><br><span class="line">    rss = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">  #  <span class="built_in">List</span> (目录或标签) 页面配置</span><br><span class="line">  [params.list]</span><br><span class="line">    <span class="meta"># list 页面每页显示文章数量</span></span><br><span class="line">    paginate = <span class="number">20</span></span><br><span class="line">    # 日期格式 (月和日)</span><br><span class="line">    dateFormat = <span class="string">&quot;01-02&quot;</span></span><br><span class="line">    # RSS 文章数目</span><br><span class="line">    rss = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">  #  应用图标配置</span><br><span class="line">  [params.app]</span><br><span class="line">    # 当添加到 iOS 主屏幕或者 Android 启动器时的标题, 覆盖默认标题</span><br><span class="line">    title = <span class="string">&quot;CATS LAB&quot;</span></span><br><span class="line">    # 是否隐藏网站图标资源链接</span><br><span class="line">    noFavicon = <span class="literal">true</span></span><br><span class="line">    # 更现代的 SVG 网站图标, 可替代旧的 .png 和 .ico 文件</span><br><span class="line">    svgFavicon = <span class="string">&quot;favicon-32x32.png&quot;</span></span><br><span class="line">    # Android 浏览器主题色</span><br><span class="line">    themeColor = <span class="string">&quot;#ffffff&quot;</span></span><br><span class="line">    # Safari 图标颜色</span><br><span class="line">    iconColor = <span class="string">&quot;#5bbad5&quot;</span></span><br><span class="line">    # Windows v8<span class="number">-10</span>磁贴颜色</span><br><span class="line">    tileColor = <span class="string">&quot;#da532c&quot;</span></span><br><span class="line"></span><br><span class="line">  #  搜索配置</span><br><span class="line">  [params.search]</span><br><span class="line">    enable = <span class="literal">true</span></span><br><span class="line">    # 搜索引擎的类型 [<span class="string">&quot;lunr&quot;</span>, <span class="string">&quot;algolia&quot;</span>]</span><br><span class="line">    type = <span class="string">&quot;algolia&quot;</span></span><br><span class="line">    # 文章内容最长索引长度</span><br><span class="line">    contentLength = <span class="number">4000</span></span><br><span class="line">    # 搜索框的占位提示语</span><br><span class="line">    placeholder = <span class="string">&quot;&quot;</span></span><br><span class="line">    #  最大结果数目</span><br><span class="line">    maxResultLength = <span class="number">10</span></span><br><span class="line">    #  结果内容片段长度</span><br><span class="line">    snippetLength = <span class="number">50</span></span><br><span class="line">    #  搜索结果中高亮部分的 HTML 标签</span><br><span class="line">    highlightTag = <span class="string">&quot;em&quot;</span></span><br><span class="line">    #  是否在搜索索引中使用基于 baseURL 的绝对路径</span><br><span class="line">    absoluteURL = <span class="literal">false</span></span><br><span class="line">    [params.search.algolia]</span><br><span class="line">      index = <span class="string">&quot;&quot;</span></span><br><span class="line">      appID = <span class="string">&quot;&quot;</span></span><br><span class="line">      searchKey = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  # 主页配置</span><br><span class="line">  [params.home]</span><br><span class="line">    #  RSS 文章数目</span><br><span class="line">    rss = <span class="number">10</span></span><br><span class="line">    # 主页个人信息</span><br><span class="line">    [params.home.profile]</span><br><span class="line">      enable = <span class="literal">true</span></span><br><span class="line">      # Gravatar 邮箱，用于优先在主页显示的头像</span><br><span class="line">      gravatarEmail = <span class="string">&quot;&quot;</span></span><br><span class="line">      # 主页显示头像的 URL</span><br><span class="line">      avatarURL = <span class="string">&quot;/avatar.png&quot;</span></span><br><span class="line">      #  主页显示的网站标题 (支持 HTML 格式)</span><br><span class="line">      title = <span class="string">&quot;CATS LAB&quot;</span></span><br><span class="line">      # 主页显示的网站副标题 (允许 HTML 格式)</span><br><span class="line">      subtitle = <span class="string">&quot;&quot;</span></span><br><span class="line">      # 是否为副标题显示打字机动画</span><br><span class="line">      typeit = <span class="literal">true</span></span><br><span class="line">      # 是否显示社交账号</span><br><span class="line">      social = <span class="literal">true</span></span><br><span class="line">      #  免责声明 (支持 HTML 格式)</span><br><span class="line">      disclaimer = <span class="string">&quot;内容为体系结构与隐私计算实验室学习资料分享，仅供参考，侵权请联系删除。&quot;</span></span><br><span class="line">    # 主页文章列表</span><br><span class="line">    [params.home.posts]</span><br><span class="line">      enable = <span class="literal">true</span></span><br><span class="line">      # 主页每页显示文章数量</span><br><span class="line">      paginate = <span class="number">6</span></span><br><span class="line">      #  被 params.page 中的 hiddenFromHomePage 替代</span><br><span class="line">      # 当你没有在文章前置参数中设置 <span class="string">&quot;hiddenFromHomePage&quot;</span> 时的默认行为</span><br><span class="line">      defaultHiddenFromHomePage = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  # 作者的社交信息设置</span><br><span class="line">  [params.social]</span><br><span class="line">    GitHub = <span class="string">&quot;CATSLAB-SDU&quot;</span></span><br><span class="line">    Linkedin = <span class="string">&quot;&quot;</span></span><br><span class="line">    Twitter = <span class="string">&quot;&quot;</span></span><br><span class="line">    Instagram = <span class="string">&quot;&quot;</span></span><br><span class="line">    Facebook = <span class="string">&quot;&quot;</span></span><br><span class="line">    Telegram = <span class="string">&quot;&quot;</span></span><br><span class="line">    Medium = <span class="string">&quot;&quot;</span></span><br><span class="line">    Gitlab = <span class="string">&quot;&quot;</span></span><br><span class="line">    Youtubelegacy = <span class="string">&quot;&quot;</span></span><br><span class="line">    Youtubecustom = <span class="string">&quot;&quot;</span></span><br><span class="line">    Youtubechannel = <span class="string">&quot;&quot;</span></span><br><span class="line">    Tumblr = <span class="string">&quot;&quot;</span></span><br><span class="line">    Quora = <span class="string">&quot;&quot;</span></span><br><span class="line">    Keybase = <span class="string">&quot;&quot;</span></span><br><span class="line">    Pinterest = <span class="string">&quot;&quot;</span></span><br><span class="line">    Reddit = <span class="string">&quot;&quot;</span></span><br><span class="line">    Codepen = <span class="string">&quot;&quot;</span></span><br><span class="line">    FreeCodeCamp = <span class="string">&quot;&quot;</span></span><br><span class="line">    Bitbucket = <span class="string">&quot;&quot;</span></span><br><span class="line">    Stackoverflow = <span class="string">&quot;&quot;</span></span><br><span class="line">    Weibo = <span class="string">&quot;&quot;</span></span><br><span class="line">    Odnoklassniki = <span class="string">&quot;&quot;</span></span><br><span class="line">    VK = <span class="string">&quot;&quot;</span></span><br><span class="line">    Flickr = <span class="string">&quot;&quot;</span></span><br><span class="line">    Xing = <span class="string">&quot;&quot;</span></span><br><span class="line">    Snapchat = <span class="string">&quot;&quot;</span></span><br><span class="line">    Soundcloud = <span class="string">&quot;&quot;</span></span><br><span class="line">    Spotify = <span class="string">&quot;&quot;</span></span><br><span class="line">    Bandcamp = <span class="string">&quot;&quot;</span></span><br><span class="line">    Paypal = <span class="string">&quot;&quot;</span></span><br><span class="line">    Fivehundredpx = <span class="string">&quot;&quot;</span></span><br><span class="line">    Mix = <span class="string">&quot;&quot;</span></span><br><span class="line">    Goodreads = <span class="string">&quot;&quot;</span></span><br><span class="line">    Lastfm = <span class="string">&quot;&quot;</span></span><br><span class="line">    Foursquare = <span class="string">&quot;&quot;</span></span><br><span class="line">    Hackernews = <span class="string">&quot;&quot;</span></span><br><span class="line">    Kickstarter = <span class="string">&quot;&quot;</span></span><br><span class="line">    Patreon = <span class="string">&quot;&quot;</span></span><br><span class="line">    Steam = <span class="string">&quot;&quot;</span></span><br><span class="line">    Twitch = <span class="string">&quot;&quot;</span></span><br><span class="line">    Strava = <span class="string">&quot;&quot;</span></span><br><span class="line">    Skype = <span class="string">&quot;&quot;</span></span><br><span class="line">    Whatsapp = <span class="string">&quot;&quot;</span></span><br><span class="line">    Zhihu = <span class="string">&quot;&quot;</span></span><br><span class="line">    Douban = <span class="string">&quot;&quot;</span></span><br><span class="line">    Angellist = <span class="string">&quot;&quot;</span></span><br><span class="line">    Slidershare = <span class="string">&quot;&quot;</span></span><br><span class="line">    Jsfiddle = <span class="string">&quot;&quot;</span></span><br><span class="line">    Deviantart = <span class="string">&quot;&quot;</span></span><br><span class="line">    Behance = <span class="string">&quot;&quot;</span></span><br><span class="line">    Dribbble = <span class="string">&quot;&quot;</span></span><br><span class="line">    Wordpress = <span class="string">&quot;&quot;</span></span><br><span class="line">    Vine = <span class="string">&quot;&quot;</span></span><br><span class="line">    Googlescholar = <span class="string">&quot;&quot;</span></span><br><span class="line">    Researchgate = <span class="string">&quot;&quot;</span></span><br><span class="line">    Mastodon = <span class="string">&quot;&quot;</span></span><br><span class="line">    Thingiverse = <span class="string">&quot;&quot;</span></span><br><span class="line">    Devto = <span class="string">&quot;&quot;</span></span><br><span class="line">    Gitea = <span class="string">&quot;&quot;</span></span><br><span class="line">    XMPP = <span class="string">&quot;&quot;</span></span><br><span class="line">    Matrix = <span class="string">&quot;&quot;</span></span><br><span class="line">    Bilibili = <span class="string">&quot;&quot;</span></span><br><span class="line">    Discord = <span class="string">&quot;&quot;</span></span><br><span class="line">    DiscordInvite = <span class="string">&quot;&quot;</span></span><br><span class="line">    Lichess = <span class="string">&quot;&quot;</span></span><br><span class="line">    ORCID = <span class="string">&quot;&quot;</span></span><br><span class="line">    Pleroma = <span class="string">&quot;&quot;</span></span><br><span class="line">    Kaggle = <span class="string">&quot;&quot;</span></span><br><span class="line">    MediaWiki= <span class="string">&quot;&quot;</span></span><br><span class="line">    Plume = <span class="string">&quot;&quot;</span></span><br><span class="line">    HackTheBox = <span class="string">&quot;&quot;</span></span><br><span class="line">    RootMe= <span class="string">&quot;&quot;</span></span><br><span class="line">    Phone = <span class="string">&quot;&quot;</span></span><br><span class="line">    Email = <span class="string">&quot;&quot;</span></span><br><span class="line">    RSS = <span class="literal">false</span> # </span><br><span class="line"></span><br><span class="line">  #  文章页面全局配置</span><br><span class="line">  [params.page]</span><br><span class="line">    #  是否在主页隐藏一篇文章</span><br><span class="line">    hiddenFromHomePage = <span class="literal">false</span></span><br><span class="line">    #  是否在搜索结果中隐藏一篇文章</span><br><span class="line">    hiddenFromSearch = <span class="literal">false</span></span><br><span class="line">    #  是否使用 twemoji</span><br><span class="line">    twemoji = <span class="literal">false</span></span><br><span class="line">    # 是否使用 lightgallery</span><br><span class="line">    lightgallery = <span class="literal">false</span></span><br><span class="line">    #  是否使用 ruby 扩展语法</span><br><span class="line">    ruby = <span class="literal">true</span></span><br><span class="line">    #  是否使用 fraction 扩展语法</span><br><span class="line">    fraction = <span class="literal">true</span></span><br><span class="line">    #  是否使用 fontawesome 扩展语法</span><br><span class="line">    fontawesome = <span class="literal">true</span></span><br><span class="line">    # 是否在文章页面显示原始 Markdown 文档链接</span><br><span class="line">    linkToMarkdown = <span class="literal">true</span></span><br><span class="line">    #  是否在 RSS 中显示全文内容</span><br><span class="line">    rssFullText = <span class="literal">false</span></span><br><span class="line">    #  目录配置</span><br><span class="line">    [params.page.toc]</span><br><span class="line">      # 是否使用目录</span><br><span class="line">      enable = <span class="literal">true</span></span><br><span class="line">      #  是否保持使用文章前面的静态目录</span><br><span class="line">      keepStatic = <span class="literal">false</span></span><br><span class="line">      # 是否使侧边目录自动折叠展开</span><br><span class="line">      <span class="keyword">auto</span> = <span class="literal">true</span></span><br><span class="line">    #  代码配置</span><br><span class="line">    [params.page.code]</span><br><span class="line">      # 是否显示代码块的复制按钮</span><br><span class="line">      copy = <span class="literal">true</span></span><br><span class="line">      # 默认展开显示的代码行数</span><br><span class="line">      maxShownLines = <span class="number">50</span></span><br><span class="line">    #  KaTeX 数学公式</span><br><span class="line">    [params.page.math]</span><br><span class="line">      enable = <span class="literal">true</span></span><br><span class="line">      #  默认行内定界符是 $ ... $ 和 \( ... \)</span><br><span class="line">      inlineLeftDelimiter = <span class="string">&quot;&quot;</span></span><br><span class="line">      inlineRightDelimiter = <span class="string">&quot;&quot;</span></span><br><span class="line">      #  默认块定界符是 $$ ... $$, \[ ... \],  \begin&#123;equation&#125; ... \end&#123;equation&#125; 和一些其它的函数</span><br><span class="line">      blockLeftDelimiter = <span class="string">&quot;&quot;</span></span><br><span class="line">      blockRightDelimiter = <span class="string">&quot;&quot;</span></span><br><span class="line">      # KaTeX 插件 copy_tex</span><br><span class="line">      copyTex = <span class="literal">true</span></span><br><span class="line">      # KaTeX 插件 mhchem</span><br><span class="line">      mhchem = <span class="literal">true</span></span><br><span class="line">    #  Mapbox GL JS 配置</span><br><span class="line">    [params.page.mapbox]</span><br><span class="line">      # Mapbox GL JS 的 access token</span><br><span class="line">      accessToken = <span class="string">&quot;&quot;</span></span><br><span class="line">      # 浅色主题的地图样式</span><br><span class="line">      lightStyle = <span class="string">&quot;mapbox://styles/mapbox/light-v10?optimize=true&quot;</span></span><br><span class="line">      # 深色主题的地图样式</span><br><span class="line">      darkStyle = <span class="string">&quot;mapbox://styles/mapbox/dark-v10?optimize=true&quot;</span></span><br><span class="line">      # 是否添加 NavigationControl</span><br><span class="line">      navigation = <span class="literal">true</span></span><br><span class="line">      # 是否添加 GeolocateControl</span><br><span class="line">      geolocate = <span class="literal">true</span></span><br><span class="line">      # 是否添加 ScaleControl</span><br><span class="line">      scale = <span class="literal">true</span></span><br><span class="line">      # 是否添加 FullscreenControl</span><br><span class="line">      fullscreen = <span class="literal">true</span></span><br><span class="line">    #  文章页面的分享信息设置</span><br><span class="line">    [params.page.share]</span><br><span class="line">      enable = <span class="literal">true</span></span><br><span class="line">      Twitter = <span class="literal">true</span></span><br><span class="line">      Facebook = <span class="literal">true</span></span><br><span class="line">      Linkedin = <span class="literal">false</span></span><br><span class="line">      Whatsapp = <span class="literal">false</span></span><br><span class="line">      Pinterest = <span class="literal">false</span></span><br><span class="line">      Tumblr = <span class="literal">false</span></span><br><span class="line">      HackerNews = <span class="literal">true</span></span><br><span class="line">      Reddit = <span class="literal">false</span></span><br><span class="line">      VK = <span class="literal">false</span></span><br><span class="line">      Buffer = <span class="literal">false</span></span><br><span class="line">      Xing = <span class="literal">false</span></span><br><span class="line">      Line = <span class="literal">true</span></span><br><span class="line">      Instapaper = <span class="literal">false</span></span><br><span class="line">      Pocket = <span class="literal">false</span></span><br><span class="line">      Flipboard = <span class="literal">false</span></span><br><span class="line">      Weibo = <span class="literal">true</span></span><br><span class="line">      Blogger = <span class="literal">false</span></span><br><span class="line">      Baidu = <span class="literal">false</span></span><br><span class="line">      Odnoklassniki = <span class="literal">false</span></span><br><span class="line">      Evernote = <span class="literal">false</span></span><br><span class="line">      Skype = <span class="literal">false</span></span><br><span class="line">      Trello = <span class="literal">false</span></span><br><span class="line">      Mix = <span class="literal">false</span></span><br><span class="line">    #  评论系统设置</span><br><span class="line">    [params.page.comment]</span><br><span class="line">      enable = <span class="literal">true</span></span><br><span class="line">      # Disqus 评论系统设置</span><br><span class="line">      [params.page.comment.disqus]</span><br><span class="line">        <span class="meta"># </span></span><br><span class="line"><span class="meta">        enable = false</span></span><br><span class="line">        # Disqus 的 shortname，用来在文章中启用 Disqus 评论系统</span><br><span class="line">        shortname = <span class="string">&quot;&quot;</span></span><br><span class="line">      # Gitalk 评论系统设置</span><br><span class="line">      [params.page.comment.gitalk]</span><br><span class="line">        <span class="meta"># </span></span><br><span class="line"><span class="meta">        enable = true</span></span><br><span class="line">        owner = <span class="string">&quot;&quot;</span></span><br><span class="line">        repo = <span class="string">&quot;&quot;</span></span><br><span class="line">        clientId = <span class="string">&quot;&quot;</span></span><br><span class="line">        clientSecret = <span class="string">&quot;&quot;</span></span><br><span class="line">        id= <span class="string">&quot;location.pathname&quot;</span> # 文章页面的链接地址就是ID</span><br><span class="line">        labels= <span class="string">&quot;gitalk&quot;</span> # Github issue labels. If you used to use Gitment, you can change it</span><br><span class="line">        perPage= <span class="number">15</span> # Pagination size, with maximum <span class="number">100.</span></span><br><span class="line">        pagerDirection= <span class="string">&quot;last&quot;</span> # Comment sorting direction, available values are <span class="string">&#x27;last&#x27;</span> <span class="keyword">and</span> <span class="string">&#x27;first&#x27;</span>.</span><br><span class="line">        createIssueManually= <span class="literal">true</span> # 设置为<span class="literal">true</span>，如果是管理员登录，会自动创建issue，如果是<span class="literal">false</span>，需要管理员手动添加第一个评论(issue)</span><br><span class="line">        distractionFreeMode= <span class="literal">false</span> # Enable hot <span class="built_in">key</span> (cmd|ctrl + enter) submit comment.</span><br><span class="line">      # Valine 评论系统设置</span><br><span class="line">      [params.page.comment.valine]</span><br><span class="line">        enable = <span class="literal">false</span></span><br><span class="line">        appId = <span class="string">&quot;&quot;</span></span><br><span class="line">        appKey = <span class="string">&quot;&quot;</span></span><br><span class="line">        placeholder = <span class="string">&quot;&quot;</span></span><br><span class="line">        avatar = <span class="string">&quot;mp&quot;</span></span><br><span class="line">        meta= <span class="string">&quot;&quot;</span></span><br><span class="line">        pageSize = <span class="number">10</span></span><br><span class="line">        # 为空时自动适配当前主题 i18n 配置</span><br><span class="line">        lang = <span class="string">&quot;&quot;</span></span><br><span class="line">        visitor = <span class="literal">true</span></span><br><span class="line">        recordIP = <span class="literal">true</span></span><br><span class="line">        highlight = <span class="literal">true</span></span><br><span class="line">        enableQQ = <span class="literal">false</span></span><br><span class="line">        serverURLs = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="meta">#  emoji 数据文件名称, 默认是 <span class="string">&quot;google.yml&quot;</span></span></span><br><span class="line">        # [<span class="string">&quot;apple.yml&quot;</span>, <span class="string">&quot;google.yml&quot;</span>, <span class="string">&quot;facebook.yml&quot;</span>, <span class="string">&quot;twitter.yml&quot;</span>]</span><br><span class="line">        # 位于 <span class="string">&quot;themes/LoveIt/assets/lib/valine/emoji/&quot;</span> 目录</span><br><span class="line">        # 可以在你的项目下相同路径存放你自己的数据文件:</span><br><span class="line">        # <span class="string">&quot;assets/lib/valine/emoji/&quot;</span></span><br><span class="line">        emoji = <span class="string">&quot;&quot;</span></span><br><span class="line">      # Facebook 评论系统设置</span><br><span class="line">      [params.page.comment.facebook]</span><br><span class="line">        enable = <span class="literal">false</span></span><br><span class="line">        width = <span class="string">&quot;100%&quot;</span></span><br><span class="line">        numPosts = <span class="number">10</span></span><br><span class="line">        appId = <span class="string">&quot;&quot;</span></span><br><span class="line">        # 为空时自动适配当前主题 i18n 配置</span><br><span class="line">        languageCode = <span class="string">&quot;zh_CN&quot;</span></span><br><span class="line">      #  Telegram Comments 评论系统设置</span><br><span class="line">      [params.page.comment.telegram]</span><br><span class="line">        enable = <span class="literal">false</span></span><br><span class="line">        siteID = <span class="string">&quot;&quot;</span></span><br><span class="line">        limit = <span class="number">5</span></span><br><span class="line">        height = <span class="string">&quot;&quot;</span></span><br><span class="line">        color = <span class="string">&quot;&quot;</span></span><br><span class="line">        colorful = <span class="literal">true</span></span><br><span class="line">        dislikes = <span class="literal">false</span></span><br><span class="line">        outlined = <span class="literal">false</span></span><br><span class="line">      #  Commento 评论系统设置</span><br><span class="line">      [params.page.comment.commento]</span><br><span class="line">        enable = <span class="literal">false</span></span><br><span class="line">      <span class="meta">#  utterances 评论系统设置</span></span><br><span class="line">      [params.page.comment.utterances]</span><br><span class="line">        enable = <span class="literal">false</span></span><br><span class="line">        <span class="meta"># owner/repo</span></span><br><span class="line">        repo = <span class="string">&quot;&quot;</span></span><br><span class="line">        issueTerm = <span class="string">&quot;pathname&quot;</span></span><br><span class="line">        label = <span class="string">&quot;&quot;</span></span><br><span class="line">        lightTheme = <span class="string">&quot;github-light&quot;</span></span><br><span class="line">        darkTheme = <span class="string">&quot;github-dark&quot;</span></span><br><span class="line">      <span class="meta"># giscus comment 评论系统设置 (https:<span class="comment">//giscus.app/zh-CN)</span></span></span><br><span class="line">      [params.page.comment.giscus]</span><br><span class="line">        # 你可以参考官方文档来使用下列配置</span><br><span class="line">        enable = <span class="literal">false</span></span><br><span class="line">        repo = <span class="string">&quot;&quot;</span></span><br><span class="line">        repoId = <span class="string">&quot;&quot;</span></span><br><span class="line">        category = <span class="string">&quot;Announcements&quot;</span></span><br><span class="line">        categoryId = <span class="string">&quot;&quot;</span></span><br><span class="line">        # 为空时自动适配当前主题 i18n 配置</span><br><span class="line">        lang = <span class="string">&quot;&quot;</span></span><br><span class="line">        mapping = <span class="string">&quot;pathname&quot;</span></span><br><span class="line">        reactionsEnabled = <span class="string">&quot;1&quot;</span></span><br><span class="line">        emitMetadata = <span class="string">&quot;0&quot;</span></span><br><span class="line">        inputPosition = <span class="string">&quot;bottom&quot;</span></span><br><span class="line">        lazyLoading = <span class="literal">false</span></span><br><span class="line">        lightTheme = <span class="string">&quot;light&quot;</span></span><br><span class="line">        darkTheme = <span class="string">&quot;dark&quot;</span></span><br><span class="line">    #  第三方库配置</span><br><span class="line">    [params.page.library]</span><br><span class="line">      [params.page.library.css]</span><br><span class="line">        # someCSS = <span class="string">&quot;some.css&quot;</span></span><br><span class="line">        # 位于 <span class="string">&quot;assets/&quot;</span></span><br><span class="line">        # 或者</span><br><span class="line">        # someCSS = <span class="string">&quot;https://cdn.example.com/some.css&quot;</span></span><br><span class="line">      [params.page.library.js]</span><br><span class="line">        # someJavascript = <span class="string">&quot;some.js&quot;</span></span><br><span class="line">        # 位于 <span class="string">&quot;assets/&quot;</span></span><br><span class="line">        # 或者</span><br><span class="line">        # someJavascript = <span class="string">&quot;https://cdn.example.com/some.js&quot;</span></span><br><span class="line">    #  页面 SEO 配置</span><br><span class="line">    [params.page.seo]</span><br><span class="line">      # 图片 URL</span><br><span class="line">      images = []</span><br><span class="line">      # 出版者信息</span><br><span class="line">      [params.page.seo.publisher]</span><br><span class="line">        name = <span class="string">&quot;&quot;</span></span><br><span class="line">        logoUrl = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  #  TypeIt 配置</span><br><span class="line">  [params.typeit]</span><br><span class="line">    # 每一步的打字速度 (单位是毫秒)</span><br><span class="line">    speed = <span class="number">100</span></span><br><span class="line">    # 光标的闪烁速度 (单位是毫秒)</span><br><span class="line">    cursorSpeed = <span class="number">1000</span></span><br><span class="line">    # 光标的字符 (支持 HTML 格式)</span><br><span class="line">    cursorChar = <span class="string">&quot;|&quot;</span></span><br><span class="line">    # 打字结束之后光标的持续时间 (单位是毫秒, <span class="string">&quot;-1&quot;</span> 代表无限大)</span><br><span class="line">    duration = <span class="number">-1</span></span><br><span class="line"></span><br><span class="line">  # 网站验证代码，用于 Google/Bing/Yandex/Pinterest/Baidu</span><br><span class="line">  [params.verification]</span><br><span class="line">    google = <span class="string">&quot;&quot;</span></span><br><span class="line">    bing = <span class="string">&quot;&quot;</span></span><br><span class="line">    yandex = <span class="string">&quot;&quot;</span></span><br><span class="line">    pinterest = <span class="string">&quot;&quot;</span></span><br><span class="line">    baidu = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  #  网站 SEO 配置</span><br><span class="line">  [params.seo]</span><br><span class="line">    # 图片 URL</span><br><span class="line">    image = <span class="string">&quot;/favicon-32x32.png&quot;</span></span><br><span class="line">    # 缩略图 URL</span><br><span class="line">    thumbnailUrl = <span class="string">&quot;/favicon-32x32.png&quot;</span></span><br><span class="line"></span><br><span class="line">  #  网站分析配置</span><br><span class="line">  [params.analytics]</span><br><span class="line">    enable = <span class="literal">true</span></span><br><span class="line">    # Google Analytics</span><br><span class="line">    [params.analytics.google]</span><br><span class="line">      id = <span class="string">&quot;&quot;</span></span><br><span class="line">      # 是否匿名化用户 IP</span><br><span class="line">      anonymizeIP = <span class="literal">true</span></span><br><span class="line">    # Fathom Analytics</span><br><span class="line">    [params.analytics.fathom]</span><br><span class="line">      id = <span class="string">&quot;&quot;</span></span><br><span class="line">      # 自行托管追踪器时的主机路径</span><br><span class="line">      server = <span class="string">&quot;&quot;</span></span><br><span class="line">    # Plausible Analytics</span><br><span class="line">    [params.analytics.plausible]</span><br><span class="line">      dataDomain = <span class="string">&quot;&quot;</span></span><br><span class="line">    # Yandex Metrica</span><br><span class="line">    [params.analytics.yandexMetrica]</span><br><span class="line">      id = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  #  Cookie 许可配置</span><br><span class="line">  [params.cookieconsent]</span><br><span class="line">    enable = <span class="literal">false</span></span><br><span class="line">    # 用于 Cookie 许可横幅的文本字符串</span><br><span class="line">    [params.cookieconsent.content]</span><br><span class="line">      message = <span class="string">&quot;&quot;</span></span><br><span class="line">      dismiss = <span class="string">&quot;&quot;</span></span><br><span class="line">      link = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  #  第三方库文件的 CDN 设置</span><br><span class="line">  [params.cdn]</span><br><span class="line">    # CDN 数据文件名称, 默认不启用</span><br><span class="line">    # [<span class="string">&quot;jsdelivr.yml&quot;</span>]</span><br><span class="line">    # 位于 <span class="string">&quot;themes/LoveIt/assets/data/cdn/&quot;</span> 目录</span><br><span class="line">    # 可以在你的项目下相同路径存放你自己的数据文件:</span><br><span class="line">    # <span class="string">&quot;assets/data/cdn/&quot;</span></span><br><span class="line">    data = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  #  兼容性设置</span><br><span class="line">  [params.compatibility]</span><br><span class="line">    # 是否使用 Polyfill.io 来兼容旧式浏览器</span><br><span class="line">    polyfill = <span class="literal">false</span></span><br><span class="line">    # 是否使用 object-fit-images 来兼容旧式浏览器</span><br><span class="line">    objectFit = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"># Hugo 解析文档的配置</span><br><span class="line">[markup]</span><br><span class="line">  # 语法高亮设置</span><br><span class="line">  [markup.highlight]</span><br><span class="line">    codeFences = <span class="literal">true</span></span><br><span class="line">    guessSyntax = <span class="literal">true</span></span><br><span class="line">    lineNos = <span class="literal">true</span></span><br><span class="line">    lineNumbersInTable = <span class="literal">true</span></span><br><span class="line">    <span class="meta"># false 是必要的设置</span></span><br><span class="line">    # (https:<span class="comment">//github.com/dillonzq/LoveIt/issues/158)</span></span><br><span class="line">    noClasses = <span class="literal">false</span></span><br><span class="line">  # Goldmark 是 Hugo <span class="number">0.60</span> 以来的默认 Markdown 解析库</span><br><span class="line">  [markup.goldmark]</span><br><span class="line">    [markup.goldmark.extensions]</span><br><span class="line">      definitionList = <span class="literal">true</span></span><br><span class="line">      footnote = <span class="literal">true</span></span><br><span class="line">      linkify = <span class="literal">true</span></span><br><span class="line">      strikethrough = <span class="literal">true</span></span><br><span class="line">      table = <span class="literal">true</span></span><br><span class="line">      taskList = <span class="literal">true</span></span><br><span class="line">      typographer = <span class="literal">true</span></span><br><span class="line">    [markup.goldmark.renderer]</span><br><span class="line">      # 是否在文档中直接使用 HTML 标签</span><br><span class="line">      unsafe = <span class="literal">true</span></span><br><span class="line">  # 目录设置</span><br><span class="line">  [markup.tableOfContents]</span><br><span class="line">    startLevel = <span class="number">2</span></span><br><span class="line">    endLevel = <span class="number">6</span></span><br><span class="line"></span><br><span class="line"># 网站地图配置</span><br><span class="line">[sitemap]</span><br><span class="line">  changefreq = <span class="string">&quot;weekly&quot;</span></span><br><span class="line">  filename = <span class="string">&quot;sitemap.xml&quot;</span></span><br><span class="line">  priority = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"># Permalinks 配置</span><br><span class="line">[Permalinks]</span><br><span class="line">  <span class="meta"># posts = <span class="string">&quot;:year/:month/:filename&quot;</span></span></span><br><span class="line">  posts = <span class="string">&quot;:filename&quot;</span></span><br><span class="line"></span><br><span class="line"># 隐私信息配置</span><br><span class="line">[privacy]</span><br><span class="line">  #  Google Analytics 相关隐私 (被 params.analytics.google 替代)</span><br><span class="line">  [privacy.googleAnalytics]</span><br><span class="line">    # ...</span><br><span class="line">  [privacy.twitter]</span><br><span class="line">    enableDNT = <span class="literal">true</span></span><br><span class="line">  [privacy.youtube]</span><br><span class="line">    privacyEnhanced = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"># 用于输出 Markdown 格式文档的设置</span><br><span class="line">[mediaTypes]</span><br><span class="line">  [mediaTypes.<span class="string">&quot;text/plain&quot;</span>]</span><br><span class="line">    suffixes = [<span class="string">&quot;md&quot;</span>]</span><br><span class="line"></span><br><span class="line"># 用于输出 Markdown 格式文档的设置</span><br><span class="line">[outputFormats.MarkDown]</span><br><span class="line">  mediaType = <span class="string">&quot;text/plain&quot;</span></span><br><span class="line">  isPlainText = <span class="literal">true</span></span><br><span class="line">  isHTML = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"># 用于 Hugo 输出文档的设置</span><br><span class="line">[outputs]</span><br><span class="line">  home = [<span class="string">&quot;HTML&quot;</span>, <span class="string">&quot;RSS&quot;</span>, <span class="string">&quot;JSON&quot;</span>]</span><br><span class="line">  page = [<span class="string">&quot;HTML&quot;</span>, <span class="string">&quot;MarkDown&quot;</span>]</span><br><span class="line">  section = [<span class="string">&quot;HTML&quot;</span>, <span class="string">&quot;RSS&quot;</span>]</span><br><span class="line">  taxonomy = [<span class="string">&quot;HTML&quot;</span>, <span class="string">&quot;RSS&quot;</span>]</span><br><span class="line">  taxonomyTerm = [<span class="string">&quot;HTML&quot;</span>]</span><br></pre></td></tr></table></figure>
<p>本地启动，<a href="http://localhost:1313/">http://localhost:1313/</a> 查看效果</p>
<p>本地启动测试。</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">hugo server</span><br></pre></td></tr></table></figure>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403270911647.png" alt="image">​</p>
<h2 id="3-部署到Github"><a href="#3-部署到Github" class="headerlink" title="3 部署到Github"></a>3 部署到Github</h2><p>进入pubilc创建仓库,并推送到公开仓库</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> public</span><br><span class="line">git init</span><br><span class="line">git add .</span><br><span class="line">git commit <span class="literal">-m</span> <span class="string">&quot;first commit&quot;</span></span><br><span class="line">git branch <span class="literal">-M</span> main</span><br><span class="line">git remote add origin https://github.com/CATSLAB<span class="literal">-SDU</span>/CATSLAB<span class="literal">-SDU</span>.github.io.git</span><br><span class="line">git push <span class="literal">-u</span> origin main</span><br></pre></td></tr></table></figure>
<p>在github中进行配置</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403270912394.png" alt="">​</p>
<h2 id="4-自动部署"><a href="#4-自动部署" class="headerlink" title="4 自动部署"></a>4 自动部署</h2><p>在站点根目录执行 <code>Hugo</code>​ 命令生成最终页面，注意替换仓库和主题。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">hugo <span class="literal">--theme</span>=LoveIt <span class="literal">--baseURL</span>=<span class="string">&quot;https://CATSLAB-SDU.github.io/&quot;</span></span><br></pre></td></tr></table></figure>
<p>在本地创建文件hugo.yaml</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">mkdir .github/workflows/</span><br></pre></td></tr></table></figure>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="built_in">new-item</span> .github/workflows/main.yaml <span class="literal">-type</span> file</span><br></pre></td></tr></table></figure>
<p>把下面内容复制到main.yaml中</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Sample workflow for building and deploying a Hugo site to GitHub Pages</span></span><br><span class="line"><span class="comment"># This is a basic workflow to help you get started with Actions</span></span><br><span class="line"></span><br><span class="line">name: CI</span><br><span class="line"></span><br><span class="line"><span class="comment"># Controls when the action will run.</span></span><br><span class="line">on:</span><br><span class="line">  <span class="comment"># Triggers the workflow on push or pull request events but only for the master branch</span></span><br><span class="line">  push:</span><br><span class="line">    branches: [<span class="type">main</span>]</span><br><span class="line">  pull_request:</span><br><span class="line">    branches: [<span class="type">main</span>]</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Allows you to run this workflow manually from the Actions tab</span></span><br><span class="line">  workflow_dispatch:</span><br><span class="line"></span><br><span class="line"><span class="comment"># A workflow run is made up of one or more jobs that can run sequentially or in parallel</span></span><br><span class="line">jobs:</span><br><span class="line">  <span class="comment"># This workflow contains a single job called &quot;build&quot;</span></span><br><span class="line">  build:</span><br><span class="line">    <span class="comment"># The type of runner that the job will run on</span></span><br><span class="line">    runs<span class="literal">-on</span>: ubuntu<span class="literal">-latest</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Steps represent a sequence of tasks that will be executed as part of the job</span></span><br><span class="line">    steps:</span><br><span class="line">      <span class="comment"># Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it</span></span><br><span class="line">      - uses: actions/checkout@v2</span><br><span class="line">        with:</span><br><span class="line">          submodules: true <span class="comment"># Fetch Hugo themes (true OR recursive)</span></span><br><span class="line">          fetch<span class="literal">-depth</span>: <span class="number">0</span> <span class="comment"># Fetch all history for .GitInfo and .Lastmod</span></span><br><span class="line"></span><br><span class="line">      - name: Hugo setup</span><br><span class="line">        <span class="comment"># You may pin to the exact commit or the version.</span></span><br><span class="line">        <span class="comment"># uses: peaceiris/actions-hugo@2e89aa66d0093e4cd14751b3028fc1a179452c2e</span></span><br><span class="line">        uses: peaceiris/actions<span class="literal">-hugo</span>@v2.<span class="number">4.13</span></span><br><span class="line">        with:</span><br><span class="line">          <span class="comment"># The Hugo version to download (if necessary) and use. Example: 0.58.2</span></span><br><span class="line">          hugo<span class="literal">-version</span>: latest <span class="comment"># optional, default is latest</span></span><br><span class="line">          <span class="comment"># Download (if necessary) and use Hugo extended version. Example: true</span></span><br><span class="line">          extended: true <span class="comment"># optional, default is false</span></span><br><span class="line"></span><br><span class="line">      - name: Build</span><br><span class="line">        run: hugo</span><br><span class="line"></span><br><span class="line">      - name: Pushes to another repository</span><br><span class="line">        uses: cpina/github<span class="literal">-action-push-to-another-repository</span>@main</span><br><span class="line">        env:</span><br><span class="line">          API_TOKEN_GITHUB: <span class="variable">$</span>&#123;&#123; secrets.API_TOKEN_GITHUB &#125;&#125;</span><br><span class="line">        with:</span><br><span class="line">          source<span class="literal">-directory</span>: <span class="string">&quot;public&quot;</span></span><br><span class="line">          destination<span class="literal">-github-username</span>: <span class="string">&quot;CATSLAB-SDU&quot;</span></span><br><span class="line">          destination<span class="literal">-repository-name</span>: <span class="string">&quot;CATSLAB-SDU.github.io&quot;</span></span><br><span class="line">          user<span class="literal">-email</span>: catslabsdu@gmail.com</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在github中设置<code>Developer settings/Personal access tokens</code>​，新建一个密钥，权限设置把<code>Repo</code>​打勾。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403270912848.png" alt="">​</p>
<p>回到私人仓库的设置里，新建密钥，将刚才生成的个人密钥填进去，名字设为<code>API_TOKEN_GITHUB</code>​(跟 CI 脚本里的名称对应即可)</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403270912890.png" alt="">​</p>
<p>完成该设置后更新私有库后公共库会自动更新。</p>
<p>‍</p>
<h2 id="4-细节设置"><a href="#4-细节设置" class="headerlink" title="4 细节设置"></a>4 细节设置</h2><p><a href="https://realfavicongenerator.net/">Favicon Generator for perfect icons on all browsers (realfavicongenerator.net)</a>利用该网站生成头像等资源发在static目录下面。</p>
<p>‍</p>
<h2 id="5-评论设置"><a href="#5-评论设置" class="headerlink" title="5 评论设置"></a>5 评论设置</h2><p>首先要去<code>Github -&gt; Settings -&gt; Developer Settings -&gt; OAuth App</code>​ 里注册一个新的 OAuth App 来给 Gitalk 使用。并修改<code>config.toml</code>​:</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">params.page.comment</span>]</span><br><span class="line">     enable = true  &lt;<span class="literal">--</span> 启用评论系统</span><br><span class="line">     [<span class="type">params.page.comment.gitalk</span>]</span><br><span class="line">       enable = true</span><br><span class="line">       owner = <span class="string">&quot;JellyZhang&quot;</span>  &lt;<span class="literal">--</span> Github用户名</span><br><span class="line">       repo = <span class="string">&quot;blog-comment&quot;</span> &lt;<span class="literal">--</span> 用来存放评论的repo名称</span><br><span class="line">       clientId = <span class="string">&quot;&quot;</span>  &lt;<span class="literal">--</span> 申请好的OAuth的ClientId</span><br><span class="line">       clientSecret = <span class="string">&quot;&quot;</span> &lt;<span class="literal">--</span> 申请好的OAuth的ClientSecret</span><br></pre></td></tr></table></figure>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403270912115.png" alt="">​</p>
<h2 id="6-搜索设置"><a href="#6-搜索设置" class="headerlink" title="6 搜索设置"></a>6 搜索设置</h2><p>在<a href="https://www.algolia.com/">AI search that understands | Algolia</a>创建账号,创建一个<code>application</code>​与<code>index</code>​:</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403270912311.png" alt="">​</p>
<p>然后将下面的内容填写到<code>config.toml</code>​中：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment">#  搜索配置</span></span><br><span class="line">  [<span class="type">params.search</span>]</span><br><span class="line">    enable = true</span><br><span class="line">    <span class="comment"># 搜索引擎的类型 [&quot;lunr&quot;, &quot;algolia&quot;]</span></span><br><span class="line">    <span class="built_in">type</span> = <span class="string">&quot;algolia&quot;</span></span><br><span class="line">    <span class="comment"># 文章内容最长索引长度</span></span><br><span class="line">    contentLength = <span class="number">4000</span></span><br><span class="line">    <span class="comment"># 搜索框的占位提示语</span></span><br><span class="line">    placeholder = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="comment">#  最大结果数目</span></span><br><span class="line">    maxResultLength = <span class="number">10</span></span><br><span class="line">    <span class="comment">#  结果内容片段长度</span></span><br><span class="line">    snippetLength = <span class="number">50</span></span><br><span class="line">    <span class="comment">#  搜索结果中高亮部分的 HTML 标签</span></span><br><span class="line">    highlightTag = <span class="string">&quot;em&quot;</span></span><br><span class="line">    <span class="comment">#  是否在搜索索引中使用基于 baseURL 的绝对路径</span></span><br><span class="line">    absoluteURL = false</span><br><span class="line">    [<span class="type">params.search.algolia</span>]</span><br><span class="line">      index = <span class="string">&quot;blog&quot;</span></span><br><span class="line">      appID = <span class="string">&quot;&quot;</span></span><br><span class="line">      searchKey = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403270912375.png" alt="">​</p>
<p>‍</p>
<p>修改main.yaml，将下面内容加到最后面：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">- name: Algolia Index Uploader</span><br><span class="line">       <span class="comment"># You may pin to the exact commit or the version.</span></span><br><span class="line">       <span class="comment"># uses: rxrw/algolia-index-uploader@294d1d600c4a2197a64903b6161cc80acea1becb</span></span><br><span class="line">       uses: rxrw/algolia<span class="literal">-index-uploader</span>@v1</span><br><span class="line">       with:</span><br><span class="line">         <span class="comment"># Your Algolia IndexPath</span></span><br><span class="line">         index_path: public/index.json </span><br><span class="line">         <span class="comment"># Algolia Index Id</span></span><br><span class="line">         algolia_index_id: </span><br><span class="line">         <span class="comment"># Algolia Index Name</span></span><br><span class="line">         algolia_index_name: </span><br><span class="line">         <span class="comment"># Algolia Admin Key</span></span><br><span class="line">         algolia_index_admin_key: </span><br></pre></td></tr></table></figure>
<p>‍</p>
<h2 id="7-日常维护"><a href="#7-日常维护" class="headerlink" title="7 日常维护"></a>7 日常维护</h2><p>登录github账号：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">user：</span><br><span class="line">password：</span><br></pre></td></tr></table></figure>
<p>在website仓库加入添加自己的github为协作账号，并在自己github账号绑定的邮件中同意。</p>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403270939957.png" alt="">​</p>
<p>‍</p>
<p>clone website仓库，将相应的markdown文件放到content/posts目录下，在文件前面加入，修改markdown.py中的文件名，执行python脚本进行字符转义。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">+++</span><br><span class="line">title = <span class="string">&quot;title&quot;</span></span><br><span class="line">date = <span class="string">&quot;2024-03-06T16:02:29+08:00&quot;</span></span><br><span class="line">draft = false</span><br><span class="line">subtitle = <span class="string">&quot;&quot;</span></span><br><span class="line">tags = [<span class="string">&quot;笔记1&quot;</span>,<span class="string">&quot;笔记1&quot;</span>]</span><br><span class="line">categories = [<span class="string">&quot;方向&quot;</span>]</span><br><span class="line">license = <span class="string">&#x27;&lt;a rel=&quot;license external nofollow noopener noreferrer&quot; href=&quot;https://creativecommons.org/licenses/by-nc/4.0/&quot; target=&quot;_blank&quot;&gt;CC BY-NC 4.0&lt;/a&gt;&#x27;</span></span><br><span class="line">+++</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>python转义主要是为了兼容数学公式,下面是一个示​例$idf*$​：</p>
<script type="math/tex; mode=display">
\begin{align*}
\omega_{R\cdot C}^{(k_{r}+k_{c}\cdot R)(i_{r}\cdot C+i_{c})}&=\omega_{R\cdot C}^{i_{c}k_{r}+i_{c}k_{c}\cdot R+i_{r}k_{r}\cdot C+i_{r}k_{c}\cdot RC} \\&=\omega_{R\cdot C}^{i_{c}k_{r}}\cdot \omega_{R\cdot C}^{i_{c}k_{c}\cdot R}\cdot \omega_{R\cdot C}^{i_{r}k_{r}\cdot C}\cdot \omega_{R\cdot C}^{i_{r}k_{c}\cdot RC}
\end{align*}</script><p>返回website根目录执行：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">hugo </span><br><span class="line"></span><br><span class="line">git add .</span><br><span class="line">git commit <span class="literal">-m</span> <span class="string">&quot;添加文件&quot;</span></span><br><span class="line">git push <span class="literal">-u</span> origin main</span><br></pre></td></tr></table></figure>
<h2 id="8-图片处理"><a href="#8-图片处理" class="headerlink" title="8 图片处理"></a>8 图片处理</h2><p>markdown中的图片需要上传到网络图床。下载PicGo这里推荐山东大学的镜像网站：<a href="https://mirrors.sdu.edu.cn/github-release/Molunerfinn_PicGo/v2.3.1/">v2.3.1 (sdu.edu.cn)</a></p>
<p>进行图床设置：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">仓库名:   CATSLAB<span class="literal">-SDU</span>/ImageBed</span><br><span class="line"></span><br><span class="line">分支：main</span><br><span class="line"></span><br><span class="line">token：</span><br><span class="line"></span><br><span class="line">存储路径：</span><br><span class="line"></span><br><span class="line">自定义域名：</span><br></pre></td></tr></table></figure>
<p>​<img src="https://cdn.jsdelivr.net/gh/yinxiangkai/ImageBed@main/202403270912813.png" alt="">​</p>
<p>‍</p>
]]></content>
      <categories>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>网站</tag>
      </tags>
  </entry>
</search>
